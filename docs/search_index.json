[["portada.html", "Modelización del azar y toma de decisiones", " Modelización del azar y toma de decisiones Autor: Jaime Turrión Edición de 2026 Estos apuntes están pensados como material de apoyo para la asignatura Modelización del Azar y Toma de Decisiones, dirigida a estudiantes de primer curso. El objetivo es introducir los conceptos fundamentales de probabilidad y variables aleatorias combinando: - Explicaciones teóricas claras - Ejemplos resueltos paso a paso - Simulaciones y visualizaciones con R Estos apuntes están en fase de preparación. Todavía están en desarrollo y se irán introduciendo mejoras a lo largo del curso. "],["intro.html", "Tema 1 Introducción", " Tema 1 Introducción La incertidumbre es un elemento central en numerosos problemas económicos, empresariales y sociales. Desde la toma de decisiones bajo riesgo hasta el análisis de fenómenos aleatorios observados en datos reales, resulta imprescindible disponer de herramientas formales que permitan describir, modelizar e interpretar situaciones en las que el resultado no es determinista. La Modelización del Azar proporciona ese marco conceptual y técnico, apoyándose en la teoría de la probabilidad y en el estudio de las variables aleatorias. Estos apuntes están concebidos como material de apoyo para la asignatura Modelización del Azar y Toma de Decisiones, dirigida a estudiantes de primer curso. Su objetivo principal es introducir de forma progresiva los fundamentos del razonamiento probabilístico, combinando el rigor matemático con una orientación aplicada y computacional. A lo largo del texto se desarrollan los conceptos clave que permiten pasar de la descripción de experimentos aleatorios a la construcción de modelos probabilísticos capaces de explicar y anticipar el comportamiento de fenómenos reales. El recorrido comienza con el estudio de la probabilidad, partiendo de la noción de experimento aleatorio y espacio muestral, el análisis de sucesos y sus operaciones, y la formulación axiomática de Kolmogórov. Sobre esta base se introducen las reglas fundamentales de la probabilidad, la probabilidad condicionada y los principales teoremas, que constituyen el núcleo del razonamiento probabilístico. A continuación se aborda el concepto de variable aleatoria como herramienta fundamental para cuantificar resultados aleatorios. Se distinguen variables discretas y continuas, se analizan sus funciones de distribución y de densidad, y se introducen las principales medidas descriptivas asociadas, como la esperanza matemática y la varianza. Estos conceptos permiten conectar la teoría probabilística con el análisis de datos y la interpretación estadística. Sobre esta base, los apuntes desarrollan los modelos de probabilidad discretos y continuos más relevantes, prestando especial atención a su interpretación, propiedades y ámbitos de aplicación. El tratamiento no se limita a la exposición teórica, sino que se acompaña de ejemplos, representaciones gráficas y simulaciones que facilitan la comprensión de los modelos y su comportamiento. El material se completa con un capítulo dedicado a la relación entre distribuciones y la convergencia en distribución, donde se introducen ideas clave para entender aproximaciones probabilísticas y resultados asintóticos fundamentales, como el papel de la distribución normal en contextos muy diversos. Finalmente, se incluye una colección de ejercicios orientados a consolidar los conceptos trabajados, fomentar el razonamiento probabilístico y desarrollar la capacidad de modelización. A lo largo de los apuntes se incorporan además ejemplos y simulaciones realizadas con R, con el doble objetivo de reforzar la intuición teórica y familiarizar al alumnado con herramientas computacionales ampliamente utilizadas en el análisis de datos. Por tanto, estos apuntes pretenden servir como guía estructurada para el aprendizaje de la asignatura Modelización del azar y toma de decisiones, facilitando la transición desde los conceptos básicos hasta resultados de mayor profundidad, y proporcionando una base sólida para asignaturas posteriores de estadística, econometría y análisis de datos. "],["prob.html", "Tema 2 Probabilidad 2.1 Introducción 2.2 Sucesos y operaciones con sucesos 2.3 Concepto de probabilidad 2.4 Axiomas de Kolmogórov 2.5 Reglas (Teoremas) de la probabilidad 2.6 Independencia de sucesos 2.7 Combinatoria: Técnicas de enumeración", " Tema 2 Probabilidad 2.1 Introducción A lo largo de nuestra vida —como ciudadanos, analistas o científicos— estamos expuestos constantemente a fenómenos inciertos: los resultados de un experimento, las fluctuaciones de los mercados, el clima, o el comportamiento humano. Todos estos fenómenos comparten una característica común: la incertidumbre. Esta incertidumbre nos lleva a formular preguntas como: - ¿Por qué se ha producido este resultado? - ¿Era previsible? - ¿Cuál es el resultado más probable? - ¿Podría haberse anticipado? - ¿Cómo influye la información disponible en nuestras expectativas? Es aquí donde entra en juego la probabilidad, que proporciona un lenguaje matemático para describir, cuantificar y gestionar la incertidumbre. Nos permite asignar un valor numérico (una probabilidad) a la posibilidad de que ocurra un determinado suceso dentro de un fenómeno aleatorio, , ayudándonos a comprender mejor lo que observamos y, en algunos casos, a anticiparlo. La Estadística, como disciplina, se apoya en dos grandes pilares: Estadística descriptiva: organiza y resume la información observada. Inferencia estadística: extrae conclusiones generales a partir de los datos, basándose en modelos de probabilidad. La probabilidad actúa como puente entre ambas etapas. Antes de poder interpretar datos inciertos o extraer conclusiones válidas, es necesario comprender cómo se comportan los fenómenos aleatorios. Este tema constituye la base para desarrollar ese conocimiento y tiene como objetivo: Introducir los elementos básicos de la teoría de la probabilidad. Analizar distintas formas de entender la probabilidad. Presentar las reglas fundamentales para operar con sucesos. Establecer las bases para trabajar con modelos probabilísticos. Introducir los principios de combinatoria, necesarios para calcular probabilidades en experimentos complejos. A lo largo del tema combinaremos teoría, ejemplos intuitivos y simulaciones con R para que puedas aplicar estos conceptos en problemas reales de análisis de datos, economía o gestión empresarial. 2.2 Sucesos y operaciones con sucesos Antes de estudiar cómo calcular la probabilidad de un fenómeno aleatorio, es fundamental comprender qué es un experimento aleatorio, qué posibles resultados puede tener y cómo representarlos mediante sucesos. 2.2.1 Experimento aleatorio y espacio muestral Un experimento aleatorio es un proceso cuyo resultado no puede preverse con certeza, aunque se conocen todos los posibles resultados que pueden ocurrir. El conjunto de todos los resultados posibles se denomina espacio muestral, y se representa habitualmente por \\(\\Omega\\) o \\(E\\). Ejemplos: Lanzar una moneda una vez: \\(\\Omega = { c, + }\\), donde \\(c\\) representa cara y \\(+\\) cruz. Lanzar una moneda dos veces: \\(\\Omega = { cc, c+, +c, ++ }\\). Lanzar un dado una vez: \\(\\Omega = {1, 2, 3, 4, 5, 6}\\). 2.2.2 Tipos de sucesos Un suceso (también llamado evento) es cualquier subconjunto del espacio muestral: \\(A \\subseteq \\Omega\\). Si contiene un solo resultado → suceso elemental. Si contiene varios → suceso compuesto. Ejemplo: Se lanza un dado y se observa el número que aparece. El espacio muestral es: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) - \\(A = \\{2, 4, 6\\}\\): suceso compuesto (“salir número par”). - \\(B = \\{3\\}\\): suceso elemental (“salir un 3”). Casos particulares de de sucesos Suceso seguro: contiene todos los resultados posibles (todos los elementos del espacio muestral). Siempre ocurre. \\(A = \\Omega\\). Figure 2.1: Suceso seguro: A = Ω Suceso imposible: no contiene ningún resultado. Nunca ocurre. \\(A = \\emptyset\\). Sucesos incompatibles: No pueden ocurrir a la vez. \\(A \\cap B = \\emptyset\\). Sucesos compatibles: Pueden ocurrir simultáneamente. \\(A \\cap B \\neq \\emptyset\\). 2.2.3 Operaciones con sucesos Las operaciones con sucesos se corresponden con operaciones de conjuntos. A continuación se presentan las más relevantes, con su interpretación y visualización. Unión: El suceso \\(A \\cup B\\) ocurre si ocurre \\(A\\), \\(B\\), o ambos. Figure 2.2: Unión de sucesos: A ∪ B Intersección: El suceso \\(A \\cap B\\) ocurre solo si ocurren ambos sucesos a la vez. ## Loading required package: futile.logger Complementario: El suceso \\(\\overline{A}\\) (también denotado \\(A^c\\)) ocurre cuando no ocurre el suceso \\(A\\). Diferencia: El suceso \\(A - B\\) ocurre si ocurre \\(A\\) pero no ocurre \\(B\\). Por analogía, el suceso \\(B-A\\) ocurre si ocurre \\(B\\) pero no ocurre \\(A\\). Ejemplo:Dado el espacio muestral \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), y los sucesos: - \\(A = \\{2, 4, 6\\}\\) - \\(B = \\{1, 2, 3, 4\\}\\) entonces: - \\(A \\cup B = \\{1, 2, 3, 4, 6\\}\\) - \\(A \\cap B = \\{2, 4\\}\\) - \\(\\overline{A} = \\{1, 3, 5\\}\\) - \\(A - B = \\{6\\}\\) 2.2.4 Propiedades del álgebra de sucesos Sean \\(A\\), \\(B\\) y \\(C\\) sucesos del espacio muestral \\(\\Omega\\): Idempotencia: \\(A \\cup A = A\\), \\(A \\cap A = A\\) Conmutativa: \\(A \\cup B = B \\cup A\\), \\(A \\cap B = B \\cap A\\) Asociativa: \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\), etc. Distributiva: \\((A \\cup B) \\cap C = (A \\cap C) \\cup (B \\cap C)\\) Neutro: \\(A \\cup \\emptyset = A\\), \\(A \\cap \\Omega = A\\) Absorbente: \\(A \\cup \\Omega = \\Omega\\), \\(A \\cap \\emptyset = \\emptyset\\) Complemento: \\(A \\cup \\overline{A} = \\Omega\\), \\(A \\cap \\overline{A} = \\emptyset\\) Doble complemento: \\(\\overline{\\overline{A}} = A\\) Leyes de Morgan: 1ª ley de Morgan: \\(\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}\\), 2ª Ley de Morgan: \\(\\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}\\) Esta última propiedad es especialmente útil, ya que permite simplificar muchos cálculos. Por ello, vamos a definirla con mayor detalle. Las leyes de De Morgan son reglas fundamentales del álgebra de conjuntos que permiten expresar el complemento de una unión o de una intersección mediante las operaciones inversas. Se formulan del siguiente modo: Primera ley de Morgan: \\(\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}\\) La primera ley indica que todo lo que no pertenece a la unión de \\(A\\) y \\(B\\), es decir, \\(\\overline{A \\cup B}\\), coincide con lo que está fuera de \\(A\\) y fuera de \\(B\\) simultáneamente. Segunda Ley de Morgan: \\(\\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}\\) La segunda ley señala que todo lo que no pertenece a la intersección de \\(A\\) y \\(B\\), es decir, \\(\\overline{A \\cap B}\\), equivale a lo que no está en \\(A\\) o no está en \\(B\\). Estas leyes nos permiten transformar expresiones con complementos de conjuntos compuestos en otras más manejables, lo cual resulta especialmente útil al calcular probabilidades y trabajar con eventos complejos. ###Ejercicios Dado el espacio muestral \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), define los siguientes sucesos: Suceso seguro: \\(A = \\Omega\\) Suceso imposible: \\(B = \\emptyset\\) Sucesos incompatibles: \\(C = \\{1, 2\\},\\quad D = \\{3, 4\\}\\) ya que \\(C \\cap D = \\emptyset\\) Sucesos compatibles: \\(E = \\{2, 3, 4\\},\\quad F = \\{4, 5, 6\\}\\) ya que \\(E \\cap F = \\{4\\}\\) Verifica la primera ley de De Morgan para: \\(A = {2, 4, 6}\\),\\(B = {1, 2, 3, 4}\\),\\(\\Omega = {1, 2, 3, 4, 5, 6}\\) \\[ \\overline{A \\cup B} = \\overline{A} \\cap \\overline{B} \\] \\[ A \\cup B = \\{1, 2, 3, 4, 6\\} \\] Calculamos el complementario de \\(A \\cup B\\)** Recordamos que el complemento de un conjunto \\(C\\), denotado \\(\\overline{C}\\), es el conjunto de los elementos de \\(\\Omega\\) que no están en \\(C\\): \\[ \\overline{A \\cup B} = \\Omega - (A \\cup B) = \\{1, 2, 3, 4, 5, 6\\} - \\{1, 2, 3, 4, 6\\} = \\{5\\} \\] Calculamos \\(\\overline{A}\\) y \\(\\overline{B}\\)** \\(\\overline{A} = \\Omega - A = \\{1, 3, 5\\}\\) \\(\\overline{B} = \\Omega - B = \\{5, 6\\}\\) Calculamos la intersección \\(\\overline{A} \\cap \\overline{B}\\)** \\[ \\overline{A} \\cap \\overline{B} = \\{1, 3, 5\\} \\cap \\{5, 6\\} = \\{5\\} \\] Si comparamos los resultados \\(\\overline{A \\cup B} = \\{5\\}\\) \\(\\overline{A} \\cap \\overline{B} = \\{5\\}\\) ambos conjuntos coinciden, por tanto: \\[ \\boxed{\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}} \\] 2.3 Concepto de probabilidad La probabilidad es el lenguaje matemático con el que medimos la incertidumbre. Nos permite asignar un valor numérico a qué tan probable es que ocurra un determinado suceso dentro de un experimento aleatorio. Esta asignación es clave cuando pasamos de describir lo que ha ocurrido —estadística descriptiva— a estimar lo que podría ocurrir en el futuro o en otros contextos —inferencia estadística—. En estadística, trabajamos habitualmente con muestras para extraer conclusiones sobre poblaciones. Sin embargo, como las muestras se obtienen al azar, necesitamos herramientas para cuantificar hasta qué punto las conclusiones que obtenemos son fiables. Aquí es donde entra en juego la probabilidad: es la base teórica que justifica los métodos inferenciales. El objetivo de esta sección es proporcionar una primera aproximación al concepto de probabilidad, mostrar las principales interpretaciones existentes y presentar las herramientas que nos permitirán calcularla en distintos contextos. Estos fundamentos son esenciales para todo el análisis probabilístico posterior, incluyendo el estudio de variables aleatorias y distribuciones. La probabilidad es una herramienta matemática fundamental para analizar fenómenos inciertos. Su utilidad es clave en la toma de decisiones bajo incertidumbre, en ámbitos tan diversos como los seguros, la economía, la gestión empresarial o las ciencias sociales. Antes de aplicar reglas o fórmulas, es necesario entender qué significa hablar de la probabilidad de un suceso. 2.3.1 Interpretaciones de la probabilidad 2.3.1.1 Probabilidad clásica Una de las primeras formas de entender la probabilidad es la llamada probabilidad clásica, también conocida como probabilidad a priori. Esta interpretación surge en el contexto de los juegos de azar, donde todos los resultados posibles se consideran igualmente probables. Definición: La probabilidad clásica de un suceso \\(A\\) se define como el cociente entre el número de casos favorables a \\(A\\) y el número total de casos posibles, siempre que todos ellos tengan la misma probabilidad de ocurrir: \\[ P(A) = \\frac{\\text{número de casos favorables a } A}{\\text{número total de casos posibles}} = \\frac{n(A)}{n(\\Omega)} \\] donde: \\(n(A)\\): número de resultados favorables al suceso \\(A\\) \\(n(\\Omega)\\): número total de resultados posibles en el espacio muestral \\(\\Omega\\) Condiciones de aplicación Esta definición solo es válida cuando: El espacio muestral es finito Todos los resultados elementales son equiprobables 2.3.1.1.1 Propiedades de la probabilidad clásica A partir de esta definición, se pueden deducir las siguientes propiedades fundamentales: Rango: La probabilidad de cualquier suceso está entre 0 y 1: \\[ 0 \\leq P(A) \\leq 1 \\] Suceso imposible: \\[ P(\\emptyset) = 0 \\] Suceso seguro: \\[ P(\\Omega) = 1 \\] Complementario: \\[ P(\\overline{A}) = 1 - P(A) \\] Adición para sucesos incompatibles: \\[ A \\cap B = \\emptyset \\Rightarrow P(A \\cup B) = P(A) + P(B) \\] Monotonía: \\[ A \\subseteq B \\Rightarrow P(A) \\leq P(B) \\] Ejemplo Al lanzar un dado justo, la probabilidad de obtener un número par es: \\[ P(\\text{par}) = \\frac{3}{6} = 0{,}5 \\] 2.3.1.2 Probabilidad frecuentista Una interpretación alternativa y muy influyente de la probabilidad es la frecuentista. Esta concepción se basa en la observación de fenómenos repetidos un gran número de veces. Definición: La probabilidad frecuentista de un suceso \\(A\\) se define como el límite de la frecuencia relativa de aparición de \\(A\\) cuando el experimento se repite muchas veces en condiciones similares: \\[ P(A) = \\lim_{n \\to \\infty} \\frac{n(A)}{n} \\] donde: \\(n(A)\\): número de veces que ocurre el suceso \\(A\\) \\(n\\): número total de repeticiones del experimento Esta definición se entiende como una propiedad empírica del experimento aleatorio: cuanto mayor sea el número de repeticiones, más se estabiliza la frecuencia relativa del suceso \\(A\\). Condiciones de aplicación El experimento debe poder repetirse en condiciones similares o idénticas. Se requiere un número suficientemente grande de repeticiones para aproximarse al valor de la probabilidad. 2.3.1.2.1 Propiedades de la probabilidad frecuentista Al igual que con la probabilidad clásica, se cumplen las propiedades fundamentales: \\(0 \\leq P(A) \\leq 1\\) \\(P(\\Omega) = 1\\) \\(P(\\emptyset) = 0\\) \\(P(\\overline{A}) = 1 - P(A)\\) Si \\(A \\cap B = \\emptyset\\), entonces \\(P(A \\cup B) = P(A) + P(B)\\) Estas propiedades pueden observarse empíricamente al analizar datos de experimentos reales repetidos muchas veces. Ejemplo Supongamos que lanzamos una moneda 1.000 veces y obtenemos 513 caras. La probabilidad frecuentista de obtener cara se estima como: \\[ P(\\text{cara}) \\approx \\frac{513}{1000} = 0.513 \\] A medida que se incrementa el número de lanzamientos, esta frecuencia relativa tiende a estabilizarse en torno al valor teórico (0,5 si la moneda es equilibrada). 2.3.1.3 Probabilidad bayesiana La probabilidad bayesiana interpreta la probabilidad como un grado de creencia subjetivo que tiene una persona sobre la ocurrencia de un suceso, en función de la información disponible. Este enfoque reconoce que las personas pueden asignar probabilidades diferentes a un mismo suceso, dependiendo del conocimiento previo que posean. A diferencia de la probabilidad clásica o frecuentista, no exige que el experimento sea repetible ni que todos los resultados sean equiprobables. Características clave Subjetiva: se basa en el conocimiento, experiencia o información previa del observador. Dinamismo: la probabilidad se actualiza cuando se dispone de nueva información (usando el Teorema de Bayes). Útil en contextos de incertidumbre parcial, como la medicina, el diagnóstico, las decisiones económicas, etc. Ejemplo Supongamos que sabemos que un paciente pertenece a un grupo de riesgo de cierta enfermedad. Esto nos lleva a asignar una probabilidad inicial (o a priori) de que esté enfermo. Tras realizarle una prueba médica, si el resultado es positivo, actualizamos nuestra creencia sobre su estado de salud combinando la información previa con la nueva evidencia. Este proceso se realiza aplicando el Teorema de Bayes, que permite pasar de la probabilidad a priori a una probabilidad a posteriori. Interpretación La probabilidad bayesiana no es una propiedad objetiva del suceso, sino una expresión del conocimiento y la incertidumbre del observador. Por ello, es especialmente útil en situaciones donde la información es incompleta o se va obteniendo progresivamente. 2.4 Axiomas de Kolmogórov La formulación matemática moderna de la probabilidad se basa en el sistema axiomático propuesto por Andréi Kolmogórov en 1933. Este enfoque establece las reglas fundamentales que debe cumplir toda asignación de probabilidades. Sean \\(\\Omega\\) el espacio muestral y \\(\\mathcal{F}\\) una colección de sucesos (subconjuntos de \\(\\Omega\\)). Una función \\(P\\) que asigna un número real \\(P(A)\\) a cada suceso \\(A \\in \\mathcal{F}\\) es una probabilidad si cumple los siguientes axiomas: 2.4.1 Axioma 1: No negatividad \\[ \\forall A \\in \\mathcal{F}, \\quad P(A) \\geq 0 \\] La probabilidad de cualquier suceso es un número mayor o igual que cero. 2.4.2 Axioma 2: Normalización \\[ P(\\Omega) = 1 \\] La probabilidad del suceso seguro (es decir, el conjunto de todos los posibles resultados) es igual a 1. ###Axioma 3: Aditividad numerable Si \\(A_1, A_2, A_3, \\ldots\\) son sucesos mutuamente incompatibles (es decir, \\(A_i \\cap A_j = \\emptyset\\) para \\(i \\neq j\\)), entonces: \\[ P\\left( \\bigcup_{i=1}^{\\infty} A_i \\right) = \\sum_{i=1}^{\\infty} P(A_i) \\] Este axioma se conoce como sigma-aditividad y garantiza que la probabilidad se comporta de forma coherente incluso cuando consideramos una sucesión infinita de sucesos disjuntos. La tripleta \\((\\Omega, \\mathcal{F}, P)\\) se denomina espacio de probabilidad. Justificación y contexto Aunque estos axiomas se aceptan sin demostración, tienen una fuerte motivación basada en la realidad que modelan: Los dos primeros axiomas pueden justificarse desde la teoría clásica (equiprobabilidad) y la frecuentista (frecuencias relativas): La probabilidad no debe ser negativa. La probabilidad del suceso seguro debe ser 1. El tercer axioma es más técnico: en la práctica, se trabaja con sucesiones finitas de sucesos, pero su generalización a casos infinitos es fundamental en el plano teórico y en el desarrollo de la probabilidad continua. 2.4.3 Propiedades derivadas de los axiomas A partir de los tres axiomas de Kolmogórov, se pueden deducir una serie de propiedades que facilitan el cálculo de probabilidades y permiten desarrollar el resto de la teoría: 1. Probabilidad del suceso imposible El suceso imposible es el conjunto vacío, \\(\\emptyset\\), y su probabilidad es: \\[ P(\\emptyset) = 0 \\] Esto se deduce del axioma 3 aplicándolo a una familia vacía de sucesos. 2. Probabilidad del Complemento de un suceso Dado un suceso \\(A\\), su complemento se denota \\(\\overline{A}\\) (o \\(A^c\\)) y representa que no ocurre \\(A\\). Entonces: \\[ P(\\overline{A}) = 1 - P(A) \\] Esto se deduce usando que \\(A \\cup \\overline{A} = \\Omega\\) y que \\(A \\cap \\overline{A} = \\emptyset\\). 3. Monotonía Si un suceso \\(A\\) está contenido en otro suceso \\(B\\), es decir \\(A \\subseteq B\\), entonces: \\[ P(A) \\leq P(B) \\] 4. Aditividad finita Si \\(A\\) y \\(B\\) son sucesos incompatibles, es decir \\(A \\cap B = \\emptyset\\), entonces: \\[ P(A \\cup B) = P(A) + P(B) \\] Este resultado es un caso particular del axioma 3. Fórmula de la unión para dos sucesos Cuando \\(A\\) y \\(B\\) no son disjuntos, se puede calcular la probabilidad de su unión mediante: \\[ P(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\] 5.Probabilidad de la diferencia de sucesos La probabilidad de \\(A - B\\) (es decir, de que ocurra \\(A\\) pero no \\(B\\)) es: \\[ P(A - B) = P(A) - P(A \\cap B) \\] Todas estas propiedades se aplican de forma sistemática en los ejercicios prácticos y en el desarrollo de técnicas más avanzadas, como el cálculo de probabilidades condicionadas o el uso del teorema de Bayes. 2.5 Reglas (Teoremas) de la probabilidad Una vez comprendido el concepto de probabilidad, es necesario aprender a combinarla en distintos contextos. Las reglas que veremos a continuación nos permiten calcular probabilidades más complejas, muchas veces necesarias en aplicaciones estadísticas, financieras o de gestión de riesgos. Estas reglas permiten calcular probabilidades más complejas combinando sucesos conocidos. Son fundamentales en aplicaciones como la predicción de riesgos o el diagnóstico médico. A partir de los axiomas de Kolmogórov y las propiedades deducidas, se pueden establecer una serie de resultados fundamentales que permiten calcular probabilidades en situaciones más complejas. A continuación presentamos los más importantes. 2.5.1 Probabilidad condicionada La probabilidad condicionada de un suceso \\(A\\) dado que ha ocurrido otro suceso \\(B\\) (con \\(P(B) &gt; 0\\)) se define como: \\[ P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\] Esta expresión representa la probabilidad de que ocurra \\(A\\), sabiendo que ya ha ocurrido \\(B\\). Es útil cuando tenemos información adicional que modifica nuestro punto de vista sobre el experimento. Ejemplo: Si sabemos que ha salido un número par al lanzar un dado, la probabilidad de que sea mayor que 3 ya no es \\(\\frac{3}{6}\\), sino \\(\\frac{2}{3}\\), porque solo consideramos los pares: \\(\\{2,4,6\\}\\). 2.5.2 Regla del producto A partir de la definición de probabilidad condicionada, se obtiene la regla del producto para dos sucesos: \\[ P(A \\cap B) = P(B) \\cdot P(A \\mid B) = P(A) \\cdot P(B \\mid A) \\] Esta fórmula permite calcular la probabilidad de la intersección de dos sucesos. 2.5.3 Teorema de la probabilidad total Sea \\(\\{B_1, B_2, \\dots, B_n\\}\\) una partición del espacio muestral \\(\\Omega\\) (es decir, sucesos incompatibles y cuya unión es \\(\\Omega\\)), y sea \\(A\\) un suceso cualquiera. Entonces: \\[ P(A) = \\sum_{i=1}^n P(B_i) \\cdot P(A \\mid B_i) \\] Este teorema permite descomponer la probabilidad de un suceso complejo en términos de probabilidades condicionadas, lo que resulta especialmente útil cuando se tienen diferentes escenarios posibles. 2.5.4 Teorema de Bayes Este resultado permite invertir la condición en una probabilidad condicionada. Es decir, calcular \\(P(B_i \\mid A)\\) a partir de \\(P(A \\mid B_i)\\) y \\(P(B_i)\\). \\[ P(B_i \\mid A) = \\frac{P(B_i) \\cdot P(A \\mid B_i)}{\\sum_{j=1}^n P(B_j) \\cdot P(A \\mid B_j)} \\] Este teorema se entiende mejor visualmente a través de un diagrama de árbol, que representa cómo se ramifican los sucesos condicionales. Ejemplo resuelto con el Teorema de Bayes Supongamos que en una población: El 40% fuma y el 60% no fuma. Entre los fumadores, el 75% son hombres. Entre los no fumadores, el 40% son hombres. Figure 2.3: Diagrama de árbol para el Teorema de Bayes Pregunta: Si una persona seleccionada al azar es hombre, ¿cuál es la probabilidad de que fume? ✅ Paso 1: Definir los sucesoss - \\(F\\): la persona fuma - \\(\\overline{F}\\): la persona no fuma - \\(H\\): la persona es hombre Queremos calcular: \\[ P(F \\mid H) = ? \\] ✅ Paso 2: Aplicar el Teorema de Bayes \\[ P(F \\mid H) = \\frac{P(F) \\cdot P(H \\mid F)}{P(F) \\cdot P(H \\mid F) + P(\\overline{F}) \\cdot P(H \\mid \\overline{F})} \\] Sustituimos los datos del árbol: \\[ P(F \\mid H) = \\frac{0.4 \\cdot 0.75}{0.4 \\cdot 0.75 + 0.6 \\cdot 0.4} = \\frac{0.3}{0.3 + 0.24} = \\frac{0.3}{0.54} \\approx 0{,}556 \\] ✅ Conclusión La probabilidad de que una persona fume, sabiendo que es hombre, es aproximadamente 0,556. Este ejemplo muestra cómo el Teorema de Bayes nos permite invertir la condición y obtener una probabilidad a posteriori a partir de datos previos y condicionales. Permite invertir probabilidades condicionadas, pasando de \\(P(A \\mid B)\\) a \\(P(B \\mid A)\\). Es la base del razonamiento bayesiano: \\[ P(B_j \\mid A) = \\frac{P(A \\mid B_j) P(B_j)}{\\sum_{i=1}^n P(A \\mid B_i) P(B_i)} \\] Este teorema es la base de la probabilidad bayesiana, y se aplica frecuentemente en diagnóstico médico, toma de decisiones y clasificación en ciencia de datos. Ejemplo típico: Si un test médico da positivo, ¿cuál es la probabilidad de que realmente el paciente esté enfermo? Bayes permite responder a esta pregunta teniendo en cuenta la probabilidad previa de enfermedad y las tasas de falsos positivos y negativos. 2.5.4.1 Ejercicios Teorema de Bayes 2.5.4.1.1 Ejercicio 1: Diagnóstico médico Una enfermedad afecta al 2 % de la población. Existe una prueba médica que: Da positivo en el 99 % de los casos si la persona está enferma. Da positivo en el 5 % de los casos si la persona no está enferma (falso positivo). Pregunta: Si una persona da positivo en la prueba, ¿cuál es la probabilidad de que esté realmente enferma? ✅Solución Paso 1: Definir los sucesos \\(E\\): persona está enferma \\(\\overline{E}\\): persona no está enferma \\(+\\): la prueba da positivo Queremos calcular: \\[ P(E \\mid +) \\] Paso 2: Aplicar el Teorema de Bayes \\[ P(E \\mid +) = \\frac{P(E) \\cdot P(+ \\mid E)}{P(E) \\cdot P(+ \\mid E) + P(\\overline{E}) \\cdot P(+ \\mid \\overline{E})} \\] Sustituimos: [ P(E +) = = = ] Conclusión: Aunque la prueba sea bastante fiable, la probabilidad de que una persona realmente esté enferma si da positivo es solo 0,288. Esto se debe a que la enfermedad es poco frecuente. 2.5.4.1.2 Ejercicio 2: Contratación en una empresa Una empresa contrata a candidatos de dos universidades: El 30% de los contratados proviene de la Universidad A, y el 70% de la Universidad B. El 90% de los egresados de A superan el periodo de prueba. El 60% de los egresados de B lo superan. Pregunta: Si un empleado ha superado el periodo de prueba, ¿cuál es la probabilidad de que haya estudiado en la Universidad A? ✅ Solución guiada Paso 1: Definir los sucesos \\(A\\): proviene de la Universidad A \\(B\\): proviene de la Universidad B \\(S\\): supera el periodo de prueba Queremos calcular: \\[ P(A \\mid S) \\] Paso 2: Aplicar el Teorema de Bayes \\[ P(A \\mid S) = \\frac{P(A) \\cdot P(S \\mid A)}{P(A) \\cdot P(S \\mid A) + P(B) \\cdot P(S \\mid B)} \\] Sustituimos: \\[ P(A \\mid S) = \\frac{0.3 \\cdot 0.9}{0.3 \\cdot 0.9 + 0.7 \\cdot 0.6} = \\frac{0.27}{0.27 + 0.42} = \\frac{0.27}{0.69} \\approx 0.391 \\] Conclusión: Si un empleado supera el periodo de prueba, la probabilidad de que provenga de la Universidad A es aproximadamente 0.391. 2.5.4.2 Ejercicio con R: Clasificación de correos como spam (aprendizaje automático) En un sistema de detección de spam, se ha entrenado un clasificador que detecta si un correo es spam o no, basado en ciertas palabras clave. Se sabe que: El 10% de los correos recibidos son spam. El clasificador: Detecta correctamente un spam el 98 % de las veces (sensibilidad). Clasifica como no spam correctamente un 90 % de los correos legítimos (especificidad). Pregunta: Si un correo ha sido marcado como spam, ¿cuál es la probabilidad de que realmente lo sea? Solución En primer lugar simulamos con R: set.seed(42) # Tamaño de muestra n &lt;- 10000 # Generamos si el correo es spam (10%) es_spam &lt;- rbinom(n, 1, 0.10) # Clasificador identifica spam con sensibilidad 98% y especificidad 90% marcado_spam &lt;- ifelse(es_spam == 1, rbinom(n, 1, 0.98), # verdadero positivo rbinom(n, 1, 0.10)) # falso positivo # Guardamos en un data.frame correos &lt;- data.frame(es_spam, marcado_spam) # Tabla de frecuencias table(correos$marcado_spam, correos$es_spam, dnn = c(&quot;Marcado como spam&quot;, &quot;Es spam&quot;)) ## Es spam ## Marcado como spam 0 1 ## 0 8093 20 ## 1 876 1011 A continuación calculamos la probabilidad empírica: # Correos marcados como spam correos_marcados &lt;- correos[correos$marcado_spam == 1, ] # Proporción de verdaderos spam entre los marcados prob_spam_dado_marcado &lt;- mean(correos_marcados$es_spam) prob_spam_dado_marcado ## [1] 0.5357711 Aunque el clasificador es bastante preciso (98% de sensibilidad y 90% de especificidad), solo el 53.6% de los correos marcados como spam son realmente spam. Esto ocurre porque el evento “ser spam” es poco frecuente (solo el 10% de todos los correos). En estos casos, incluso una pequeña tasa de error puede provocar que muchos correos legítimos sean marcados erróneamente como spam (falsos positivos), y eso hace que la probabilidad de que un correo marcado como spam sea realmente spam no sea tan alta como cabría esperar. Conclusión clave: El valor del 53.6% muestra que en contextos con baja prevalencia (como el spam), la probabilidad posterior puede alejarse bastante de la sensibilidad del test. Es decir, tener un buen clasificador no garantiza una alta fiabilidad en los positivos si el evento que se intenta detectar es raro. Esto es una consecuencia directa del teorema de Bayes. Visualización Interpretación del gráfico Barra izquierda (Spam): Mayoritariamente clasificados correctamente como spam (color rojo). Barra derecha (No spam): Un pequeño porcentaje se clasifica erróneamente como spam (falsos positivos). ✅ Conclusión Con esta simulación, hemos estimado empíricamente la probabilidad \\(P(Spam∣Marcado)\\), es decir, la probabilidad de que un correo realmente sea spam si ha sido clasificado como tal. Este valor estará alrededor del 52%, mostrando cómo incluso un buen clasificador puede producir una alta tasa de falsos positivos cuando el evento es poco frecuente. 2.6 Independencia de sucesos En muchos fenómenos reales, algunos sucesos no se afectan entre sí. Por ejemplo, lanzar un dado y tirar una moneda son experimentos que no interfieren uno con otro. El concepto de independencia formaliza esta idea y nos permite simplificar notablemente los cálculos cuando se cumple. Es especialmente relevante en modelos de probabilidad compuesta y en teoría estadística. La independencia permite identificar situaciones en las que un suceso no afecta a la ocurrencia de otro, algo muy relevante para modelos de riesgo o predicciones múltiples. Definición Dos sucesos \\(A\\) y \\(B\\) se consideran independientes cuando la ocurrencia de uno de ellos (por ejemplo, \\(B\\)) no modifica la probabilidad de que ocurra el otro (\\(A\\)). Matemáticamente, esta relación se expresa mediante las igualdades: \\(P(A \\mid B) = P(A)\\) \\(P(B \\mid A) = P(B)\\) Es decir, si \\(A\\) y \\(B\\) son independientes, conocer que ha ocurrido uno de ellos no aporta información adicional sobre la ocurrencia del otro. La probabilidad de \\(A\\) condicionada a \\(B\\) coincide con la probabilidad incondicional de \\(A\\), y lo mismo sucede con \\(B\\) condicionado a \\(A\\). Por tanto, si dos sucesos \\(A\\) y \\(B\\) son independientes se verifica que: \\[ P(A \\cap B) = P(A) P(B) \\] En estas circunastancias: \\(P(A \\mid B) = \\frac{P(A \\cap B)}{P(A)}=P(A)\\) Ejemplo: Lanzar una moneda y tirar un dado. El resultado del dado no influye en la moneda. ### Ejemplo: Independencia entre dos sucesos Supongamos que lanzamos un dado y tiramos una moneda. Definimos los siguientes sucesos: \\(A\\): obtener un número par en el dado. \\(B\\): obtener cara en la moneda. Queremos saber si los sucesos \\(A\\) y \\(B\\) son independientes. Calculamos \\(P(A)\\) En un dado hay 3 números pares: 2, 4 y 6. Por tanto: \\[ P(A) = \\frac{3}{6} = 0.5 \\] Calculamos \\(P(B)\\) La moneda tiene dos caras: cara y cruz. La probabilidad de sacar cara es: \\[ P(B) = \\frac{1}{2} = 0.5 \\] Calculamos \\(P(A \\cap B)\\) Como el resultado del dado no afecta al de la moneda y viceversa, el total de posibles combinaciones es \\(6 \\times 2 = 12\\). Las combinaciones que dan par y cara son: (2, cara), (4, cara), (6, cara) → 3 casos favorables. \\[ P(A \\cap B) = \\frac{3}{12} = 0.25 \\] Verificamos si \\(P(A \\cap B) = P(A) \\cdot P(B)\\) \\[ P(A) \\cdot P(B) = 0.5 \\cdot 0.5 = 0.25 = P(A \\cap B) \\] Como se cumple la igualdad: \\[ \\boxed{A \\text{ y } B \\text{ son sucesos independientes}} \\] Simulación en R Vamos a simular este experimento 100.000 veces y comprobar empíricamente la independencia: set.seed(42) n &lt;- 100000 dado &lt;- sample(1:6, n, replace = TRUE) moneda &lt;- sample(c(&quot;cara&quot;, &quot;cruz&quot;), n, replace = TRUE) A &lt;- dado %% 2 == 0 B &lt;- moneda == &quot;cara&quot; p_A &lt;- mean(A) p_B &lt;- mean(B) p_AB &lt;- mean(A &amp; B) c(P_A = p_A, P_B = p_B, P_AyB = p_AB, Producto = p_A * p_B, dif = p_AB - p_A * p_B) ## P_A P_B P_AyB Producto dif ## 0.498520000 0.498450000 0.249800000 0.248487294 0.001312706 Nota: al ser un experimento empírico, la igualdad no se cumple perfectamente. Obsérvese que sacar un número par en un lanzamiento de un dado no es exáctamente 0.5, y lo mismo ocurre con el número de caras al lanzar una moneda. Si se incrementa el número de repeticiones se espera que esas diferencias son menores. 2.6.1 Regla del producto o de la multiplicación La regla del producto o multiplicación permite calcular la probabilidad de que ocurran simultáneamente varios sucesos, incluso si no son independientes. Para \\(n\\) sucesos \\(A_1, A_2, \\dots, A_n\\), la probabilidad conjunta se puede expresar como una cadena de probabilidades condicionadas: \\[ P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) = P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot P(A_3 \\mid A_1 \\cap A_2) \\cdot \\dots \\cdot P(A_n \\mid A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1}) \\] Esta fórmula nos dice que para conocer la probabilidad de que ocurran todos los sucesos a la vez, primero calculamos la probabilidad del primero, luego la del segundo en función de que haya ocurrido el primero, después la del tercero dado que han ocurrido los dos anteriores, y así sucesivamente. Cuando los sucesos son independientes entre sí, esta fórmula se simplifica notablemente, ya que las probabilidades condicionadas se igualan a las incondicionales. En ese caso, basta con multiplicar las probabilidades individuales: \\[ P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) = P(A_1) \\cdot P(A_2) \\cdot \\dots \\cdot P(A_n) \\] Este resultado es una consecuencia directa de la definición de independencia para más de dos sucesos. Ejemplo: Aplicación de la regla del producto Supongamos que en una empresa se están seleccionando candidatos para tres puestos diferentes: A, B y C. Cada selección depende de la anterior: La probabilidad de seleccionar un candidato adecuado para el puesto A es \\(P(A) = 0.9\\). Si se ha seleccionado a alguien para A, la probabilidad de encontrar un candidato adecuado para B es \\(P(B \\mid A) = 0.8\\). Si se han seleccionado candidatos para A y B, la probabilidad de seleccionar a uno adecuado para C es \\(P(C \\mid A \\cap B) = 0.7\\). Queremos calcular la probabilidad de que se seleccionen buenos candidatos para los tres puestos a la vez, es decir: \\[ P(A \\cap B \\cap C) \\] En primer lugar, según la regla del producto: \\[ P(A \\cap B \\cap C) = P(A) \\cdot P(B \\mid A) \\cdot P(C \\mid A \\cap B) \\] Si sustituimos valores \\[ P(A \\cap B \\cap C) = 0.9 \\cdot 0.8 \\cdot 0.7=0.504 \\] Por tanto, la probabilidad de que se encuentren buenos candidatos para los tres puestos es del 50.4%: \\[ \\boxed{P(A \\cap B \\cap C) = 0.504} \\] Podemos confirmar este resultado mediante simulación. Supongamos que repetimos este proceso 10000 veces: set.seed(123) n &lt;- 10000 A &lt;- runif(n) &lt; 0.9 B &lt;- runif(n) &lt; 0.8 &amp; A # B depende de A C &lt;- runif(n) &lt; 0.7 &amp; A &amp; B # C depende de A y B # Probabilidad empírica de que A, B y C ocurran a la vez mean(A &amp; B &amp; C) ## [1] 0.5041 2.7 Combinatoria: Técnicas de enumeración Para aplicar la probabilidad clásica o calcular el tamaño de espacios muestrales, a menudo necesitamos contar cuántas formas hay de que ocurran determinados sucesos. La combinatoria o técnicas de enumeración (principio de multiplicación, permutaciones y combinaciones) nos proporcionan métodos sistemáticos para hacerlo. Son herramientas clave cuando trabajamos con espacios discretos finitos. Estas herramientas permiten contar de forma eficiente el número de casos posibles, crucial para calcular probabilidades en espacios muestrales grandes o abstractos. 2.7.1 Principio de multiplicación Si un experimento consta de \\(k\\) etapas independientes, y cada etapa puede realizarse de un número determinado de formas (\\(n_i\\)), el número total de formas de realizar el experimento completo es el producto del número de opciones en cada etapa: \\[ \\text{Total de casos} = n_1 \\cdot n_2 \\cdot \\cdots \\cdot n_k \\] Condiciones: Las elecciones son independientes entre sí. Se realiza una acción por cada etapa. Ejemplo: Un menú tiene 2 primeros platos, 3 segundos y 2 postres. ¿Cuántos menús diferentes pueden hacerse? \\(2 \\times 3 \\times 2 = 12 \\text{ menús distintos}\\) 2.7.2 Combinaciones Las combinaciones se utilizan cuando lo que importa es el conjunto elegido, no el orden. Es decir, se trata de selecciones sin importar cómo se ordenan. Esto es común en contextos como la formación de comités, grupos de trabajo o en la elección de cartas en un juego. 2.7.2.1 Combinaciones sin repetición Una combinación sin repetición es una selección de \\(k\\) elementos de un conjunto de \\(n\\) elementos, sin repetición y sin importar el orden. \\[ C(n,k) = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\] Se utiliza cuando se quiere saber de cuántas formas se pueden elegir \\(k\\) elementos de entre \\(n\\), sin repetir y sin importar el orden. Ejemplo: ¿Cuántos grupos de 3 estudiantes se pueden formar a partir de un grupo de 5? \\[ C(5,3) = \\frac{5!}{3! \\cdot 2!} = 10 \\] En R choose(5, 3) ## [1] 10 2.7.2.2 Combinaciones con repetición: Una combinación con repetición es una forma de seleccionar \\(k\\) elementos de un conjunto de \\(n\\) elementos, permitiendo la repetición de elementos y sin importar el orden en que se seleccionan. \\[ C&#39;(n,k) = \\binom{n + k - 1}{k} = \\frac{(n + k - 1)!}{k!(n - 1)!} \\] Se utiliza cuando queremos saber cuántas maneras hay de elegir \\(k\\) elementos de un conjunto de \\(n\\) opciones con repetición permitida y donde no importa el orden. Ejemplo Supongamos que disponemos de 4 tipos de caramelos y queremos escoger 3 (permitiendo repetir sabores). ¿Cuántas combinaciones diferentes de caramelos podemos formar? \\[ C&#39;(4,3) = \\binom{4 + 3 - 1}{3} = \\binom{6}{3} = 20 \\] En R # Número de combinaciones con repetición de 3 elementos tomados de 4 tipos choose(4 + 3 - 1, 3) ## [1] 20 2.7.3 Variaciones Las variaciones son disposiciones de elementos tomados de un conjunto, en las que importa el orden. Pueden ser con o sin repetición, según si se permite o no repetir elementos en la selección. 2.7.3.1 Variaciones sin repetición Una variación sin repetición es una forma de seleccionar y ordenar \\(k\\) elementos de un conjunto de \\(n\\) elementos, sin repetir elementos. La fórmula de cálculo es: \\[ V(n,k) = \\frac{n!}{(n-k)!} \\] Las variaciones se usan cuando se desea contar cuántas formas hay de ordenar \\(k\\) elementos tomados de un total de \\(n\\), sin repetir ningún elemento. Ejemplo práctico ¿Cuántos números de 2 cifras distintas se pueden formar con los dígitos del 1 al 5? \\[ V(5,2) = \\frac{5!}{(5 - 2)!} = \\frac{120}{6} = 20 \\] Código en R No existe una fórmula directa para calcular las variaciones, así que se calcula directamente mediante factoriales. # Variaciones sin repetición: V(5,2) factorial(5) / factorial(5 - 2) ## [1] 20 ####Variaciones con repetición Una variación con repetición es una disposición de \\(K\\) elementos seleccionados de un conjunto de \\(n\\) elementos, permitiendo repetición y teniendo en cuenta el orden. SU fórmula es: \\[ V&#39;(n,k) = n^k \\] Las variaciones con repetición se utilizan cuando se desea contar cuántas formas hay de ordenar \\(k\\) elementos de entre \\(n\\), con repetición y cuando el orden importa. Ejemplo práctico ¿Cuántos códigos de 3 dígitos se pueden formar con los números del 1 al 4 si se pueden repetir? \\[ V&#39;(4,3) = 4^3 = 64 \\] Código en R # Variaciones con repetición: V&#39;(4,3) 4^3 ## [1] 64 2.7.4 Permutaciones Las permutaciones son disposiciones u ordenaciones de elementos. Se caracterizan porque el orden sí importa. Se utilizan cuando queremos contar de cuántas maneras diferentes se pueden ordenar o disponer elementos, y el orden importa. Son muy comunes en contextos donde cada posición tiene un significado distinto, como la asignación de premios o el orden de llegada en una competición. Se dividen en dos tipos principales: sin repetición y con repetición. 2.7.4.1 Permutaciones sin repetición Una permutación sin repetición es una ordenación de todos los elementos de un conjunto de \\(n\\) elementos, sin repetir ninguno. Su fórmula es: \\[ P(n) = n! \\] Se emplean cuando queremos contar el número de formas diferentes de ordenar todos los elementos de un conjunto, sin que se repita ninguno. Ejemplo práctico ¿Cuántas formas hay de ordenar las letras de la palabra ROMA? Como tiene 4 letras distintas: \\[ P(4) = 4! = 24 \\] Código en R No hay una fórmula expresa para las permuntaciones, sino que se caclula con la función ‘factorial’. # Permutaciones sin repetición: P(4) factorial(4) ## [1] 24 2.7.4.2 Permutaciones con repetición Una permutación con repetición es una ordenación de un conjunto de elementos donde algunos son idénticos entre sí. Se trata de contar cuántas formas distintas hay de ordenar dichos elementos, sin distinguir los repetidos. \\[ P(n; n_1, n_2, \\dots, n_k) = \\frac{n!}{n_1! \\cdot n_2! \\cdots n_k!} \\] Donde: - \\(n\\) es el número total de elementos, - \\(n_1, n_2, \\dots, n_k\\) representan las repeticiones de cada tipo de elemento indistinguible. Se usa cuando hay elementos repetidos en el conjunto, y queremos contar las disposiciones distintas teniendo en cuenta que los elementos iguales no se diferencian. Ejemplo práctico ¿Cuántas formas distintas hay de ordenar las letras de la palabra ANA? Total de letras: \\(n = 3\\) La letra A se repite dos veces: \\(n_1 = 2\\) La letra N aparece una vez: \\(n_2 = 1\\) \\[ P = \\frac{3!}{2! \\cdot 1!} = \\frac{6}{2} = 3 \\] Código en R COmo en el caso anterior, no existe una fórmula para las permutaciones. # Permutaciones con repetición: letras de &quot;ANA&quot; factorial(3) / (factorial(2) * factorial(1)) ## [1] 3 "],["varale.html", "Tema 3 Variables aleatorias 3.1 Clasificación de las variables aleatorias 3.2 Variables aleatorias Unidimensionales 3.3 Momentos estadísticos de una variable aleatoria unidimensional: esperanza y varianza 3.4 Variables aleatorias Bidimensionales 3.5 Momentos de variables aleatorias bidimensionales", " Tema 3 Variables aleatorias En el estudio de fenómenos aleatorios —como lanzar una moneda, medir el tiempo que tarda en llegar un pedido o analizar el número de visitas a una página web— nos interesa modelizar los posibles resultados numéricamente. Para ello utilizamos las variables aleatorias, que permiten asociar un valor numérico a cada resultado posible de un experimento aleatorio. Esta idea sencilla nos permite transformar la incertidumbre en un objeto matemático que puede ser analizado con herramientas estadísticas. Las variables aleatorias se utilizan cada vez que queremos cuantificar resultados inciertos, modelizar procesos aleatorios o construir modelos probabilísticos que nos ayuden a tomar decisiones. Son fundamentales en economía, empresa, ciencia de datos, ingeniería o ciencias sociales, ya que permiten calcular probabilidades, medias, varianzas y, en general, describir el comportamiento de un fenómeno aleatorio. Una variable aleatoria es una función que asigna un número real a cada resultado del espacio muestral de un experimento aleatorio. Es decir, es una regla que traduce los posibles resultados de un fenómeno aleatorio en valores numéricos que podemos estudiar matemáticamente. Formalmente, una variable aleatoria \\(X\\) es una función: \\[ X: \\Omega \\longrightarrow \\mathbb{R} \\] donde \\(\\Omega\\) es el espacio muestral (conjunto de todos los posibles resultados del experimento) y \\(( \\mathbb{R}\\) es el conjunto de los números reales. 3.1 Clasificación de las variables aleatorias Podemos clasificar las variables aleatorias en función de dos criterios principales: Número de dimensiones (número de variables): Unidimensionales: asocian un único número real a cada resultado del experimento. Por ejemplo, medir el peso de un paquete o contar el número de reclamaciones recibidas en un día. Bidimensionales (o más generalmente, multidimensionales): asocian un vector de números reales a cada resultado del experimento. Por ejemplo, registrar simultáneamente el peso y el volumen de un paquete, o medir el gasto mensual y el ingreso mensual de un hogar. En este caso, hablamos de una variable aleatoria vectorial o un vector aleatorio. Formalmente, si \\(X = (X_1, X_2)\\) es una variable aleatoria bidimensional: \\[ X: \\Omega \\longrightarrow \\mathbb{R}^2 \\] Naturaleza de los valores que pueden tomar: Discretas: cuando sus valores posibles son finitos o infinitos numerables (por ejemplo, \\(0,1,2,\\ldots\\),el número de hijos de una familia o el número de fallos en una cadena de producción). Continuas: cuando pueden tomar cualquier valor dentro de un intervalo o subconjunto de los números reales (por ejemplo, la altura de una persona o el tiempo que tarda un cliente en ser atendido). 3.2 Variables aleatorias Unidimensionales 3.2.1 Variables aleatorias discretas Una variable aleatoria discreta es aquella que solo puede tomar un número finito o numerable de valores. Estos valores suelen estar separados entre sí, como los números enteros, y cada uno tiene una probabilidad asociada. Ejemplos comunes de variables aleatorias discretas son: El número de caras al lanzar varias monedas. El número de clientes que llegan a una tienda en una hora. - El número de errores en un documento. 3.2.1.1 Función de probabilidad o función de cuantía La función de probabilidad (también llamada función de masa de probabilidad o función de cuantía) de una variable aleatoria discreta \\(X\\) es una función que asigna a cada valor posible \\(x_i\\) la probabilidad de que la variable tome ese valor: \\[ f(x_i) = P(X = x_i) \\] Cumple dos propiedades fundamentales: \\(f(x_i) \\geq 0\\) para todo \\(x_i\\) \\(\\sum_i f(x_i) = 1\\) Estas probabilidades pueden representarse en una tabla, un gráfico de barras o en forma de función. 3.2.1.2 Función de distribución acumulada (FDA) La función de distribución acumulada \\(F(x)\\) de una variable aleatoria discreta se define como: \\[ F(x) = P(X \\leq x) = \\sum_{x_i \\leq x} f(x_i) \\] La FDA representa la probabilidad de que la variable tome un valor menor o igual que \\(x\\). Es una función escalonada, monótona no decreciente, con las siguientes propiedades: \\(\\lim_{x \\to -\\infty} F(x) = 0\\) \\(\\lim_{x \\to \\infty} F(x) = 1\\) \\(0 \\leq F(x) \\leq 1\\) para todo \\(x\\). Es una función monótona no decreciente: si \\(x &lt; y\\), entonces \\(F(x) \\leq F(y)\\). Es escalonada: aumenta en los puntos donde la variable aleatoria toma valores, y es constante entre ellos. Es continua por la derecha: en cada punto \\(x\\), se cumple que \\(F(x) = \\lim_{t \\downarrow x} F(t)\\). Gráficamente, tanto la función de cuantía como de distribución tienen la siguiente forma: Ejemplos de variables aleatorias discretas Ejemplo 1: Número de clientes atendidos en una hora La variable aleatoria \\(X\\) representa el número de clientes que entran en una tienda durante una hora. Supongamos que los valores posibles son 0, 1, 2 o 3 clientes, y las probabilidades se basan en la experiencia previa. \\(x\\) \\(f(x) = P(X = x)\\) \\(F(x) = P(X \\leq x)\\) 0 0.1 0.1 1 0.3 0.4 2 0.4 0.8 3 0.2 1.0 Ejemplo 2 (distribución de Bernoulli): Aprobación de un test La variable aleatoria \\(X\\) representa si un estudiante aprueba (1) o suspende (0) un test. Supongamos que la probabilidad de aprobar es 0.7. \\(x\\) \\(f(x) = P(X = x)\\) \\(F(x) = P(X \\leq x)\\) 0 0.3 0.3 1 0.7 1.0 Ejemplo 3 (distribución uniforme discreta): Sorteo de una plaza La variable aleatoria \\(X\\) representa el número del participante que gana una beca, entre 5 candidatos con igual probabilidad. \\(x\\) \\(f(x) = P(X = x)\\) \\(F(x) = P(X \\leq x)\\) 1 0.2 0.2 2 0.2 0.4 3 0.2 0.6 4 0.2 0.8 5 0.2 1.0 Ejemplo 4: número de caras al lanzar 3 monedas Sea \\(X\\) la variable aleatoria que cuenta el número de caras al lanzar tres monedas. Los posibles valores que puede tomar son: \\(X = 0, 1, 2, 3\\) La tabla muestra la función de cuantía \\(f(x) = P(X = x)\\) y la función de distribución acumulada \\(F(x) = P(X \\leq x)\\): \\(x\\) \\(f(x) = P(X = x)\\) \\(F(x) = P(X \\leq x)\\) 0 \\(\\frac{1}{8}\\) = 0.125 0.125 1 \\(\\frac{3}{8}\\) = 0.375 0.500 2 \\(\\frac{3}{8}\\) = 0.375 0.875 3 \\(\\frac{1}{8}\\) = 0.125 1.000 Representación gráfica en R del “número de caras al lanzar tres monedas” # Valores posibles de X x &lt;- 0:3 # Función de cuantía p &lt;- c(1, 3, 3, 1) / 8 # Función de distribución acumulada F &lt;- cumsum(p) # Función de cuantía (gráfico de &quot;palos&quot;) plot(x, p, type = &quot;h&quot;, lwd = 2, col = &quot;blue&quot;, main = &quot;Función de cuantía f(x)&quot;, xlab = &quot;Valores de X&quot;, ylab = &quot;P(X = x)&quot;) points(x, p, pch = 16, col = &quot;blue&quot;) # Función de distribución acumulada (gráfico escalera) plot(x, F, type = &quot;s&quot;, lwd = 2, col = &quot;darkgreen&quot;, main = &quot;Función de distribución acumulada F(x)&quot;, xlab = &quot;Valores de X&quot;, ylab = &quot;F(x)&quot;) points(x, F, pch = 16, col = &quot;darkgreen&quot;) 3.2.2 Variables aleatorias continuas Una variable aleatoria continua es aquella que puede tomar infinitos valores dentro de un intervalo del conjunto de los números reales. A diferencia de las variables discretas, donde los valores están separados unos de otros (por ejemplo, 0, 1, 2…), en las variables continuas no hay “saltos” entre los posibles resultados. Es decir, entre dos valores cualesquiera, siempre existe otro valor posible, por lo que el conjunto de valores que puede tomar no es numerable. Dado que hay infinitos valores posibles, la probabilidad de que la variable tome un valor exacto es siempre cero: \\(P(X = x) = 0\\). Por tanto, solo se pueden calcular probabilidades sobre intervalos, como \\(P(a \\leq X \\leq b)\\). Ejemplos comunes de variables aleatorias continuas son: El tiempo de espera de un cliente en una cola: puede ser 1,85 minutos, 3,142 minutos, o cualquier número real positivo. La cantidad diaria de lluvia en una ciudad, medida en litros por metro cuadrado: puede ser 0, 1,5, 2,78, etc. La altura de una persona, que puede medirse con tanta precisión como permita el instrumento: 165,0 cm, 165,01 cm, 165,001 cm… Estas variables requieren herramientas matemáticas diferentes a las discretas, como la función de densidad y el cálculo integral, para poder estudiar sus propiedades y calcular probabilidades. 3.2.2.1 Función de densidad de probabilidad La función de densidad de una variable aleatoria continua \\(f(x)\\) cumple: \\(f(x) \\geq 0\\) para todo \\(x \\in \\mathbb{R}\\) (es no negativa) \\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\) La probabilidad de que \\(X\\) esté entre dos puntos \\(a\\) y \\(b\\) se calcula como el área bajo la curva: \\[ P(a \\leq X \\leq b) = \\int_a^b f(x) dx \\] 3.2.2.2 Función de distribución acumulada (FDA) La función de distribución acumulada de una variable aleatoria continua \\(X\\) es una función \\(F(x)\\) que asocia a cada valor \\(a\\) la probabilidad de que la variable tome un valor menor o igual que \\(a\\), es decir: \\[ F(a) = P(X \\leq a) = \\int_{-\\infty}^a f(x) dx \\] Esta función también cumple: \\(\\lim_{x \\to -\\infty} F(x) = 0\\) \\(\\lim_{x \\to \\infty} F(x) = 1\\) Es continua, monótona no decreciente. Su derivada (si existe) es la función de densidad: \\[ f(x) = \\frac{dF(x)}{dx} \\] Ejemplo del tiempo de espera en una cola. Sea \\(X\\) la variable aleatoria que representa el tiempo (en minutos) que un cliente espera en una cola de atención. Aunque no podemos asignar una probabilidad exacta a un valor concreto (por ejemplo, \\(P(X = 3) = 0\\)), sí tiene sentido calcular probabilidades en intervalos, como: \\(P(1 \\leq X \\leq 1,5)\\): probabilidad de que espere entre 1 y 1,5 minutos. \\(P(X \\leq 5)\\): probabilidad de que espere como mucho 5 minutos. 3.3 Momentos estadísticos de una variable aleatoria unidimensional: esperanza y varianza Los momentos son medidas que permiten describir las características fundamentales de una variable aleatoria, tales como su tendencia central, dispersión, asimetría o curtosis. De manera general, los momentos cuantifican el valor medio de las potencias de la variable aleatoria respecto a un punto de referencia. Podemos distinguir dos tipos principales de momentos: Momentos respecto del origen: miden la magnitud promedio de las potencias de la variable respecto a cero. Momentos respecto de la media: miden la dispersión y forma de la distribución respecto a su media. 3.3.1 Momentos respecto del origen El momento de orden \\(k\\) respecto del origen de una variable aleatoria \\(X\\) se define como la esperanza de la variable aleatoria de orden \\(k\\): \\[ \\alpha_k = E\\left[X^k\\right] \\] El caso particular más importante es el momento de primer orden respecto del origen, que corresponde a la media o Esperanza de la variable aleatoria \\(X\\): \\[ \\alpha_1 = E[X] \\] 3.3.2 Momentos respecto de la media El momento de orden \\(k\\) respecto de la media (o momento central) se define como: \\[ \\mu_k = E\\left[(X - E[X])^k\\right] \\] Este tipo de momentos nos informa sobre la dispersión, la asimetría y la forma de la distribución. El más importante es el momento de segundo orden respecto de la media, que corresponde a la varianza (\\(\\sigma^2\\)): \\[ \\mu_2 =\\sigma^2= Var(X) = E\\left[(X - E[X])^2\\right] \\] En los siguientes puntos se explicará como se calcula para el caso discreto y continuo. 3.3.3 Relación entre los momentos respecto de la media y del origen Todos los momentos respecto de la media se pueden calcular como una función de los momentos respecto del origen. La fórmula general que los relaciona es: \\[ \\mu_r = \\sum_{k=0}^{r} \\binom{r}{k} (-1)^{r-k}\\,\\mu^{r-k}\\,\\alpha_k. \\] donde \\(r\\) es el orden del momento respecto de la media, \\(k\\) es un número entero que va desde 0 hasta \\(r\\) y \\(\\mu=\\alpha_1\\) es el momento respecto del origen de orden 1 o la media. En particular, los primeros momentos cumplen: Momento respecto de la media de orden 1: \\[ \\mu_1 = 0. \\] Momento respecto de la media de orden 2 (varianza): \\[ \\mu_2 = \\alpha_2 - (\\alpha_1)^2. \\] Demostración: Partiendo de la fórmula general: \\[ \\mu_r = \\sum_{k=0}^{r} \\binom{r}{k}\\,(-1)^{r-k}\\,\\mu^{r-k}\\,\\alpha_k, \\] Para \\(r=2\\): \\[ \\mu_2 = \\sum_{k=0}^{2} \\binom{2}{k}\\,(-1)^{2-k}\\,\\mu^{2-k}\\,\\alpha_k. \\] Desarrollamos término a término del valor \\(k\\): Primer término (\\(k=0\\)): \\[ \\binom{2}{0}\\,(-1)^{2-0}\\,\\mu^{2-0}\\,\\alpha_0 = (1)\\,(+1)\\,\\mu^{2}\\,(1) = \\mu^2. \\] Segundo término (\\(k=1\\)): \\[ \\binom{2}{1}\\,(-1)^{2-1}\\,\\mu^{2-1}\\,\\alpha_1 = (2)\\,(-1)\\,\\mu\\,\\alpha_1 = -2\\,\\mu\\,\\alpha_1=-2\\,\\mu^2 \\] Tercer término (\\(k=2\\)): \\[ \\binom{2}{2}\\,(-1)^{2-2}\\,\\mu^{2-2}\\,\\alpha_2 = (1)\\,(+1)\\,(1)\\,\\alpha_2 = \\alpha_2. \\] Sumamos los tres términos: \\[ \\mu_2 = \\mu^2 - 2\\mu^2 + \\alpha_2=\\alpha_2-\\mu^2 \\] Finalmente: \\[ \\boxed{ \\mu_2 = \\alpha_2 - \\alpha_1^2 } \\] Momento respecto de la media de orden 3 (asimetría): \\[ \\mu_3 = \\alpha_3 - 3\\,\\alpha_1\\,\\alpha_2 + 2\\,(\\alpha_1)^3. \\] Momento respecto la media de orden 4 (curtosis): \\[ \\mu_4 = \\alpha_4 - 4\\,\\alpha_1\\,\\alpha_3 + 6\\,(\\alpha_1)^2\\,\\alpha_2 - 3\\,(\\alpha_1)^4. \\] 3.3.4 Esperanza y varianza de las variables aleatorias unidimensionales Para definir la media y la varianza de manera más concreta, debemos distinguir entre variables aleatorias discretas y continuas. 3.3.4.1 Esperanza y varianza para variables aleatorias discretas Sea \\(X\\) una variable aleatoria discreta con función de masa de probabilidad \\(p(x)\\): Esperanza matemática (media): \\[ \\mu_X=E[X] = \\sum_{x_i} x_i \\, p(x_i) \\] Varianza: \\[ \\sigma^2=Var(X) = \\sum_{x_i} (x_i - E[X])^2 \\, p(x_i)=\\sum_{x_i} (x_i - \\mu_X)^2 \\, p(x_i) \\] que también se puede calcular como \\[ \\sigma^2=\\text{Var}(X) = E[X^2] - (E[X])^2=E[X^2] - \\mu_X^2 \\] En este caso, \\(E[X^2]\\) es el momento respecto del origen de orden 2 que se calcula como: \\[ E[X^2] = \\sum_{x_i} x^2_i \\, p(x_i) \\] 3.3.4.2 Esperanza y varianza para variables aleatorias continuas Sea \\(X\\) una variable aleatoria continua con función de densidad \\(f(x)\\): Esperanza matemática: \\[ E[X] = \\int_{-\\infty}^{\\infty} x \\, f(x) \\, dx \\] Varianza: \\[ \\sigma^2=Var(X) = \\int_{-\\infty}^{\\infty} (x - E[X])^2f(x)dx=\\int_{-\\infty}^{\\infty} (x - \\mu_X)^2f(x) dx \\] que se puede reescribir como: \\[ \\text{Var}(X) = E[(X - E[X])^2]= E[(X - \\mu_X)^2] \\] A efectos prácticos y aplicando las relaciones entre momenttos, suele calcularse con la siguiente fórmula: \\[ \\text{Var}(X) = E[X^2] - (E[X])^2=E[X^2] - \\mu_X^2 \\] donde \\(E[X^2]\\) para el caso continuo es igual a: \\[ E[X^2] = \\int_{-\\infty}^{\\infty} x^2 \\cdot f(x)dx \\] A continuación se presentan las definiciones y fórmulas para variables aleatorias discretas y continuas. Notar, que la definición de estos momentos poblacionales es análoga a la de momentos muestrales (y sus propiedades son las mismas), pero en vez de emplear frecuencias (relativas o absolutas) se emplean probabilidades o densidades. Interpretación La esperanza representa la media de la variable aleatoria e indica el “centro de gravedad” de la distribución. La varianza mide la dispersión alrededor de ese centro. Cuanto mayor es la varianza, más alejados están, en promedio, los valores posibles de la media. Ejemplo en R (variable discreta): # Valores y probabilidades x &lt;- 0:4 p &lt;- c(0.1, 0.3, 0.4, 0.15, 0.05) # Esperanza esperanza &lt;- sum(x * p) # Varianza varianza &lt;- sum((x - esperanza)^2 * p) varianza_momentos &lt;- sum(x^2 * p) - esperanza^2 c(Esperanza = esperanza, Varianza = varianza, Varianza_mom = varianza_momentos) ## Esperanza Varianza Varianza_mom ## 1.7500 0.9875 0.9875 Ejemplo en R (variable continua): # Normal estándar: media 0, varianza 1 esperanza &lt;- integrate(function(x) x * dnorm(x), -Inf, Inf)$value varianza &lt;- integrate(function(x) (x - esperanza)^2 * dnorm(x), -Inf, Inf)$value c(Esperanza = esperanza, Varianza = varianza) ## Esperanza Varianza ## 0 1 3.3.5 Propiedades de la esperanza y la varianza Las propiedades algebraicas de la esperanza y la varianza permiten simplificar muchos cálculos y analizar el comportamiento de las variables aleatorias cuando se transforman o combinan. 3.3.5.1 Propiedades de la esperanza matemática Esperanza de una constante Si \\(c\\) es una constante: \\[ \\mathbb{E}[c] = c \\] Cambio de origen Si \\(X\\) es una variable aleatoria y \\(a\\) es una constante, entonces: \\[ E[X + a] = E[X] + a \\] Sumar una constante \\(a\\) a una variable aleatoria desplaza su esperanza en esa misma cantidad. La forma de la distribución no cambia, solo se traslada a la derecha o a la izquierda. Cambio de escala Si \\(X\\) es una variable aleatoria y \\(b\\) es una constante, entonces: \\[ E[bX] = b \\cdot E[X] \\] Multiplicar una variable aleatoria por una constante escala su esperanza por ese mismo valor. Esta propiedad es un caso particular de la linealidad de la esperanza cuando no hay término independiente. Linealidad de la esperanza Para cualquier variable aleatoria \\(X\\) y constantes \\(a\\), \\(b\\): \\[ E[bX + a] = b \\cdot E[X] + a \\] La esperanza se comporta como una media: escalar por \\(b\\) escala la media, y sumar \\(a\\) la desplaza. Esperanza de la suma o diferencia de variables aleatorias Si \\(X\\) y \\(Y\\) son variables aleatorias (independientes o no): \\[ E[X + Y] = E[X] + E[Y] \\] Y en general, para \\(X_1, X_2, \\dots, X_n\\): \\[ E\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n E[X_i] \\] y lo mismo para \\[ E[X-Y]=E[X]-E[Y] \\] Esperanza del producto de dos variables aleatorias Si \\(X\\) y \\(Y\\) son dos variables aleatorias, en general: \\[ E[XY] \\neq E[X] \\cdot E[Y] \\] Sin embargo, si \\(X\\) y \\(Y\\) son independientes, entonces: \\[ E[XY] = E[X] \\cdot E[Y] \\] Esta propiedad es muy útil cuando se trabaja con productos de variables aleatorias independientes, ya que permite descomponer la esperanza del producto como el producto de las esperanzas. Importante: La independencia es una condición necesaria para que la igualdad se cumpla. Si \\(X\\) y \\(Y\\) no son independientes, la relación no es válida en general. 3.3.5.2 Propiedades de la varianza No negatividad de la varianza Para cualquier variable aleatoria \\(X\\): \\[ \\text{Var}(X) \\geq 0 \\] La varianza nunca puede ser negativa, ya que está definida como la esperanza de un cuadrado: \\[ \\text{Var}(X) = E\\left[(X - E[X])^2\\right] \\] Dado que los cuadrados son siempre mayores o iguales que cero, su media también lo es. La varianza es cero solo cuando \\(X\\) toma siempre el mismo valor (es decir, es una constante). Varianza de una constante Si \\(c\\) es una constante: \\[ \\text{Var}(c) = 0 \\] No hay variabilidad si el valor es constante, ya que siempre toma el mismo valor. Cambio de origen Si \\(X\\) es una variable aleatoria y \\(a\\) una constante: \\[ \\text{Var}(X + a) = \\text{Var}(X) \\] Sumar una constante a una variable aleatoria no cambia su dispersión, solo traslada la distribución horizontalmente. Por tanto, la varianza permanece inalterada. Cambio de escala Si \\(X\\) es una variable aleatoria y \\(b\\) una constante: \\[ \\text{Var}(bX) = b^2 \\cdot \\text{Var}(X) \\] Multiplicar una variable aleatoria por una constante escala su varianza al cuadrado de esa constante. La dispersión se amplifica o reduce según el valor de \\(b\\). Combinación lineal con cambio de origen y escala Si \\(X\\) es una variable aleatoria y \\(a\\), \\(b\\) constantes: \\[ \\text{Var}(a + bX) = b^2 \\cdot \\text{Var}(X) \\] La varianza no se ve afectada por el término constante \\(a\\), y se escala al cuadrado con \\(b\\). Varianza de la suma de variables aleatorias independientes Si \\(X\\) y \\(Y\\) son independientes: \\[ \\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) \\] Y más generalmente, si \\(X_1, X_2, \\dots, X_n\\) son independientes: \\[ \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\text{Var}(X_i) \\] La dispersión total es la suma de las dispersiónes individuales si las variables son independientes. Varianza de la diferencia de variables aleatorias independientes Si \\(X\\) y \\(Y\\) son independientes: \\[ \\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) \\] Aunque se trata de una resta, las dispersiónes se suman si las variables son independientes, ya que la varianza mide magnitud, no dirección. Varianza de la suma si las variables NO son independientes En el caso general, si \\(X\\) y \\(Y\\) no son independientes, entonces: \\[ \\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2 \\cdot \\text{Cov}(X, Y) \\] La covarianza introduce un ajuste que depende de cómo se relacionan las variables. Si la covarianza es positiva, aumenta la varianza total; si es negativa, la reduce. Varianza de la diferencia de variables aleatorias NO independientes Si \\(X\\) y \\(Y\\) son variables aleatorias no independientes, entonces: \\[ \\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2 \\cdot \\text{Cov}(X, Y) \\] Cuando las variables no son independientes, la covarianza entre ellas afecta a la dispersión total. Si \\(\\text{Cov}(X, Y) &gt; 0\\) (tienden a variar en la misma dirección), la varianza de la diferencia disminuye. Si \\(\\text{Cov}(X, Y) &lt; 0\\) (tienden a variar en direcciones opuestas), la varianza de la diferencia aumenta. Esta propiedad es útil cuando se analizan diferencias entre medidas correlacionadas, como por ejemplo antes y después de una intervención. Varianza del producto de una constante y una suma de variables Si \\(X_1, \\dots, X_n\\) son variables aleatorias y \\(b\\) una constante: \\[ \\text{Var}\\left(b \\cdot \\sum_{i=1}^n X_i\\right) = b^2 \\cdot \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\] Este resultado utiliza la propiedad de cambio de escala. No se requiere independencia entre las variables. Si, además, las variables \\(X_i\\) son independientes, entonces: \\[ \\text{Var}\\left(b \\cdot \\sum_{i=1}^n X_i\\right) = b^2 \\cdot \\sum_{i=1}^n \\text{Var}(X_i) \\] 3.4 Variables aleatorias Bidimensionales En muchos problemas de probabilidad y estadística nos interesa estudiar simultáneamente dos variables aleatorias que pueden estar relacionadas. Por ejemplo, el número de productos vendidos y el beneficio obtenido, o el tiempo de servicio y el coste asociado. En estos casos hablamos de variables aleatorias bidimensionales o pares de variables aleatorias. 3.4.1 Variables aleatorias bidimensionales discretas Definición: Un par de variables aleatorias discretas es una función que asigna a cada resultado del espacio muestral un par ordenado de números reales. Sus valores posibles son combinaciones finitas o numerables de valores discretos. 3.4.1.1 Función de masa de probabilidad conjunta La función de masa de probabilidad conjunta se define como: \\[ p(x_i, y_j) = P(X = x_i, \\, Y = y_j)=f(x,y) \\] Esta función da la probabilidad de que \\(X\\) tome el valor \\(x_i\\) e \\(Y\\) tome el valor \\(y_j\\) simultáneamente. Para que la función de probabilidad conjunta sea tal, deben cumplirse las siguientes propiedades: Las probabilidades deben ser siempre nulas o positivas: \\[ p(x_i, y_j) \\ge 0 \\] La masa de probabilidad conjunta debe ser igual a la unidad: \\[ \\sum_i \\sum_j p(x_i, y_j) = 1 \\] 3.4.1.2 Funciones marginales Las funciones marginales de probabilidad de cada variable se obtienen sumando sobre los posibles valores de la otra variable: Función marginal de X: \\[ p_X(x_i) = \\sum_j p(x_i, y_j) \\] Función marginal de Y: \\[ p_Y(y_j) = \\sum_i p(x_i, y_j) \\] Nótese, que para obtener la distribución marginal de una variable, se agregan todos los posibles valores de la otra, obteniéndose valores que dependen exclusivamente de la variable para la que se calcula la marginal. Con un ejemplo se entenderá mejor. 3.4.1.3 Funciones de probabilidad condicionada Sea \\((X,Y)\\) una variable aleatoria bidimensional con función de probabilidad conjunta . Una de las formas de estudiar la relación entre ambas variables es a través de las probabilidades condicionadas. Si \\((X,Y)\\) es discreta, la probabilidad condicionada de que \\(X = x_i\\) dado que \\(Y = y_j\\) es: \\[ P(X = x_i \\mid Y = y_j) = \\frac{P(X = x_i,\\, Y = y_j)}{P(Y = y_j)} = \\frac{p_{ij}}{p_{\\cdot j}}, \\] donde: \\(p_{ij}\\) es la probabilidad conjunta \\(P(X = x_i,\\, Y = y_j)\\). \\(p_{\\cdot j} = \\sum_i p_{ij}\\) es la probabilidad marginal de \\(Y = y_j\\). De manera análoga: \\[ P(Y = y_j \\mid X = x_i) = \\frac{P(X = x_i,\\, Y = y_j)}{P(X = x_i)} = \\frac{p_{ij}}{p_{i \\cdot}}. \\] Estas probabilidades forman las distribuciones condicionadas de una variable dado el valor de la otra. Ejemplo de variables aleatorias discretas Imaginemos que tenemos dos variables aleatorias discretas: \\(X =\\) número de reclamaciones en el turno de mañana (puede ser 0 o 1). \\(Y =\\) número de reclamaciones en el turno de tarde (puede ser 0, 1 o 2). La función de masa conjunta (obtenida como frecuencias relativas o probabilidades) es: \\(Y=0\\) \\(Y=1\\) \\(Y=2\\) \\(p_X(x)\\) \\(X=0\\) 0.10 0.15 0.05 0.30 \\(X=1\\) 0.20 0.30 0.20 0.70 \\(p_Y(y)\\) 0.30 0.45 0.25 1.00 Interpretación de la tabla: Cada celda o intersección muestra la probabilidad conjunta \\(P(X = x_i, Y = y_j)\\). Las sumas por filas dan las probabilidades marginales de X, es decir, es como si sólo se tuviera una única variable X que no depende de Y. Las sumas por columnas dan las probabilidades marginales de Y, es decir, es como si sólo se tuviera una variable Y que no depende de X. La suma total es 1, es decir, el conjunto de todas las probabilidades es igual a 1. Cálculo de las marginales: Marginal de X: Para el cálculo de la marginal de X, se suma para cada uno de los valores posibles (0, 1), los datos de Y. \\[ p_X(0) = 0.10 + 0.15 + 0.05 = 0.30 \\] \\[ p_X(1) = 0.20 + 0.30 + 0.20 = 0.70 \\] Marginal de Y: Igual que X, pero en ese caso para Y. \\[ p_Y(0) = 0.10 + 0.20 = 0.30 \\] \\[ p_Y(1) = 0.15 + 0.30 = 0.45 \\] \\[ p_Y(2) = 0.05 + 0.20 = 0.25 \\] Comprobación: La suma de todas las probabilidades es igual a la unidad. Esto se puede obtener o sumando cada una de las marginales o sumando el conjunto de probabilidades conjuntas. \\[ \\sum_x \\sum_y p(x,y) = 1.00 \\] La probabilidad condicionada de un valor de \\(X\\) dado un valor de \\(Y\\) se calcula como: \\[ P(X = x_i \\mid Y = y_j) = \\frac{P(X = x_i, Y = y_j)}{P(Y = y_j)}. \\] Por ejemplo: Probabilidad de que haya una reclamación en la mañana (\\(X=1\\)), sabiendo que en la tarde hubo exactamente una reclamación (\\(Y=1\\)): \\[ P(X=1 \\mid Y=1) = \\frac{P(X=1, Y=1)}{P(Y=1)} = \\frac{0.30}{0.45} = 0.6667. \\] Probabilidad de que en la tarde haya dos reclamaciones (\\(Y=2\\)), sabiendo que en la mañana hubo una reclamación (\\(X=1\\)): \\[ P(Y=2 \\mid X=1) = \\frac{P(X=1, Y=2)}{P(X=1)} = \\frac{0.20}{0.70} \\approx 0.2857. \\] Estas probabilidades muestran cómo el conocimiento de un suceso afecta la distribución de la otra variable. 3.4.2 Variables aleatorias bidimensionales continuas Definición: Un par de variables aleatorias continuas es aquel cuyas probabilidades se describen mediante una función de densidad conjunta. 3.4.2.1 Función de densidad conjunta La función de densidad conjunta \\(f(x,y)\\), al igual que en el caso discreto, satisface las siguientes propiedades: \\[ f(x,y) \\ge 0 \\] \\[ \\iint_{-\\infty}^{\\infty} f(x,y) \\, dx \\, dy = 1 \\] La probabilidad de que \\((X,Y)\\) tome valores dentro de un conjunto \\(A\\) es: \\[ P\\bigl((X,Y) \\in A\\bigr) = \\iint_A f(x,y)\\, dx\\, dy \\] 3.4.2.2 Funciones marginales Las densidades marginales se obtienen integrando la densidad conjunta respecto de la otra variable: Densidad marginal de X: Para obtener la marginal de X se integra respecto de Y. \\[ f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dy \\] Densidad marginal de Y: Para obtener la marginal de Y se integra respecto de X. \\[ f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dx \\] 3.4.2.3 Funciones de probabilidad condicionadas Si \\((X,Y)\\) es continua con función de densidad conjunta \\(f_{X,Y}(x,y)\\), la densidad condicionada de \\(X\\) dado \\(Y=y\\) es: \\[ f_{X \\mid Y}(x \\mid y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}, \\] donde: \\[ f_Y(y) = \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\,dx \\] es la densidad marginal de \\(Y\\). De forma simétrica: \\[ f_{Y \\mid X}(y \\mid x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}. \\] Estas densidades permiten calcular probabilidades y esperanzas condicionadas, y son la base para el estudio de la dependencia entre variables. Ejemplo de variables aleatorias bidimensionales continuas Consideremos el par de variables aleatorias continuas \\((X,Y)\\) con la siguiente función de densidad conjunta: \\[ f(x,y) = \\begin{cases} 4xy, &amp; 0 \\le x \\le 1,\\; 0 \\le y \\le 1 \\\\ 0, &amp; \\text{en otro caso} \\end{cases} \\] Verificación de que es una densidad (para verificarlo hay que comprobar que el conjunto de la masa de probabilidad sea igual a 1): \\[ \\int_{0}^{1}\\int_{0}^{1}4xy\\,dx\\,dy = 4 \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = 1. \\] Por tanto, es válida. Densidad marginal de X: \\[ f_X(x) = \\int_0^1 4xy\\,dy = 4x \\left[\\frac{y^2}{2}\\right]_0^1 = 4x \\cdot \\frac{1}{2} = 2x. \\] Densidad marginal de Y: \\[ f_Y(y) = \\int_0^1 4xy\\,dx = 4y \\left[\\frac{x^2}{2}\\right]_0^1 = 4y \\cdot \\frac{1}{2} = 2y. \\] La densidad condicionada de X dado que \\(Y=y\\) se define como: \\[ f_{X \\mid Y}(x \\mid y) = \\frac{f(x,y)}{f_Y(y)}. \\] Sustituimos: \\[ f_{X \\mid Y}(x \\mid y) = \\frac{4xy}{2y} = \\frac{4x}{2} = 2x. \\] Interpretación: Para cada valor fijo \\(y\\) entre 0 y 1, la distribución de \\(X\\) dado \\(Y=y\\) sigue una densidad independiente de y: \\[ f_{X \\mid Y}(x \\mid y) = 2x, \\quad 0 \\le x \\le 1. \\] La densidad condicionada de Y dado que \\(X=x\\) es: \\[ f_{Y \\mid X}(y \\mid x) = \\frac{f(x,y)}{f_X(x)}. \\] Sustituyendo: \\[ f_{Y \\mid X}(y \\mid x) = \\frac{4xy}{2x} = \\frac{4y}{2} = 2y. \\] Interpretación: Para cada valor fijo \\(x\\) entre 0 y 1, la distribución de \\(Y\\) dado \\(X=x\\) también es independiente de \\(x\\): \\[ f_{Y \\mid X}(y \\mid x) = 2y, \\quad 0 \\le y \\le 1. \\] Vamos a representar gráficamente el soporte y las marginales. Vamos a calcular la propabilidad de que \\(X \\le 0.5\\) y \\(Y \\le 0.5\\): Queremos calcular: \\[ P(X \\le 0.5, \\, Y \\le 0.5) = \\int_{0}^{0.5}\\int_{0}^{0.5}4xy\\,dx\\,dy. \\] Caclulamos paso a paso: Primero integramos respecto a \\(x\\): \\[ \\int_0^{0.5} 4y \\left[ \\frac{x^2}{2} \\right]_0^{0.5} dy = \\int_0^{0.5} 4y \\cdot \\frac{(0.5)^2}{2} \\,dy. \\] Recalculamos dentro de la integral: \\[ \\frac{(0.5)^2}{2} = \\frac{0.25}{2} = 0.125. \\] Por tanto: \\[ \\int_0^{0.5} 4y \\cdot 0.125 \\,dy = \\int_0^{0.5} 0.5y \\,dy. \\] Integramos respecto a \\(y\\): \\[ 0.5 \\left[ \\frac{y^2}{2} \\right]_0^{0.5} = 0.5 \\cdot \\frac{(0.5)^2}{2} = 0.5 \\cdot \\frac{0.25}{2} = 0.5 \\times 0.125 = 0.0625. \\] Por lo que \\[ P(X \\le 0.5, \\, Y \\le 0.5) = 0.0625. \\] 3.4.3 Independencia de variables aleatorias bidimensionales Dos variables aleatorias \\(X\\) y \\(Y\\) son independientes si conocer el valor de una de ellas no aporta ninguna información sobre la distribución de la otra. En términos de las funciones de probabilidad condicionada, esto significa que, para todo \\(x\\) y \\(y\\): \\[ P(X = x \\mid Y = y) = P(X = x) \\] \\[ P(Y = y \\mid X = x) = P(Y = y) \\] Es decir, la probabilidad de que \\(X\\) tome el valor \\(x\\) no depende del valor que tome \\(Y\\), y viceversa. Definición formal: Variables discretas: \\(X\\) y \\(Y\\) son independientes si, para todos los valores posibles \\(x_i\\) y \\(y_j\\), se cumple: \\[ P(X = x_i,\\, Y = y_j) = P(X = x_i)P(Y = y_j) \\] Es decir, la probabilidad conjunta es igual al producto de las marginales. Variables continuas: \\(X\\) y \\(Y\\) son independientes si, para todo par \\((x,y)\\), se cumple: \\[ f(x,y) = f_X(x)\\,f_Y(y), \\] donde: \\(f(x,y)\\) es la densidad conjunta. \\(f_X(x)\\) y \\(f_Y(y)\\) son las densidades marginales. En este sentido, las consecuencias de la independencia son: La distribución condicionada de una variable dado un valor de la otra coincide con su distribución marginal. Por ejemplo: \\[ P(X = x_i \\mid Y = y_j) = P(X = x_i). \\] o, en el caso continuo: \\[ f_{X \\mid Y}(x \\mid y) = f_X(x). \\] Las variables no presentan ninguna forma de dependencia estadística. Por tanto, si \\(X\\) y \\(Y\\) son independientes, conocer \\(Y\\) no cambia la probabilidad ni la densidad de \\(X\\), y viceversa. 3.5 Momentos de variables aleatorias bidimensionales Los momentos bidimensionales permiten describir características de la distribución conjunta de dos variables aleatorias continuas o discretas \\((X, Y)\\). Al igual que en el caso unidimensional, son herramientas fundamentales para calcular medias, varianzas, covarianza y otras medidas. Con caracter general, los momestos respecto del origen y la media se definen como: Momentos respecto del origen: \\(\\alpha_{rs} = E\\bigl(X^r \\, Y^s\\bigr)\\), Momentos respecto de la media: \\(\\mu_{rs} = E\\Bigl[(X - \\alpha_{10})^r \\,(Y - \\alpha_{01})^s\\Bigr]\\) 3.5.1 Momentos respecto al origen Momentos respecto al origen para distribuciones discretas: El momento de orden \\((r,s)\\) respecto al origen es: \\[ \\alpha_{rs} = \\sum_i \\sum_j x_i^r \\, y_j^s \\, p_{ij}, \\] donde \\(p_{ij}\\) es la probabilidad conjunta \\(P(X = x_i, Y = y_j)\\). Momentos respecto al origen para distribuciones continuas: \\[ \\alpha_{rs} = \\iint_{-\\infty}^{\\infty} x^r \\, y^s \\, f(x,y) \\, dx \\, dy, \\] donde \\(f(x,y)\\) es la densidad conjunta. Los momentos más habituales son: De primer orden: \\(\\alpha_{10} = E(X)\\) (media de \\(X\\)) \\(\\alpha_{01} = E(Y)\\) (media de \\(Y\\)) De segundo orden: \\(\\alpha_{20} = E(X^2)\\) \\(\\alpha_{02} = E(Y^2)\\) \\(\\alpha_{11} = E(X \\, Y)\\) 3.5.2 Momentos respecto a la media Los momentos centrales o momentos respecto a la media permiten medir la variabilidad y la relación entre \\(X\\) y \\(Y\\). Momentos respecto a la media para distribuciones discretas: \\[ \\mu_{rs} = \\sum_i \\sum_j \\bigl(x_i - \\alpha_{10}\\bigr)^r \\,\\bigl(y_j - \\alpha_{01}\\bigr)^s \\,p_{ij} \\] Momentos respecto a la media para distribuciones continuas: \\[ \\mu_{rs} = \\iint_{-\\infty}^{\\infty}\\bigl(x - \\alpha_{10}\\bigr)^r \\,\\bigl(y - \\alpha_{01}\\bigr)^s \\,f(x,y)\\, dx\\, dy \\] Los momentos respecto a la media más frecuentes son: De primer orden: \\(\\mu_{10}=0\\) \\(\\mu_{01}=0\\) De segundo orden: \\(\\mu_{20} = Var(X) = \\sigma_X^2\\) \\(\\mu_{02} = Var(Y) = \\sigma_Y^2\\) \\(\\mu_{11} = Cov(X,Y)=\\sigma_{XY}\\) Cálculo de varianzas y covarianza a partir de los momentos respecto al origen Las varianzas marginales de \\(X\\) y \\(Y\\) se obtienen como: \\[ \\sigma_X^2 = Var(X) = E(X^2) - \\bigl[E(X)\\bigr]^2 = \\alpha_{20} - \\alpha_{10}^2 \\] \\[ \\sigma_Y^2 = Var(Y) = E(Y^2) - \\bigl[E(Y)\\bigr]^2 = \\alpha_{02} - \\alpha_{01}^2 \\] La covarianza puede calcularse a partir de: \\[ \\sigma_{XY} = Cov(X,Y) = E(X\\,Y) - E(X)\\,E(Y) = \\alpha_{11} - \\alpha_{10}\\,\\alpha_{01} \\] "],["discr.html", "Tema 4 Modelos de probabilidad discretos 4.1 Distribución uniforme discreta \\((U_d)\\) 4.2 Distribución Bernoulli \\((B(1, p))\\) 4.3 Distribución binomial \\((B(n, p))\\) 4.4 Distribución binomial negativa \\((BN(r, p))\\) 4.5 Distribución Poisson \\((\\text{Poisson}(\\lambda))\\) 4.6 Distribución geométrica \\((G(p))\\) 4.7 Distribución hipergeométrica \\((H(N, K, n))\\) 4.8 Distribución multinomial \\((M(n; {p_i}))\\) 4.9 Resumen de las distribuciones discretas 4.10 Funciones disponibles en R para funciones discretas", " Tema 4 Modelos de probabilidad discretos Uno de los principales objetivos del Cálculo de Probabilidades es construir modelos teóricos que representen de forma adecuada el comportamiento de fenómenos aleatorios observables en la realidad. Estos modelos permiten al científico simular situaciones, analizar comportamientos complejos y formular predicciones que, de otro modo, serían difíciles o imposibles de estudiar directamente. Modelizar lo observable no solo responde a una necesidad científica básica, sino que constituye una herramienta fundamental para entender y explicar el entorno que nos rodea, aunque ello implique necesariamente una simplificación de la realidad. En este tema nos centraremos en el estudio de los modelos de probabilidad discretos, es decir, aquellos que describen situaciones en las que las variables aleatorias solo pueden tomar un número finito o numerable de valores posibles. Comprender estos modelos es esencial porque proporcionan una base sólida para analizar fenómenos tan variados como el número de llamadas que recibe un centro de atención, el resultado de experimentos repetidos o los patrones de demanda en un sistema económico. Estudiar sus propiedades, estructura y aplicaciones nos permitirá no solo interpretar correctamente situaciones aleatorias, sino también tomar decisiones informadas en contextos reales basados en incertidumbre. Este documento desarrolla los casos prácticos de cada distribución discreta, con teoría, ejemplos aplicados al ámbito económico-empresarial y ejercicios resueltos, acompañados de código en R. El objetivo es proporcionar una herramienta completa que permita al alumno no solo comprender los fundamentos teóricos de cada modelo, sino también aplicarlos a problemas reales que surgen en el análisis de datos económicos, financieros o empresariales. 4.1 Distribución uniforme discreta \\((U_d)\\) Una variable aleatoria discreta sigue una distribución uniforme discreta cuando puede tomar un número finito de valores distintos, todos ellos con la misma probabilidad. Es decir, cada uno de los posibles valores es equiprobable. Esta distribución representa situaciones en las que no existe preferencia por ningún resultado en particular, y todos los resultados posibles son igualmente probables. ¿Para qué sirve? Se utiliza cuando todos los resultados son igualmente probables. En el contexto de empresa, sirve para modelar sorteos, selección aleatoria de clientes, o cualquier proceso donde no hay sesgo hacia ningún resultado. Teoría: Sea \\(X\\) una variable aleatoria discreta que toma \\(n\\) valores distintos: {\\(x_1, x_2, ..., x_n\\)} con igual probabilidad. Se denota que la variable aleatoria \\(X\\) sigue una distribución uniforme de la siguiente manera \\[ X \\sim \\mathcal{U}\\_d(x_1, x_2, \\dots, x_n) \\] o bien, si los valores son enteros consecutivos entre dos extremos: \\[ X \\sim \\mathcal{U}_d(a, b) \\] donde \\(a\\) y \\(b\\) son enteros, y \\(X\\) puede tomar cualquier valor en el conjunto \\(\\{a, a+1, \\dots, b\\}\\) con igual probabilidad. En esta caso, su función de cuantía será: \\[ P(X = x_i) = \\frac{1}{n}, \\\\ i = 1, 2, ..., n. \\] y su función de distribución (que representa la probabilidad acumulada) es: \\[ F(x_k) = P(X \\leq x_k) = \\sum_{i=1}^{k} \\frac{1}{n} = \\frac{k}{n} \\] Esto da lugar a una función escalonada, que puede expresarse como: \\[ F(x) = \\begin{cases} 0 &amp; \\text{si } x &lt; x_1 \\\\\\\\ \\frac{1}{n} &amp; \\text{si } x_1 \\leq x &lt; x_2 \\\\\\\\ \\frac{2}{n} &amp; \\text{si } x_2 \\leq x &lt; x_3 \\\\\\\\ \\vdots &amp; \\vdots \\\\\\\\ \\frac{k}{n} &amp; \\text{si } x_k \\leq x &lt; x_{k+1} \\\\\\\\ \\vdots &amp; \\vdots \\\\\\\\ 1 &amp; \\text{si } x \\geq x_n \\end{cases} \\] Parámetros fundamentales: - \\(n\\): número de posibles valores de la variable (positivo y entero). Momentos: - Media: \\(E(X) = \\frac{n + 1}{2}\\) - Varianza: \\(Var(X) = \\frac{n^2 - 1}{12}\\) Ejercicio: Se lanza un dado de 8 caras. ¿Cuál es la probabilidad de que salga un número menor o igual a 3? Calcula su media y su varianza. Solución: - Probabilidad de obtener un número menor o igual a 3 Hay 3 resultados favorables: \\(\\{1, 2, 3\\}\\), de un total de 8 posibles. Por tanto: \\[ P(X \\leq 3) = \\frac{3}{8} = 0{,}375 \\] - Esperanza matemática La esperanza de una distribución uniforme discreta sobre \\(n\\) valores es: \\[ E(X) = \\frac{n + 1}{2} = \\frac{8 + 1}{2} = \\frac{9}{2} = 4{,}5 \\] - Varianza La varianza se calcula con la fórmula: \\[ V(X) = \\frac{n^2 - 1}{12} = \\frac{8^2 - 1}{12} = \\frac{63}{12} = 5{,}25 \\] Ejemplo en R: Consideremos un dado perfecto o justo, en el que la probabilidad de que salga cualquiera de sus caras es igual a \\(\\frac{1}{6}\\). Determínese la esperanza y la varianza de los posibles resultados que se pueden obtener. La variable aleatoria \\(X\\) puede tomar los valores \\(\\{1, 2, 3, 4, 5, 6\\}\\), todos ellos con probabilidad \\(\\frac{1}{6}\\). Por tanto, puede modelizarse mediante una distribución uniforme discreta. Resolución: # Probabilidad de obtener más de 4 n_caras &lt;- 6 prob_mayor_4 &lt;- length(5:6) / n_caras prob_mayor_4 ## [1] 0.3333333 # Media y varianza media &lt;- (n_caras + 1) / 2 varianza &lt;- (n_caras^2 - 1) / 12 media ## [1] 3.5 varianza ## [1] 2.916667 4.2 Distribución Bernoulli \\((B(1, p))\\) Una variable aleatoria discreta sigue una distribución de Bernoulli, es decir, \\(\\text{Binomial}(1, p)\\), cuando modela una situación en la que se realiza un único experimento aleatorio con dos posibles resultados complementarios, a los que comúnmente se denomina éxito y fracaso,. ¿Para qué sirve? Es muy habitual encontrar situaciones en las que se encuentre esta distribución ya que modela experimentos de tipo éxito/fracaso. Ejemplos típicos en empresa serían si un cliente hace o no una compra, si una campaña publicitaria logra o no un clic, si una pieza sale defectuosa o no, etc. Teoría: Una variable aleatoria discreta \\(X\\) sigue una distribución de Bernoulli de parámetro \\(p\\), con \\(0 &lt; p &lt; 1\\), si toma únicamente los valores 0 y 1, que representan dos resultados complementarios de un único experimento aleatorio \\[ X = \\begin{cases} 1 &amp; \\text{con probabilidad } p \\\\ 0 &amp; \\text{con probabilidad } 1 - p \\end{cases} \\] Se denota como: \\[ X \\sim \\text{Bernoulli}(p) \\quad \\text{o bien} \\quad X \\sim \\text{Binomial}(1, p) \\] Resumiendo la información Valor de \\(X\\) Probabilidad \\(0\\) \\(1 - p\\) \\(1\\) \\(p\\) De este modo, la función de cuantía o de probabilidad de \\(X\\) es: \\[ f(x) = P(X = x) = \\begin{cases} p &amp; \\text{si } x = 1 \\\\\\\\ 1 - p &amp; \\text{si } x = 0 \\\\\\\\ 0 &amp; \\text{en otro caso} \\end{cases} \\] También puede escribirse de forma compacta como: \\[ f(x)=P(X = x) = p^x (1 - p)^{1 - x}, \\quad \\text{para } x \\in \\{0, 1\\} \\] Y la Función de Distribución o probabilidad acumulada \\(F(x) = P(X \\leq x)\\) es: \\[ F(x) = \\begin{cases} 0 &amp; \\text{si } x &lt; 0 \\\\\\\\ 1 - p &amp; \\text{si } 0 \\leq x &lt; 1 \\\\\\\\ 1 &amp; \\text{si } x \\geq 1 \\end{cases} \\] Parámetros fundamentales: \\(p \\in [0,1]\\): probabilidad de éxito. - \\(q = 1 - p\\): probabilidad de fracaso. Momentos: - Media: \\(E(X) = p\\) - Varianza: \\(Var(X) = p(1 - p)\\) Ejercicio: La probabilidad de que un cliente compre un producto tras recibir una oferta comercial es 0,3. Determínese la media y la varianza de esta variable, y la probabilidad de que el cliente no realice la compra. Dado que el fenómeno presenta dos posibles resultados —compra (C) o no compra (NC)—, se puede modelizar mediante una distribución binomial de un solo ensayo, es decir, \\(B(1; 0,3)\\), donde: \\[ P(C) = P(X = 1) = p = 0{,}3 \\\\ P(NC) = P(X = 0) = q = 1 - p = 0{,}7 \\] La esperanza y la varianza de esta variable son: \\[ E(X) = p = 0{,}3 \\\\ V(X) = p \\cdot q = 0{,}3 \\cdot 0{,}7 = 0{,}21 \\] Ejemplo en R: Simulación Supongamos que la probabilidad de que un usuario haga clic en un anuncio es del 15 % (es decir, \\(p = 0{,}15\\)). Esta situación se puede modelizar con una variable aleatoria de Bernoulli, donde el valor 1 (éxito) representa que el usuario hace clic y el valor 0 (fracaso) que no lo hace. Vamos a simular el comportamiento de 10 individuos y posteriormente compararlo con el valor teórico o esperado. Para realizar esa simulación del comportamiento de 10 usuarios utilizamos la función rbinom() de R, y comparamos los resultados empíricos (media y varianza observadas) con los valores teóricos esperados: set.seed(123) resultados &lt;- rbinom(10, size = 1, prob = 0.15) resultados ## [1] 0 0 0 1 1 0 0 1 0 0 # Media y varianza empíricas media_empirica &lt;- mean(resultados); media_empirica ## [1] 0.3 var_empirica &lt;- var(resultados); var_empirica ## [1] 0.2333333 # Valores teóricos p &lt;- 0.15 media_teorica &lt;- p var_teorica &lt;- p * (1 - p) media_teorica ## [1] 0.15 var_teorica ## [1] 0.1275 dif_media &lt;- media_empirica-media_teorica; dif_media ## [1] 0.15 dif_var &lt;- var_empirica-var_teorica; dif_var ## [1] 0.1058333 4.3 Distribución binomial \\((B(n, p))\\) Una variable aleatoria \\(X\\) sigue una distribución binomial con parámetros \\(n\\) y \\(p\\), que se denota como \\(X \\sim B(n; p)\\), cuando puede expresarse como la suma de \\(n\\) variables aleatorias independientes e idénticamente distribuidas según una distribución de Bernoulli \\(B(1, p)\\), es decir: \\[ X = X_1 + X_2 + \\cdots + X_n \\quad \\text{con} \\quad X_i \\overset{\\text{iid}}{\\sim} B(1; p) \\] Desde un punto de vista conceptual, la distribución \\(B(n; p)\\) modeliza situaciones en las que un mismo experimento aleatorio dicotómico (con dos posibles resultados: éxito o fracaso) se repite \\(n\\) veces bajo condiciones de independencia entre ensayos. Dado que cada variable \\(X_i\\) puede tomar solo los valores 0 o 1, la variable total \\(X\\), que cuenta cuántos éxitos se han producido, puede tomar cualquier valor entero desde 0 (si todos los ensayos resultan en fracaso) hasta \\(n\\) (si todos los ensayos resultan en éxito). Por tanto, el rango de \\(X\\) es: \\[ X \\in \\{0, 1, 2, \\dots, n\\} \\] Al codificar el resultado “éxito” como 1 y “fracaso” como 0, si la variable aleatoria \\(X\\) toma el valor 3, significa que en las \\(n\\) repeticiones se ha producido el suceso de interés 3 veces y su complementario \\(n - 3\\) veces. De este modo, \\(X\\) funciona como una variable contadora del número de éxitos obtenidos en \\(n\\) ensayos independientes, cada uno con probabilidad de éxito \\(p\\). ¿Para qué sirve? La distribución binomial es una herramienta fundamental en la modelización de fenómenos aleatorios dicotómicos, es decir, aquellos en los que solo pueden ocurrir dos resultados mutuamente excluyentes (por ejemplo, éxito o fracaso, compra o no compra, impago o pago, etc.). Su principal uso es contar el número de veces que ocurre un determinado resultado (denominado éxito) en un número fijo de repeticiones independientes de un mismo experimento aleatorio, cuando la probabilidad de éxito se mantiene constante en cada ensayo. En el ámbito económico y de la empresa, la distribución binomial es especialmente útil para modelar situaciones como: Análisis de campañas de marketing, donde se cuenta cuántos clientes responden positivamente a una promoción, sabiendo que cada uno tiene una probabilidad conocida de hacerlo. Control de calidad, para calcular la probabilidad de que un lote contenga un cierto número de productos defectuosos. Estudios de mercado, donde se estima el número de consumidores que prefieren una marca entre varios entrevistados. Gestión del riesgo financiero, al modelar el número de impagos entre una cartera de créditos, cuando la probabilidad de impago es conocida y constante. Evaluación del rendimiento de ventas, como el número de cierres exitosos entre un número determinado de visitas comerciales. Toma de decisiones con incertidumbre, al predecir resultados binarios en contextos repetidos como la aceptación/rechazo de propuestas o la ocurrencia de eventos adversos. Su simplicidad, interpretabilidad y aplicabilidad la convierten en una de las distribuciones más utilizadas en análisis de datos y en procesos de toma de decisiones bajo incertidumbre. Teoría: Una variable aleatoria discreta \\(X\\) se dice que sigue una distribución binomial con parámetros \\(n\\) y \\(p\\) si representa el número de éxitos obtenidos en \\(n\\) ensayos independientes, cada uno con probabilidad de éxito \\(p\\). Se denota: \\[ X \\sim B(n, p) \\] donde: \\(n \\in \\mathbb{N}\\) es el número de ensayos (experimentos independientes), \\(p \\in (0,1)\\) es la probabilidad de éxito en cada ensayo, \\(X \\in \\{0, 1, 2, \\dots, n\\}\\) representa el número total de éxitos. La función de cuantía o función de probabilidad de la distribución binomial está dada por: \\[ P(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x}, \\quad \\text{para } x = 0, 1, 2, \\dots, n \\] donde: \\(\\binom{n}{x}\\) es el coeficiente binomial, que cuenta el número de formas de obtener \\(x\\) éxitos en \\(n\\) ensayos, \\(p^k\\) representa la probabilidad de obtener \\(k\\) éxitos, \\((1 - p)^{n - x}\\) representa la probabilidad de obtener \\(n - x\\) fracasos. Esta fórmula permite calcular la probabilidad exacta de observar \\(x\\) éxitos en una secuencia de \\(n\\) ensayos independientes con igual probabilidad de éxito. ¿Cómo se llega a esta función de cuantía? La función de cuantía de una variable aleatoria binomial permite calcular la probabilidad de obtener exactamente \\(x\\) éxitos en \\(n\\) ensayos independientes, cada uno con probabilidad de éxito \\(p\\) y de fracaso \\(q = 1 - p\\). Supongamos que realizamos \\(n\\) repeticiones de un experimento aleatorio. Si en \\(x\\) de esas repeticiones se obtiene el resultado deseado (éxito), y en las \\(n - x\\) restantes se obtiene el complementario (fracaso), la probabilidad de esa secuencia concreta es: \\[ \\underbrace{p \\cdot p \\cdot \\dots \\cdot p}_{x \\text{ veces}} \\cdot \\underbrace{q \\cdot q \\cdot \\dots \\cdot q}_{n - x \\text{ veces}} = p^x q^{n - x} \\] Pero esa es solo una de muchas formas posibles de obtener \\(x\\) éxitos y \\(n - x\\) fracasos. Como el orden no importa, debemos contar cuántas disposiciones distintas pueden formarse con \\(x\\) éxitos y \\(n - x\\) fracasos. Esa cantidad viene dada por el coeficiente binomial: \\[ \\binom{n}{x} = \\frac{n!}{x!(n - x)!} \\] Esto representa el número de formas distintas en que podemos elegir \\(x\\) posiciones para los éxitos (valor 1) entre los \\(n\\) ensayos. De este modo, la probabilidad total de obtener exactamente \\(x\\) éxitos en \\(n\\) ensayos es la función de cuantía previa. Parámetros fundamentales: - \\(n\\): número de ensayos. - \\(p\\): probabilidad de éxito. Momentos: - Media: \\(E(X) = n p\\) - Varianza: \\(Var(X) = n p (1 - p)\\) Propiedad aditiva o reproductiva de la distribución binomial La distribución binomial es reproductiva respecto al parámetro \\(n\\). Esta propiedad establece que la suma de variables aleatorias independientes, cada una con distribución binomial y el mismo parámetro de éxito \\(p\\), también sigue una distribución binomial. Formalmente, si: \\[ X \\sim B(n_1, p), \\quad Y \\sim B(n_2, p), \\quad \\text{y} \\quad X \\perp Y \\] entonces: \\[ X + Y \\sim B(n_1 + n_2, p) \\] Esta propiedad puede generalizarse a un número finito de variables binomiales independientes que compartan el mismo parámetro de probabilidad \\(p\\). La explicación de esta propiedad se encuentra en la definición estructural de la binomial: una variable aleatoria \\(X \\sim B(n, p)\\) puede construirse como la suma de\\(n\\) variables aleatorias independientes e idénticamente distribuidas según una distribución de Bernoulli\\(B(1, p)\\): \\[ X = \\sum_{i=1}^{n} \\xi_i, \\quad \\text{con } \\xi_i \\overset{\\text{iid}}{\\sim} B(1, p) \\] Dado que la suma de variables Bernoulli independientes con parámetro \\(p\\) genera una binomial, resulta inmediato que la suma de dos (o más) variables binomiales independientes, cada una como suma de variables Bernoulli independientes, también sigue una distribución binomial, con número total de ensayos igual a la suma de los ensayos de las variables originales. Ejercicios resueltos: Ejercicio 1: Inspección de productos Un inspector revisa 12 productos. La probabilidad de que un producto sea defectuoso es \\(p = 0.1\\). Se pide: a. Calcular la probabilidad de que exactamente 2 productos sean defectuosos. b. Determinar la media y la varianza del número de productos defectuosos. Solución: La variable aleatoria que cuenta el número de defectuosos se modeliza como: \\[ X \\sim B(12, 0.1) \\] Probabilidad de que\\(X = 2\\): \\[ P(X = 2) = \\binom{12}{2} \\cdot 0.1^2 \\cdot 0.9^{10} = 66 \\cdot 0.01 \\cdot 0.3487 \\approx 0.2301 \\] Media y varianza: \\[ \\mathbb{E}(X) = 12 \\cdot 0.1 = 1.2 \\\\ \\operatorname{Var}(X) = 12 \\cdot 0.1 \\cdot 0.9 = 1.08 \\] Ejercicio 2: Campaña de ventas en dos regiones Una empresa lanza una campaña de ventas en dos regiones. En la Región A, se contacta a 10 clientes potenciales; en la Región B, a 15 clientes. La probabilidad de que un cliente realice una compra tras el contacto es \\(p = 0.4\\), y se asume que las decisiones de los clientes son independientes. Se pide: a. Determinar la distribución del número total de compras realizadas en ambas regiones. b. Calcular la esperanza y la varianza del número total de compras. Solución: Sea: \\[ X \\sim B(10, 0.4), \\quad Y \\sim B(15, 0.4) \\] el número de compras en cada región. Como las variables son independientes y tienen el mismo valor de \\(p\\), por la propiedad de reproductividad de la binomial, se tiene que: \\[ Z = X + Y \\sim B(25, 0.4) \\] Esperanza: \\[ E(Z) = 25 \\cdot 0.4 = 10 \\] Varianza: \\[ \\operatorname{Var}(Z) = 25 \\cdot 0.4 \\cdot 0.6 = 6 \\] Esto significa que, en promedio, se esperan 10 compras en total, con una variabilidad medida por la varianza de 6 (una variabilidad baja). Ejercicio en R: Inspección de productos con defectos Se inspeccionan 15 productos y la probabilidad de que un producto sea defectuoso es del 5 % (\\(p = 0.05\\)). Vamos a calcular: La probabilidad de que haya exactamente 3 productos defectuosos. La probabilidad de que haya más de 4 productos defectuosos. La media y la varianza de la variable aleatoria \\(X \\sim B(15, 0.05)\\), que cuenta el número de defectuosos. # Parámetros n &lt;- 15 p &lt;- 0.05 # a) Probabilidad de que haya exactamente 3 defectuosos prob_3_defectuosos &lt;- dbinom(3, size = n, prob = p) prob_3_defectuosos ## [1] 0.03073298 # b) Probabilidad de que haya más de 4 defectuosos: P(X &gt; 4) = 1 - P(X &lt;= 4) prob_mas_4_defectuosos &lt;- 1 - pbinom(4, size = n, prob = p) prob_mas_4_defectuosos ## [1] 0.0006146829 # c) Media y varianza media &lt;- n * p varianza &lt;- n * p * (1 - p) media ## [1] 0.75 varianza ## [1] 0.7125 4.4 Distribución binomial negativa \\((BN(r, p))\\) Supongamos que realizamos un experimento de Bernoulli (con dos posibles resultados: éxito o fracaso) de forma repetida hasta alcanzar un número fijo de éxitos, denotado por \\(r\\). Definimos la variable aleatoria \\(X\\) como el número de fracasos que se producen antes de lograr el éxito número \\(r\\). En este contexto, decimos que: \\[ X \\sim \\operatorname{BN}(r, p) \\] donde: \\(r \\in \\mathbb{N}\\) es el número de éxitos deseados, \\(p \\in (0,1)\\) es la probabilidad de éxito en cada ensayo, \\(X \\in \\{0, 1, 2, \\dots\\}\\) representa el número de fracasos antes de lograr el \\(r\\)-ésimo éxito. Esta distribución modeliza procesos donde el experimento se repite hasta alcanzar \\(r\\) éxitos, y nos interesa contar cuántos fracasos ocurren hasta ese momento (alcanzar el éxito). ¿Para qué sirve? La distribución binomial negativa se emplea cuando se desea modelar el número de fracasos necesarios para alcanzar un número fijo de éxitos en experimentos de Bernoulli independientes, donde la probabilidad de éxito se mantiene constante. A diferencia de la distribución binomial clásica, donde se fija el número de ensayos y se cuenta cuántos éxitos se obtienen, en la binomial negativa se fija el número de éxitos y se deja que el número de ensayos (y por tanto de fracasos) varíe. Esta distribución resulta útil en distintos contextos, como por ejemplo: Marketing y ventas: número de contactos fallidos hasta lograr un número determinado de ventas. Atención al cliente: número de intentos fallidos antes de resolver satisfactoriamente \\(r\\) casos. Recursos humanos: número de entrevistas no satisfactorias antes de contratar a \\(r\\) personas adecuadas. Control de calidad: número de piezas defectuosas producidas antes de encontrar \\(r\\) unidades sin defecto. Finanzas y riesgo: número de inversiones fallidas antes de lograr  operaciones rentables. En todos estos casos, el interés está en cuántos intentos fallidos ocurren antes de conseguir un número de éxitos definidos, lo cual es clave en análisis de costos, eficiencia y planificación. Teoría: En este caso, la función de cuantía (función de probabilidad) es: \\[ P(X = x) = \\binom{x + r - 1}{x} \\cdot p^r \\cdot (1 - p)^x, \\quad x = 0, 1, 2, \\dots \\] Esta fórmula representa la probabilidad de que se observen exactamente \\(x\\) fracasos antes de que ocurra el éxito número \\(r\\), sin importar el orden en que ocurren los fracasos y los éxitos intermedios. ¿Cómo se construye la función de cuantía? Suponiendo que denotamos a \\(A\\) como éxito y \\(A^*\\) fracaso. Queremos calcular la probabilidad de que ocurran exactamente \\(x\\) fracasos antes de que se produzca el éxito número \\(r\\). El suceso que describe la variable aleatoria \\(X\\) se puede descomponer de la siguiente forma: Se producen \\(r - 1\\) éxitos en algún orden, \\(A, A, \\dots, A\\) Seguidos de \\(x\\) fracasos, \\(A^*, A^*, \\dots, A^*\\) Y finalmente el éxito número \\(r\\), que cierra el experimento, \\(A\\). Este patrón se representa como: \\[ \\underbrace{A, A, \\dots, A}_{r-1 \\text{ veces}}, \\quad \\underbrace{A^*, A^*, \\dots, A^*}_{x \\text{ veces}}, \\quad A \\] La probabilidad de esta secuencia concreta (un único orden específico) es: \\[ P(A, A, \\dots, A, A^*, A^*, \\dots, A^*, A) = p^{r-1} \\cdot q^x \\cdot p = p^r \\cdot q^x \\] Sin embargo, los \\(r - 1\\) éxitos y los \\(x\\) fracasos pueden ocurrir en cualquier orden antes del último éxito. Por tanto, necesitamos contar cuántas disposiciones distintas de esos \\(r - 1\\) éxitos y \\(x\\) fracasos existen en \\(x + r - 1\\) posiciones. Este número de disposiciones se calcula mediante permutaciones con repetición, que dan lugar al coeficiente binomial: \\[ \\binom{x + r - 1}{x} = \\frac{(x + r - 1)!}{x! \\cdot (r - 1)!} \\] Finalmente, multiplicamos este número de disposiciones por la probabilidad de cada una, obteniendo así la función de cuantía de la distribución binomial negativa: \\[ P(X = x) = \\binom{x + r - 1}{x} \\cdot p^r \\cdot q^x, \\quad \\text{para } x = 0, 1, 2, \\dots \\] Parámetros fundamentales: - \\(r\\): número de éxitos deseados. - \\(p\\): probabilidad de éxito. Momentos: - Media: \\(E(X) = r\\frac{q}{p}\\) - Varianza: \\(Var(X) = r\\frac{(1 - p)}{p^2}\\) Ejercicio resuelto: Un operador comercial realiza llamadas a clientes. La probabilidad de que una llamada termine en una venta es \\(p = 0.2\\). Se pide: a. Calcular la probabilidad de que el operador haga exactamente 4 llamadas sin éxito antes de conseguir su tercera venta. b. Calcular la esperanza y la varianza del número de fracasos antes de alcanzar 3 éxitos. Solución: Sea \\(X \\sim \\operatorname{BN}(r = 3, p = 0.2)\\). a. Queremos calcular \\(P(X = 4)\\). La función de cuantía es: \\[ P(X = x) = \\binom{x + r - 1}{x} \\cdot p^r \\cdot (1 - p)^x \\] Sustituyendo los valores: \\[ P(X = 4) = \\binom{6}{4} \\cdot (0.2)^3 \\cdot (0.8)^4 = 15 \\cdot 0.008 \\cdot 0.4096 \\approx 0.0492 \\] La probabilidad de que el operador realice exactamente 4 llamadas fallidas antes de conseguir su tercera venta es aproximadamente 0,0492, es decir, un 4,92 % b. Esperanza y varianza: Para una binomial negativa: - Esperanza: \\[ \\mathbb{E}(X) = \\frac{r(1 - p)}{p} = \\frac{3 \\cdot 0.8}{0.2} = 12 \\] Si este experimento se repitiera muchas veces (es decir, muchos operadores realizando llamadas en condiciones similares), el número medio de llamadas sin éxito antes de alcanzar la tercera venta tendería a ser 12. - Varianza: \\[ \\operatorname{Var}(X) = \\frac{r(1 - p)}{p^2} = \\frac{3 \\cdot 0.8}{0.04} = 60 \\] Ejercicio con R: Distribución binomial negativa Una empresa realiza encuestas telefónicas. La probabilidad de que una persona acepte responder la encuesta es \\(p = 0.25\\). ¿Cuál es la probabilidad de que se necesiten exactamente 5 rechazos antes de obtener la cuarta respuesta afirmativa? Calcula la esperanza y la varianza teóricas. Simula 10,000 repeticiones del experimento y compara los resultados empíricos. La variable aleatoria que cuenta el número de rechazos (fracasos) antes de obtener 4 éxitos se modeliza como: \\[ X \\sim \\operatorname{BN}(r = 4, p = 0.25) \\] # Parámetros r &lt;- 4 # número de éxitos deseados p &lt;- 0.25 # probabilidad de éxito x &lt;- 5 # número de fracasos #a. Probabilidad puntual prob_5_fallos &lt;- dnbinom(x, size = r, prob = p) prob_5_fallos ## [1] 0.0519104 #b. Esperanza y Varianza esperanza &lt;- r * (1 - p) / p varianza &lt;- r * (1 - p) / p^2 esperanza ## [1] 12 varianza ## [1] 48 #c. Simulación de 10,000 repeticiones set.seed(123) simulaciones &lt;- rnbinom(10000, size = r, prob = p) # Media y varianza empíricas mean(simulaciones) ## [1] 11.8066 var(simulaciones) ## [1] 46.39244 4.5 Distribución Poisson \\((\\text{Poisson}(\\lambda))\\) Una variable aleatoria \\(X\\) sigue una distribución de Poisson con parámetro \\(\\lambda &gt; 0\\), que se denota como: \\[ X \\sim \\text{Poisson}(\\lambda) \\] cuando modeliza el número de veces que ocurre un determinado suceso en un intervalo fijo de tiempo o espacio, siempre que: Los sucesos ocurren de forma independiente, La tasa media de ocurrencia \\(\\lambda\\) es constante en el tiempo o el espacio, No hay ocurrencias simultáneas (la probabilidad de más de un suceso en un instante infinitesimal es despreciable). Desde un punto de vista conceptual, la distribución de Poisson cuenta la cantidad de sucesos RAROS, discretos y aleatorios que ocurren en un intervalo determinado. Aunque, en teoría, una variable aleatoria con distribución de Poisson puede tomar cualquier valor natural, en la práctica las probabilidades de que adopte valores grandes disminuyen rápidamente a medida que estos crecen. Esto significa que, para un valor dado de \\(\\lambda\\), la mayor parte de la probabilidad se concentra en torno a unos pocos valores cercanos a la media, haciendo que tomar valores mucho mayores sea altamente improbable. Como consecuencia, la distribución de Poisson resulta especialmente útil para describir sucesos que, aunque posibles, tienen una baja probabilidad de ocurrencia en gran número dentro de un intervalo. Por este motivo, a la distribución de Poisson también se la conoce como la distribución de los sucesos raros. El valor de \\(\\lambda\\) representa tanto la media como la varianza del número de sucesos esperados en ese intervalo. El soporte de la variable aleatoria es: \\[ X \\in \\{0, 1, 2, \\dots\\} \\] ¿Para qué sirve? La distribución de Poisson es muy útil en la modelización de sucesos que: Ocurren de forma aleatoria en el tiempo o en el espacio, Son poco frecuentes o esporádicos, pero cuantificables. Las aplicaciones más habituales en economía y empresa Número de llamadas recibidas en un centro de atención por hora. Llegada de clientes a una tienda o entidad financiera. Número de errores de producción por lote o unidad de tiempo. Incidencias logísticas, como retrasos en entregas o fallos técnicos por día. Peticiones de préstamos o reclamaciones recibidas en un periodo fijo. Dado que solo requiere un parámetro \\(\\lambda\\), es una distribución muy versátil, especialmente útil cuando el número de oportunidades de que ocurra el suceso no está bien definido, pero sí su frecuencia media. Teoría Una variable aleatoria discreta \\(X\\) se dice que sigue una distribución de Poisson con parámetro \\(\\lambda &gt; 0\\) si: \\[ X \\sim \\text{Poisson}(\\lambda) \\] donde: \\(\\lambda\\): número medio de sucesos que se espera que ocurran en un intervalo de tiempo (o espacio), \\(X \\in \\{0, 1, 2, \\dots\\}\\): número de ocurrencias observadas. Función de cuantía La función de cuantía de la distribución de Poisson es: \\[ P(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\quad x = 0, 1, 2, \\dots \\] Esta fórmula representa la probabilidad de que ocurran exactamente \\(x\\) sucesos en un intervalo dado, cuando el número medio de ocurrencias es \\(\\lambda\\). Parámetros fundamentales - \\(\\lambda\\): número medio de ocurrencias del suceso en un intervalo (es la media y la varianza) Momentos Media: \\(E(X) = \\lambda\\) Varianza: \\(\\operatorname{Var}(X) = \\lambda\\) Propiedad aditiva o reproductiva de la Poisson Sean las variables aleatorias independientes \\(( X_1, X_2, \\dots, X_n )\\), tales que cada \\(( X_j )\\) sigue una distribución de Poisson con parámetro \\(( \\lambda_j )\\), es decir: \\[ X_j \\sim \\text{Poisson}(\\lambda_j) \\] Entonces, la suma de estas variables también sigue una distribución de Poisson. Definimos: \\[ Y = X_1 + X_2 + \\cdots + X_n \\] Por tanto, la variable \\(Y\\) también sigue una distribución de Poisson, con parámetro: \\[ \\lambda = \\sum_{j=1}^{n} \\lambda_j \\] y se concluye que: \\[ Y \\sim \\text{Poisson} \\left( \\sum_{j=1}^{n} \\lambda_j \\right) \\] Esta propiedad confirma que la distribución de Poisson es aditiva: la suma de variables independientes que siguen Poisson también es Poisson, siempre que los parámetros se sumen. Ejemplo de la propiedad aditiva de la Poisson Supongamos que en una empresa: El departamento A recibe, en promedio, 2 correos electrónicos por hora. El departamento B recibe, en promedio, 3 correos electrónicos por hora. Ambos procesos son independientes y se pueden modelar con variables aleatorias: \\[ X_1 \\sim \\text{Poisson}(2), \\quad X_2 \\sim \\text{Poisson}(3) \\] La variable \\(Y=X_1 + X_2\\) representa el número total de correos recibidos por ambos departamentos en una hora. ¿Cuál es la distribución de \\(X_1 + X_2\\)? Por la propiedad aditiva de la distribución de Poisson: \\[ Y=X_1 + X_2 \\sim \\text{Poisson}(2 + 3) = \\text{Poisson}(5) \\] Ejercicios resueltos: Distribución de Poisson Ejercicio 1: Número de reclamaciones Una aseguradora recibe, en promedio, 3 reclamaciones por día. ¿Cuál es la probabilidad de que en un día se reciban exactamente 5 reclamaciones? Solución: Modelamos la variable aleatoria con: \\[ X \\sim \\text{Poisson}(3) \\] La probabilidad de que se reciban exactamente 5 reclamaciones, utulizando la función de cuantía de la Poisson es: \\[ P(X = 5) = \\frac{3^5 \\cdot e^{-3}}{5!} = \\frac{243 \\cdot e^{-3}}{120} \\approx 0.1008 \\] En R: dpois(5, lambda = 3) ## [1] 0.1008188 Ejercicio 2: Probabilidad de más de 6 llamadas En una centralita telefónica se reciben, de media, 4 llamadas por hora. ¿Cuál es la probabilidad de que en una hora se reciban más de 6 llamadas? Solución: La variable aleatoria que representa el número de llamadas por hora se modeliza como: \\[ X \\sim \\text{Poisson}(4) \\] Queremos calcular: \\[ P(X &gt; 6) = 1 - P(X \\leq 6) \\] Primero calculamos \\(P(X \\leq 6)\\) sumando las probabilidades desde 0 hasta 6: \\[ P(X \\leq 6) = \\sum_{x = 0}^{6} \\frac{4^x e^{-4}}{x!} \\] Calculamos cada término (aproximado): \\[ \\begin{align*} P(X = 0) &amp;= \\frac{4^0 e^{-4}}{0!} = e^{-4} \\approx 0.0183 \\\\ P(X = 1) &amp;= \\frac{4^1 e^{-4}}{1!} = 4e^{-4} \\approx 0.0733 \\\\ P(X = 2) &amp;= \\frac{4^2 e^{-4}}{2!} = 8e^{-4} \\approx 0.1465 \\\\ P(X = 3) &amp;= \\frac{4^3 e^{-4}}{3!} = \\frac{64e^{-4}}{6} \\approx 0.1953 \\\\ P(X = 4) &amp;= \\frac{256e^{-4}}{24} \\approx 0.1953 \\\\ P(X = 5) &amp;= \\frac{1024e^{-4}}{120} \\approx 0.1563 \\\\ P(X = 6) &amp;= \\frac{4096e^{-4}}{720} \\approx 0.1042 \\\\ \\end{align*} \\] Sumamos: \\[ P(X \\leq 6) \\approx 0.0183 + 0.0733 + 0.1465 + 0.1953 + 0.1953 + 0.1563 + 0.1042 = 0.8892 \\] Entonces: \\[ P(X &gt; 6) = 1 - 0.8892 = 0.1108 \\] Resolución en R: # Parámetro de la Poisson lambda &lt;- 4 # Probabilidad de más de 6 llamadas prob_mas_6 &lt;- ppois(6, lambda = lambda, lower.tail = FALSE); prob_mas_6 ## [1] 0.110674 Ejercicio con R: Gestión de solicitudes de préstamos Un banco recibe, en promedio, 6 solicitudes de préstamo por hora a través de su plataforma online. Este número puede variar de hora en hora, pero se asume que las solicitudes llegan de forma independiente y a una tasa constante a lo largo del día. Por tanto, el número de solicitudes por hora se modeliza mediante una distribución de Poisson: \\[ X \\sim \\text{Poisson}(\\lambda = 6) \\] Se pide resolver con R las siguientes cuestiones: Calcular la probabilidad de que se reciban exactamente 8 solicitudes en una hora. Calcular la probabilidad de que se reciban como máximo 4 solicitudes en una hora. Calcular la probabilidad de que se reciban más de 10 solicitudes en una hora. Simular lo que ocurriría durante una jornada laboral de 7 horas. ¿Cuántas solicitudes se reciben en total? Simular 10.000 jornadas laborales para estimar: La media y la varianza empírica del número total de solicitudes por jornada, La proporción de jornadas en las que se reciben más de 50 solicitudes, lo que se considera un nivel de saturación operativa. # Parámetro por hora lambda &lt;- 6 #1. probabilidad de que se reciban exactamente 8 solicitudes en una hora prob_8 &lt;- dpois(8, lambda = lambda) prob_8 ## [1] 0.1032577 #2. probabilidad de que se reciban como máximo 4 solicitudes en una hora. prob_4_o_menos &lt;- ppois(4, lambda = lambda) prob_4_o_menos ## [1] 0.2850565 #3. probabilidad de que se reciban más de 10 solicitudes en una hora. prob_mas_10 &lt;- 1 - ppois(10, lambda = lambda) prob_mas_10 ## [1] 0.04262092 #4. Simular lo que ocurriría durante una jornada laboral de 7 horas. ¿Cuántas solicitudes se reciben en total? set.seed(123) # para reproducibilidad jornada &lt;- sum(rpois(7, lambda = lambda)) jornada ## [1] 45 #5 Simular 10.000 jornadas laborales para estimar: sim_jornadas &lt;- replicate(10000, sum(rpois(7, lambda = lambda))) #5.1 La media y la varianza empírica del número total de solicitudes por jornada, # Media empírica mean(sim_jornadas) ## [1] 41.8975 # Varianza empírica var(sim_jornadas) ## [1] 41.86078 #5.2 La proporción de jornadas en las que se reciben más de 50 solicitudes, lo que se considera un nivel de saturación operativa. mean(sim_jornadas &gt; 50) ## [1] 0.0946 4.6 Distribución geométrica \\((G(p))\\) Una variable aleatoria \\(X\\) sigue una distribución geométrica con parámetro \\(p\\), que se denota como: \\[ X \\sim G(p) \\] cuando representa el número de ensayos necesarios hasta la obtención del primer éxito en una secuencia de ensayos de Bernoulli independientes, cada uno con probabilidad de éxito \\(p\\) y fracaso \\(q = 1 - p\\). Desde un punto de vista conceptual, la distribución geométrica modeliza situaciones en las que se repite un mismo experimento aleatorio dicotómico hasta que se produce el primer éxito. En este contexto, \\(X\\) toma valores en el conjunto: \\[ X \\in \\{1, 2, 3, \\dots\\} \\] Su interpretación es clara: si \\(X = 4\\), significa que han sido necesarios cuatro intentos para obtener el primer éxito, y que los tres primeros intentos fueron fracasos. ¿Para qué sirve? La distribución geométrica es útil en contextos donde se desea modelar el número de intentos necesarios hasta obtener un resultado positivo. Algunas aplicaciones en economía y empresa son: Tiempos de espera en servicios: número de clientes atendidos hasta lograr una venta. Modelos de respuesta de clientes: número de llamadas o correos hasta obtener respuesta. Gestión de inventarios: número de periodos sin ventas hasta que se produce una compra. Riesgo crediticio: número de créditos concedidos hasta observar el primer impago. Su interpretación intuitiva y su estructura simple la hacen muy útil en modelos probabilísticos básicos y en simulaciones. Teoría Una variable aleatoria discreta \\(X\\) se distribuye geométricamente con parámetro \\(p \\in (0,1)\\) si modeliza el número de intentos necesarios hasta obtener el primer éxito. Se denota: \\[ X \\sim G(p) \\] donde: \\(p\\) es la probabilidad de éxito en cada ensayo. \\(q = 1 - p\\) es la probabilidad de fracaso. \\(X \\in \\{1, 2, 3, \\dots\\}\\) Función de cuantía La función de cuantía (función de probabilidad) de la distribución geométrica es: \\[ P(X = x) = q^{x - 1} \\cdot p, \\quad \\text{para } x = 1, 2, 3, \\dots \\] Esta fórmula representa la probabilidad de que se produzcan \\(x - 1\\) fracasos seguidos antes de obtener el primer éxito. Parámetros fundamentales Media: \\(E(X) = \\frac{1}{p}\\) Varianza:\\(\\text{Var}(X) = \\frac{1 - p}{p^2}\\) Ejercicios resueltos: Distribución Geomñetrica Ejercicio 1 Un agente comercial realiza llamadas a posibles clientes. La probabilidad de que una llamada termine en una venta es \\(p = 0.2\\) ¿Cuál es la probabilidad de que la primera venta se consiga en el cuarto intento? Solución: Sea \\(X \\sim G(0.2)\\), donde \\(X\\) representa el número de llamadas hasta la primera venta. Queremos calcular: \\[ P(X = 4) = q^{4 - 1} \\cdot p = (1 - 0.2)^3 \\cdot 0.2 = 0.8^3 \\cdot 0.2 = 0.512 \\cdot 0.2 = 0.1024 \\] Interpretación: Existe aproximadamente un 10,24% de probabilidad de que el agente realice tres llamadas fallidas y consiga una venta en el cuarto intento. Ejercicio 2: Resolución con R Supón ahora que la probabilidad de éxito es \\(p = 0.1\\). Se pide: Calcular la probabilidad de que la primera venta se logre en el sexto intento. Calcular la probabilidad de que se logre en 6 o menos intentos. Calcular la media y la varianza de la distribución. Simular 10.000 experimentos y estimar la media empírica. # Parámetro p &lt;- 0.1 # 1. P(X = 6) prob_6 &lt;- dgeom(6 - 1, prob = p) # en R, la geométrica cuenta fracasos antes del primer éxito prob_6 ## [1] 0.059049 # 2. P(X &lt;= 6) prob_acum_6 &lt;- pgeom(6 - 1, prob = p) prob_acum_6 ## [1] 0.468559 # 3. Media y varianza teóricas media &lt;- 1 / p varianza &lt;- (1 - p) / (p^2) media ## [1] 10 varianza ## [1] 90 # 4. Simulación de 10.000 experimentos set.seed(123) sim &lt;- rgeom(10000, prob = p) + 1 # sumamos 1 porque R devuelve fracasos mean(sim) ## [1] 9.8619 4.7 Distribución hipergeométrica \\((H(N, K, n))\\) Una variable aleatoria discreta \\(X\\) sigue una distribución hipergeométrica cuando representa el número de éxitos obtenidos al seleccionar una muestra aleatoria sin reemplazo de una población finita que contiene un número determinado de elementos exitosos y no exitosos. Se denota como: \\[ X \\sim H(N, K, n) \\] donde: \\(N\\): tamaño total de la población, \\(K\\): número total de elementos exitosos en la población, \\(n\\): tamaño de la muestra extraída sin reemplazo, \\(X\\): número de éxitos en la muestra. El soporte de \\(X\\) está dado por los valores enteros que cumplen: \\[ \\max(0, n - (N - K)) \\leq X \\leq \\min(n, K) \\] ¿Para qué sirve? La distribución hipergeométrica es útil para modelar situaciones de muestreo sin reemplazo, muy habituales en contextos reales donde la proporción de éxitos cambia con cada extracción. Aplicaciones en economía y empresa: Control de calidad: extraer productos sin reemplazo para evaluar cuántos son defectuosos. Auditorías: verificar cuántas facturas con errores hay en una muestra de registros contables. Inspección de lotes en inventarios. Selección de consumidores para una campaña donde algunos ya han sido contactados. Evaluación del fraude o incumplimiento en una muestra finita de expedientes. Teoría Sea una población de tamaño \\(N\\), con \\(K\\) elementos exitosos y \\(N - K\\) fracasos. Si se extrae una muestra aleatoria de tamaño \\(n\\), sin reemplazo, la variable aleatoria \\(X\\) que representa el número de éxitos en la muestra se distribuye como: \\[ X \\sim H(N, K, n) \\] Función de cuantía La función de cuantía (función de probabilidad) de la distribución hipergeométrica es: \\[ P(X = x) = \\frac{\\binom{K}{x} \\binom{N - K}{n - x}}{\\binom{N}{n}}, \\quad \\text{para } x = \\max(0, n - (N - K)), \\dots, \\min(n, K) \\] Esta fórmula expresa el cociente entre: El número de formas de seleccionar \\(x\\) éxitos entre los \\(K\\) existentes y \\(n - x\\) fracasos entre los \\(N - K\\) restantes, y el número total de formas de seleccionar \\(n\\) elementos de entre los \\(N\\). Parámetros fundamentales \\(N\\): tamaño de la población, \\(K\\): número total de éxitos en la población, \\(n\\): tamaño de la muestra. Momentos - Media: \\(E(X) = n \\cdot \\frac{K}{N}\\) - Varianza: \\(\\text{Var}(X) = n \\cdot \\frac{K}{N} \\cdot \\frac{N - K}{N} \\cdot \\frac{N - n}{N - 1}\\) Ejercicios Ejercicio 1: Un lote contiene 20 productos, de los cuales 6 son defectuosos. Se selecciona una muestra aleatoria de 5 productos sin reemplazo. ¿Cuál es la probabilidad de que haya exactamente 2 productos defectuosos en la muestra? Solución: Sea \\(X \\sim H(20, 6, 5)\\), y queremos calcular \\(P(X = 2)\\). Aplicamos la función de cuantía: \\[ P(X = 2) = \\frac{\\binom{6}{2} \\binom{14}{3}}{\\binom{20}{5}} = \\frac{15 \\cdot 364}{15504} \\approx 0.352 \\] Interpretación: Existe un 35.2 % de probabilidad de que exactamente 2 de los 5 productos seleccionados sean defectuosos. Ejercicio 2 en R. Supongamos que se tiene una población de 50 elementos, de los cuales 12 son considerados “éxito”. Se toma una muestra de tamaño 10 sin reemplazo. Se pide: Calcular la probabilidad de obtener exactamente 3 éxitos. Calcular la probabilidad de obtener 3 o menos éxitos. Calcular la esperanza y la varianza teóricas. # Parámetros N &lt;- 50 # población total K &lt;- 12 # número de éxitos en la población n &lt;- 10 # tamaño de la muestra x &lt;- 3 # 1. Probabilidad de obtener exactamente 3 éxitos dhyper(x, m = K, n = N - K, k = n) ## [1] 0.2702863 # 2. Probabilidad de obtener 3 o menos éxitos phyper(x, m = K, n = N - K, k = n) ## [1] 0.8209435 # 3. Media y varianza teóricas media &lt;- n * K / N varianza &lt;- n * (K / N) * ((N - K) / N) * ((N - n) / (N - 1)) media ## [1] 2.4 varianza ## [1] 1.48898 4.8 Distribución multinomial \\((M(n; {p_i}))\\) La distribución multinomial generaliza la distribución binomial a más de dos categorías posibles. Una variable aleatoria \\(\\boldsymbol{X} = (X_1, X_2, \\dots, X_k)\\) sigue una distribución multinomial cuando describe el número de veces que ocurren \\(k\\) posibles resultados mutuamente excluyentes tras realizar \\(n\\) ensayos independientes, cada uno con las mismas probabilidades. Se denota como: \\[ (X_1, X_2, \\dots, X_k) \\sim \\text{Multinomial}(n; p_1, p_2, \\dots, p_k) \\] o \\[ (X_1, X_2, \\dots, X_k) \\sim M(n; p_1, p_2, \\dots, p_k) \\] donde \\(n\\) es el número total de repeticiones y \\(p_j\\) son las probabilidades de que ocurra cada una de las posibles categorías o clases. ¿Para qué sirve? La distribución multinomial resulta especialmente útil cuando se desea modelar situaciones en las que un experimento puede arrojar más de dos posibles resultados excluyentes y se repite un número fijo de veces bajo condiciones de independencia. A diferencia de la binomial, que solo contempla dos categorías (éxito/fracaso), la multinomial permite trabajar con tres o más categorías En el ámbito económico y empresarial, su utilidad es muy amplia. Por ejemplo: Investigación de mercados: permite modelar cómo se distribuyen las preferencias de los consumidores entre distintas marcas, productos o servicios. Si una empresa desea saber cómo se reparte el mercado entre varias marcas competidoras, la distribución multinomial ofrece una base probabilística sólida para estimarlo. Análisis de comportamiento del consumidor: se puede emplear para estudiar la distribución de respuestas en una encuesta donde los participantes deben elegir una sola opción entre varias (por ejemplo, tipo de transporte utilizado, canal de compra preferido, nivel de satisfacción, etc.). Gestión de inventarios o logística: es útil para modelar cómo se reparte la demanda entre distintas categorías de productos en una tienda o cómo se distribuyen los envíos entre diferentes zonas geográficas. Evaluación de riesgos financieros o crediticios: permite estudiar cómo se clasifican los clientes en diferentes niveles de solvencia o riesgo. Teoría Supongamos un experimento con \\(k\\) resultados posibles mutuamente excluyentes: \\(X_1, X_2, \\dots, X_k\\), con: \\[ P(X_j) = p_j \\quad \\text{para todo } j = 1, \\dots, k, \\quad \\text{y } \\sum_{j=1}^{k} p_j = 1 \\] Si se repite el experimento \\(n\\) veces de forma independiente, y se observa \\(x_j\\) veces el resultado \\(X_j\\), el vector aleatorio: \\[ (x_1, x_2, \\dots, x_k) \\] sigue una distribución multinomial. Función de cuantía La función de probabilidad conjunta es: \\[ P(X_1 = x_1, X_2 = x_2, \\dots, X_k = x_k) = \\frac{n!}{x_1! \\cdot x_2! \\cdots x_k!} \\cdot p_1^{x_1} \\cdot p_2^{x_2} \\cdots p_k^{x_k} \\] para todo \\(x_1 + x_2 + \\cdots + x_k = n\\). donde: \\(n\\): número total de repeticiones del experimento aleatorio, \\(p_j \\in (0,1)\\): probabilidad de que ocurra el resultado \\(X_j\\), \\(\\sum_{j=1}^{k} p_j = 1\\), \\(x_j\\): número de veces que se observa el resultado \\(X_j\\), \\(\\sum_{j=1}^{k} x_j = n\\). Parámetros fundamentales \\(n \\in \\mathbb{N}\\): número de ensayos. \\(p_1, p_2, \\dots, p_k \\in (0, 1)\\) tales que \\(\\sum_{j=1}^k p_j = 1\\) Momentos \\(E(X_j) = n \\cdot p_j\\) \\(\\text{Var}(X_j) = n \\cdot p_j (1 - p_j)\\) \\(\\text{Cov}(X_i, X_j) = -n \\cdot p_i \\cdot p_j \\quad \\text{para } i \\neq j\\) Ejercicio En una encuesta, se pregunta a 10 personas por su preferencia entre tres marcas de teléfono: A, B y C. Las probabilidades de preferencia son \\(p_A = 0.5\\), \\(p_B = 0.3\\) y \\(p_C = 0.2\\) ¿Cuál es la probabilidad de que exactamente 4 personas prefieran A, 3 prefieran B y 3 prefieran C? Solución: Aplicamos la función de cuantía: \\[ P(X_A = 4, X_B = 3, X_C = 3) = \\frac{10!}{4! \\cdot 3! \\cdot 3!} \\cdot 0.5^4 \\cdot 0.3^3 \\cdot 0.2^3 \\] Calculamos paso a paso: \\[ \\frac{10!}{4!3!3!} = \\frac{3628800}{24 \\cdot 6 \\cdot 6} = \\frac{3628800}{864} = 4200 \\] \\[ P = 4200 \\cdot 0.0625 \\cdot 0.027 \\cdot 0.008 = 4200 \\cdot 0.0000135 \\approx 0.0567 \\] Ejemplo en R Vamos a calcular la probabilidad anterior usando R. # Carga de paquete necesario #install.packages(&quot;gtools&quot;) # si no lo tienes instalado library(gtools) ## Warning: package &#39;gtools&#39; was built under R version 4.3.3 # Parámetros n &lt;- 10 x &lt;- c(4, 3, 3) p &lt;- c(0.5, 0.3, 0.2) # Probabilidad multinomial dmultinom(x, prob = p) ## [1] 0.0567 4.9 Resumen de las distribuciones discretas Distribución Variable Parámetros Espacio muestral Función de cuantía Media Varianza Binomial Número de éxitos en \\(n\\) ensayos \\(n \\in \\mathbb{N},\\ p \\in (0,1)\\) \\(\\{0, 1, \\dots, n\\}\\) \\(P(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x}\\) \\(np\\) \\(np(1 - p)\\) Bernoulli Éxito o fracaso (1 experimento) \\(p \\in (0,1)\\) \\(\\{0, 1\\}\\) \\(P(X = x) = p^x (1 - p)^{1 - x}\\) \\(p\\) \\(p(1 - p)\\) Poisson Número de eventos en un intervalo \\(\\lambda &gt; 0\\) \\(\\mathbb{N}_0\\) \\(P(X = x) = \\dfrac{\\lambda^x e^{-\\lambda}}{x!}\\) \\(\\lambda\\) \\(\\lambda\\) Geométrica Ensayos hasta el 1er éxito \\(p \\in (0,1)\\) \\(\\{1, 2, 3, \\dots\\}\\) \\(P(X = x) = (1 - p)^{x - 1} p\\) \\(\\frac{1}{p}\\) \\(\\frac{1 - p}{p^2}\\) Binomial negativa Ensayos hasta \\(r\\)-ésimo éxito \\(r \\in \\mathbb{N},\\ p \\in (0,1)\\) \\(\\{r, r + 1, \\dots\\}\\) \\(P(X = x) = \\binom{x - 1}{r - 1} p^r (1 - p)^{x - r}\\) \\(\\frac{r}{p}\\) \\(\\frac{r(1 - p)}{p^2}\\) Hipergeométrica Éxitos en muestra sin reemplazo \\(N,\\ K,\\ n \\in \\mathbb{N}\\) \\(\\max(0, n - (N - K)) \\leq x \\leq \\min(n, K)\\) \\(P(X = x) = \\dfrac{\\binom{K}{x} \\binom{N - K}{n - x}}{\\binom{N}{n}}\\) \\(n \\cdot \\frac{K}{N}\\) \\(n \\cdot \\frac{K}{N} \\cdot \\frac{N - K}{N} \\cdot \\frac{N - n}{N - 1}\\) Multinomial Recuento de \\(k\\) categorías en \\(n\\) ensayos \\(n \\in \\mathbb{N},\\ p_1 + \\cdots + p_k = 1\\) \\(\\{(x_1, \\dots, x_k): \\sum x_j = n\\}\\) \\(P(X_1 = x_1, \\dots, X_k = x_k) = \\dfrac{n!}{x_1!\\cdots x_k!} p_1^{x_1} \\cdots p_k^{x_k}\\) \\(\\mathbb{E}(X_j) = np_j\\) \\(\\text{Var}(X_j) = np_j(1 - p_j)\\), \\(\\text{Cov}(X_i, X_j) = -np_i p_j\\) Notas: \\(\\mathbb{N}\\) denota los enteros positivos, y \\(\\mathbb{N}_0 = \\{0, 1, 2, \\dots\\}\\). La multinomial se interpreta como la generalización de la binomial para más de dos categorías. 4.10 Funciones disponibles en R para funciones discretas Para cada distribución discreta se tienen 4 funciones, a continuación el listado de funciones y su utilidad. dxxx(x, ...) # Función de masa de probabilidad, f(x) pxxx(q, ...) # Función de distribución acumulada hasta q, F(x) qxxx(p, ...) # Cuantil para el cual P(X &lt;= q) = p rxxx(n, ...) # Generador de números aleatorios. En el lugar de las letras xxx se de debe colocar el nombre de la distribución en R, a continuación el listado de nombres disponibles para las 6 distribuciones discretas básicas. binom # Binomial geo # Geométrica nbinom # Binomial negativa hyper # Hipergeométrica pois # Poisson multinom # Multinomial Combinando las funciones y los nombres se tiene un total de 24 funciones, por ejemplo, para obtener la función de masa de probabilidad \\(f(x)\\) de una binomial se usa la función dbinom( ) y para obtener la función acumulada \\(F(x)\\) de una Poisson se usa la función ppois( ). "],["cont.html", "Tema 5 Modelos de probabilidad continuos 5.1 Distribución uniforme \\((U(a, b))\\) 5.2 Distribución Normal 5.3 Distribuciones derivadas de la Normal 5.4 Distribución Exponencial \\((Exp(\\lambda))\\) 5.5 Distribución Gamma \\((\\Gamma(\\alpha))\\) 5.6 Distribución Beta \\((\\mathsf{Beta}(\\alpha, \\beta))\\) 5.7 Distribución de Pareto 5.8 Resumen de las distribuciones continuas 5.9 Funciones disponibles en R para distribuciones continuas", " Tema 5 Modelos de probabilidad continuos En este tema nos centraremos en el estudio de los modelos de probabilidad continuos, es decir, aquellos que describen situaciones en las que las variables aleatorias pueden tomar un número infinito no numerable de valores posibles dentro de un intervalo. Este tipo de modelos es especialmente relevante cuando se analizan fenómenos que varían de forma gradual y continua, como el tiempo, las cantidades económicas o los rendimientos financieros. Comprender estos modelos es crucial para abordar con éxito muchos problemas prácticos en economía, empresa y finanzas. Por ejemplo, permiten modelizar tiempos de espera, ingresos, tasas de conversión, precios, volúmenes de producción y muchos otros aspectos que se expresan mediante variables continuas. El estudio de sus propiedades, estructuras y aplicaciones nos ofrece una base sólida para interpretar datos reales y tomar decisiones fundamentadas en contextos de incertidumbre. Este documento desarrolla los casos prácticos de cada distribución continua, incluyendo su teoría, aplicaciones en el ámbito económico-empresarial y ejercicios resueltos tanto manualmente como con el uso de R. El objetivo es proporcionar al alumno una herramienta completa que le permita comprender los fundamentos teóricos de cada modelo y aplicarlos a problemas reales que surgen en el análisis y modelización de datos continuos. 5.1 Distribución uniforme \\((U(a, b))\\) Definición Una variable aleatoria continua \\(X\\) sigue una distribución uniforme continua en el intervalo \\([a, b]\\), con \\(a &lt; b\\), si su función de densidad de probabilidad es constante en ese intervalo: \\[ X \\sim U(a, b) \\] La función de desnsidad es: \\[ f(x) = \\begin{cases} \\frac{1}{b - a}, &amp; \\text{si } a \\le x \\le b \\\\ 0, &amp; \\text{en otro caso} \\end{cases} \\] y la Función de distribución \\[ F(x) = \\begin{cases} 0, &amp; x &lt; a \\\\ \\frac{x - a}{b - a}, &amp; a \\le x \\le b \\\\ 1, &amp; x &gt; b \\end{cases} \\] Momentos - Media: \\(E(X) = \\frac{a + b}{2}\\) - Varianza: \\(\\operatorname{Var}(X) = \\frac{(b - a)^2}{12}\\) Aplicaciones La distribución uniforme continua se utiliza cuando se considera que todos los valores dentro de un intervalo son igualmente probables. Es adecuada en situaciones como: Tiempo de llegada aleatoria dentro de un intervalo de tiempo (por ejemplo, llegada de un cliente entre las 9:00 y las 10:00). Generación de números aleatorios en simulaciones. Modelización de incertidumbre en parámetros desconocidos dentro de rangos conocidos. Representación gráfica Ejemplo: Una tienda online recibe cada día un único pedido especial que llega en algún momento entre las 9:00 y las 11:00 de la mañana. El responsable logístico considera que, debido a la falta de patrón histórico, la hora de llegada de ese pedido puede modelarse como una variable aleatoria con distribución uniforme continua en el intervalo \\([9, 11]\\). Se pide: ¿Cuál es la probabilidad de que el pedido llegue entre las 9:30 y las 10:15? Calcular la hora media esperada de llegada y la varianza del tiempo de llegada. Solución: Sea \\(X \\sim U(9, 11)\\), donde \\(X\\) representa la hora (en formato decimal) a la que llega el pedido. Para calcular \\(P(9.5 \\leq X \\leq 10.25)\\): \\[ P(9.5 \\leq X \\leq 10.25) = \\frac{10.25 - 9.5}{11 - 9} = \\frac{0.75}{2} = 0.375 \\] Nota didáctica: Para calcular la probabilidad de que una variable uniforme continua tome un valor dentro de un subintervalo del soporte, se pueden usar dos enfoques equivalentes: El primero se basa en que, para una distribución uniforme continua, la probabilidad de un intervalo dentro del soporte se obtiene dividiendo la longitud del intervalo de interés entre la longitud total del soporte. Es decir: \\[ P(d \\leq X \\leq c) = \\frac{c - d}{b -a} \\] Esto es posible solo cuando el intervalo \\[[c, d] \\subseteq [a, b]\\] y es la forma más rápida de resolverlo cuando estás trabajando a mano y no tienes acceso a funciones acumuladas. El segundo se basa en el cáclulo de la diferencia de las funciones de distribución \\(P(d \\leq X \\leq c) = F(d)-F(c)\\) La media y la varianza son: \\(E(X) = \\frac{9 + 11}{2} = 10 \\quad \\text{(hora media de llegada)}\\) \\(V(X) = \\frac{(11 - 9)^2}{12} = \\frac{4}{12} = 0.333\\) Interpretación: Hay una probabilidad del 37.5 % de que el pedido especial llegue entre las 9:30 y las 10:15. En promedio, se espera que llegue a las 10:00, con una dispersión medida por una varianza de 0.333 (horas cuadradas). Ejemplo en R Una empresa abre un periodo de recepción de solicitudes de financiación entre el día 10 y el día 20 de un mes. Se considera que la llegada de una solicitud en ese intervalo es completamente aleatoria. Se desea conocer: La probabilidad de que una solicitud llegue entre el día 12 y el 15. La media y la varianza del día de llegada. a &lt;- 10 b &lt;- 20 # Probabilidad de llegada entre los días 12 y 15 dia_inicio &lt;- 12 dia_fin &lt;- 15 #Calculamos la probabilidad como F(15)-F(12) probabilidad &lt;- punif(dia_fin, min = a, max = b) - punif(dia_inicio, min = a, max = b) # Media y varianza media &lt;- (a + b) / 2 varianza &lt;- (b - a)^2 / 12 probabilidad ## [1] 0.3 media ## [1] 15 5.2 Distribución Normal La distribución normal es una de las más importantes en la estadística y la probabilidad, tanto por sus propiedades matemáticas como por su relevancia empírica. Su importancia se justifica por varias razones fundamentales: Aparece naturalmente en muchos fenómenos: Muchas variables económicas, sociales, biológicas y físicas tienden a distribuirse aproximadamente de forma normal, al menos en situaciones de equilibrio o estabilidad (por ejemplo, los salarios, el rendimiento de carteras diversificadas o los errores de medición). Teorema Central del Límite: Este resultado fundamental de la estadística establece que, bajo condiciones generales, la suma (o media) de muchas variables aleatorias independientes tiende a distribuirse normalmente, incluso si las variables originales no siguen una normal. Esto explica por qué la normal aparece de forma tan frecuente en el análisis de datos reales. Simplicidad analítica: Tiene una función de densidad suave, continua, simétrica y con una forma conocida (la famosa campana de Gauss), lo que facilita el cálculo de probabilidades, inferencias y simulaciones. Papel clave en inferencia estadística: Muchos procedimientos estadísticos clásicos (contrastes de hipótesis, intervalos de confianza, regresión, etc.) se basan en la suposición de normalidad o aproximaciones normales. Aplicaciones económicas y empresariales: Se utiliza para modelar el comportamiento de retornos financieros, distribución de ingresos, demanda agregada, tiempos de servicio, entre otros. En la práctica, es habitual trabajar con dos versiones de la distribución normal: La distribución normal general \\(\\mathcal{N}(\\mu, \\sigma)\\) permite modelar directamente fenómenos con una media y una dispersión específicas, como salarios, costes o tiempos de producción. La distribución normal estándar \\(\\mathcal{N}(0, 1)\\) es una versión simplificada que tiene media 0 y desviación típica 1. Utilizar la versión estándar es muy útil porque: Permite usar tablas estadísticas universales sin necesidad de calcular integrales para cada caso. Facilita la resolución de ejercicios mediante la técnica de estandarización, transformando cualquier variable normal en una estándar. Hace posible comparar variables normales con diferentes unidades o escalas. 5.2.1 Distribución Normal \\((\\mu\\) , \\(\\sigma)\\). \\(\\mathcal{N}(\\mu, \\sigma)\\) Definición Una variable aleatoria continua \\(X\\) sigue una distribución normal \\((\\mu, \\sigma)\\) si su función de densidad de probabilidad es: \\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2}, \\quad x \\in \\mathbb{R} \\] Se denota: \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\) donde: \\(\\mu \\in \\mathbb{R}\\) es la media (centro de la distribución) \\(\\sigma^2 &gt; 0\\) es la varianza (dispersión) Caractrerísticas La curva es simétrica respecto a \\(\\mu\\) El valor de máxima densidad ocurre en \\(x = \\mu\\) La función nunca es cero, pero tiende a cero en los extremos La distribución es unimodal Momentos \\(E(X)= \\mu\\) \\(V⁡(X) = \\sigma^2\\) Representación gráfica A continuación, se representa gráficamente la función de densidad de una variable aleatoria con distribución normal \\(\\mathcal{N}(2000, 300^2)\\). Cambios de Varianza y media en la Normal Efecto de un cambio en la varianza. La siguiente figura muestra cómo afecta el valor de la varianza a la forma de la función de densidad: a mayor varianza, más extendida (aplanada, platicúritca) es la curva; a menor varianza, más concentrada alrededor de la media (leptocúrtica). Efecto de un cambio en la media. La siguiente figura muestra cómo afecta el valor de la media a la localización de la distribución normal, manteniendo constante la varianza. La forma de la curva no cambia, pero su centro se desplaza ha derecha o izquierda en función del valor de la media. Propiedad aditiva o reproductiva de la Normal La distribución normal es reproductiva, lo que significa que la suma de variables aleatorias normales independientes también sigue una distribución normal. Si: \\[ X_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1), \\quad X_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2), \\quad X_1 \\perp X_2 \\] Entonces: \\[ X_1 + X_2 \\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sqrt{\\sigma_1^2 + \\sigma_2^2}) \\] Es decir: La media de la suma es \\(\\mu_1 + \\mu_2\\) La desviación típica de la suma es \\(\\sqrt{\\sigma_1^2 + \\sigma_2^2}\\) Ejemplo: Si dos departamentos de una empresa tienen ingresos aleatorios independientes modelizados por normales, el ingreso total de la empresa también seguirá una distribución normal. La media del ingreso total será la suma de las medias, y la desviación típica reflejará la incertidumbre combinada de ambas fuentes. Si se generaliza esta propiedad (es decir, si se realiza un cambio en la media y en la varianza), es decir, si se hace una combinación lineal de un conjunto de variables alaeatorias normales la propiedad será: \\[ X_j \\sim \\mathcal{N}(\\mu_j, \\sigma_j) \\quad \\text{para } j = 1, \\dots, n \\] Y una combinación lineal de ellas (\\(Y\\)) : \\[ Y = b + \\sum_{j=1}^{n} a_j x_j \\] donde \\(b \\in \\mathbb{R}\\), \\(a_j \\in \\mathbb{R}\\), y no todos los \\(a_j\\) son cero. Entonces, \\(Y\\) también sigue una distribución normal con: \\[ \\omega \\sim \\mathcal{N}\\left( b + \\sum_{j=1}^{n} a_j \\mu_j, \\; \\sqrt{\\sum_{j=1}^{n} a_j^2 \\sigma_j^2} \\right) \\] Casos particulares de la propiedad aditivva o reproductiva A continuación se presentan algunos casos particulares relevantes de la propiedad aditiva para la distribución normal: Variables independientes con distinta media y desviación típica Si \\(X_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i)\\) y son independientes, la combinación lineal \\(Y = \\sum_{i =1}^{n} X_i\\) entonces: \\[ Y = X_1 + X_2 + \\cdots + X_n \\sim \\mathcal{N}\\left( \\sum_{i=1}^{n} \\mu_i, \\; \\sqrt{ \\sum_{i=1}^{n} \\sigma_i^2 } \\right) \\] 2. Variables independientes con misma desviación típica \\(\\sigma\\) Si \\(X_i \\sim \\mathcal{N}(\\mu_i, \\sigma)\\) y son independientes, la combinación lineal \\(Y = \\sum_{i =1}^{n} X_i\\) entonces: \\[ Y \\sim \\mathcal{N}\\left( \\sum_{i=1}^{n} \\mu_i, \\; \\sigma \\sqrt{n} \\right) \\] 3. Promedio de variables normales independientes con diferente media y desviación típica Si \\(X_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i)\\), independientes, la combinación lineal \\(Y = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\) entonces: \\[ Y = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\sim \\mathcal{N}\\left( \\frac{1}{n} \\sum_{i=1}^{n} \\mu_i, \\; \\sqrt{ \\frac{1}{n^2} \\sum_{i=1}^{n} \\sigma_i^2 } \\right) \\] 4. Promedio de variables normales iid con misma media y desviación típica Si \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma)\\), la combinación lineal \\(Y = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\) entonces: \\[ Y \\sim \\mathcal{N}\\left( \\mu, \\; \\frac{\\sigma}{\\sqrt{n}} \\right) \\] Estandarización Cualquier variable normal \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\) puede transformarse en una normal estándar \\(Z \\sim \\mathcal{N}(0, 1)\\) mediante: \\(Z = \\frac{X - \\mu}{\\sigma}\\) Esto permite usar tablas de la normal estándar para calcular probabilidades. Ejercicio: El salario mensual de los empleados de una empresa sigue una distribución normal con media 2000€ y desviación típica 300€. Sea \\(X \\sim \\mathcal{N}(2000, 300)\\). Calcular: La probabilidad de que un empleado cobre menos de 2300€ La probabilidad de que su salario esté entre 1850€ y 2150€ Solución: Se estandariza: \\(Z_1 = \\frac{2300 - 2000}{300} = 1\\) \\(Z_2 = \\frac{1850 - 2000}{300} = -0.5\\) \\(Z_3 = \\frac{2150 - 2000}{300} = 0.5\\) Consultando la tabla de la normal estándar: \\(P(Z &lt; 1) = 0.8413\\) \\(P(Z &lt; 0.5) = 0.6915\\) \\(P(Z &lt; -0.5) = 0.3085\\) En consecuencia \\(P(X &lt; 2300) = 0.8413\\) \\(P(1850 &lt; X &lt; 2150) = 0.6915 - 0.3085 = 0.3830\\) Solución con R mu &lt;- 2000 sigma &lt;- 300 # a) P(X &lt; 2300) pnorm(2300, mean = mu, sd = sigma) ## [1] 0.8413447 # b) P(1850 &lt; X &lt; 2150) pnorm(2150, mean = mu, sd = sigma) - pnorm(1850, mean = mu, sd = sigma) ## [1] 0.3829249 # Media y varianza media &lt;- mu varianza &lt;- sigma^2 media ## [1] 2000 varianza ## [1] 90000 Representación gráfica de las probabilidades Visualizamos a continuación las dos situaciones planteadas en el ejemplo: la probabilidad de cobrar menos de 2300€, y la probabilidad de cobrar entre 1850€ y 2150€. 5.2.2 Distribución Normal Estándar \\(\\mathcal{N}(0, 1)\\) Definición La distribución normal estándar es un caso particular de la distribución normal general en la que: \\(X \\sim \\mathcal{N}(0, 1)\\) Es decir: Tiene media \\(\\mu = 0\\) Tiene desviación típica \\(\\sigma = 1\\) Su función de densidad es: \\(f(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}z^2}, \\quad z \\in \\mathbb{R}\\) Propiedades Es simétrica respecto al origen (\\(z = 0\\)) La mayor parte del área bajo la curva se concentra entre \\(z = -3\\) y \\(z = 3\\) El valor máximo de la densidad ocurre en \\(z = 0\\) Es unimodal y su forma es la famosa “campana de Gauss” Importancia de la normal estándar Permite el cálculo de probabilidades sin necesidad de integrar para cada caso Las tablas de la normal estándar están ampliamente disponibles y permiten resolver problemas de cualquier normal mediante un cambio de variable Representación gráfica Ejemplo: El tiempo de atención al cliente en un servicio financiero se distribuye como \\(X \\sim \\mathcal{N}(15, 2)\\). Calcular la probabilidad de que un cliente tarde menos de 17 minutos en ser atendido. Solución: \\(Z = \\frac{17 - 15}{2} = 1 \\Rightarrow P(X &lt; 17) = P(Z &lt; 1) = 0.8413\\) Aproximadamente el 84.13% de los clientes son atendidos en menos de 17 minutos. Ejemplo en R mu &lt;- 15 sigma &lt;- 2 z &lt;- (17 - mu)/sigma pnorm(z) # P(Z &lt; 1) ## [1] 0.8413447 Cálculo de probabilidades directas usando tablas de la normal estándar (N(0, 1)) Las tablas que utilizamos en este curso proporcionan el valor de la probabilidad acumulada a la derecha del valor de \\(z\\), es decir: \\(P(Z &gt; z)\\) Por tanto: \\(P(Z &lt; z) = 1 - P(Z &gt; z)\\) \\(P(Z &gt; z) = \\text{valor directo de la tabla}\\) \\(P(Z &lt; -z) = P(Z &gt; z)\\) (por simetría) \\(P(|Z| &lt; z) = 1 - 2 \\cdot P(Z &gt; z)\\) Cálculo manual con tabla Calcular: \\(P(Z &gt; 1.25)\\) \\(P(Z &lt; 1.25)\\) \\(P(Z &lt; -1.25)\\) \\(P(|Z| &lt; 1.25)\\) \\(P(Z \\geq -1.85)\\) \\(P(0.20 &lt; Z \\leq 1.95)\\) \\(P(-1.60 \\leq Z \\leq -0.45)\\) Solución: A partir de la tabla (observa el dibujo que aprece en R para saber que necesitas calcular): \\(P(Z &gt; 1.25) = 0.1056\\) \\(P(Z \\&lt; 1.25) = 1 - P(Z \\geq 1.25)=1 - 0.1056 = 0.8944\\) \\(P(Z &lt; -1.25) = P(Z &gt; 1.25) = 0.1056\\) \\(P(|Z| &lt; 1.25) = 1 - 2 \\cdot 0.1056 = 0.7888\\) \\(P(Z \\geq -1.85) = 1 - P(Z \\leq -1.85) = 1 - 0.0322 = 0.9678\\) \\(P(0.20 &lt; Z \\leq 1.95) = P(Z \\geq 0.20) - P(Z \\geq 1.95)=0.4207-0.0256=0.3951\\) \\(P(-1.60 \\leq Z \\leq -0.45)= P(Z ≥ 0.45) - P(Z ≥ 1.60)=0.3264-0.0548=0.2716\\) Búsqueda en tablas de la distribución normal estándar La distribución normal estándar se denota como: \\(Z \\sim \\mathcal{N}(0, 1)\\) Las tablas que utilizamos en este curso proporcionan el valor de la probabilidad acumulada a la derecha del valor de \\(z\\), es decir: \\(P(Z &gt; z)\\) Por tanto: \\(P(Z &lt; z) = 1 - P(Z &gt; z)\\) \\(P(Z &gt; z) = \\text{valor directo de la tabla}\\) \\(P(Z &lt; -z) = P(Z &gt; z)\\) (por simetría) \\(P(|Z| &lt; z) = 1 - 2 \\cdot P(Z &gt; z)\\) Cálculo de probabilidades con R: Nota: Antes de nada, las fórmulas de R caclulan por defecto las probabilidades acumuladas (es decir, desde el punto que se busca e inferiores a el lower.tail=TRUE). Sin embargo, las tablas impresas que empleamos están construidas hacia la derecha. Calcular \\(P(Z &gt; 1.25)\\) pnorm(1.25, lower.tail = FALSE) ## [1] 0.1056498 Representación gráfica: Calcular \\(P(Z &lt; 1.25)\\) pnorm(1.25) ## [1] 0.8943502 Representación gráfica: Calcular \\(P(Z &lt; -1.25)\\) pnorm(-1.25) ## [1] 0.1056498 Representación gráfica: Calcular \\(P(|Z| &lt; 1.25)\\) 1 - 2 * pnorm(1.25, lower.tail = FALSE) ## [1] 0.7887005 Representación gráfica: Calcular \\(P(Z \\geq -1.85)\\) z&lt;- -1.85 pnorm(z, lower.tail = FALSE) ## [1] 0.9678432 \\[ P(Z \\geq -1.85) = 1 - P(Z \\leq -1.85) = 1 - 0.0322 = 0.9678 \\] Representación gráfica ## [1] 0.9678432 \\(P(0.20 &lt; Z \\leq 1,95)\\) Calculamos: \\[ P(0.20 &lt; Z \\leq 1.95) = P(Z \\geq 0.20) - P(Z \\geq 1.95) \\] a &lt;- 0.20 b &lt;- 1.95 # Cálculo de la probabilidad prob &lt;- pnorm(a, lower.tail = FALSE) - pnorm(b, lower.tail = FALSE) prob ## [1] 0.3951522 Representación gráfica \\(P(-1.60 \\leq Z \\leq -0.45)\\) a2 &lt;- -1.60 b2 &lt;- -0.45 # Cálculo usando simetría: P(Z ≥ 0.45) - P(Z ≥ 1.60) prob2 &lt;- pnorm(-a2, lower.tail = FALSE) - pnorm(-b2, lower.tail = FALSE) prob2 ## [1] -0.2715559 Representación gráfica Cálculo de probabilidad inversa de la Normal Estándar De la misma forma que hemos calculado una serie de valores de probabilidades normales, cuando conocemos el suceso podemos encontrarnos en la situación inversa, es decir, conocida la probabilidad, hallar el valor de la abscisa. En estos casos es necesario, en la mayoría de las tablas de la distribución \\(\\mathcal{N}(0,1)\\), determinar el signo de la abscisa, como se indica en el siguiente cuadro: Suceso &gt; 0,5 &lt; 0,5 = 0,5 \\(Z \\geq a\\) Negativa Positiva 0 \\(Z \\leq a\\) Positiva Negativa 0 Ejemplos 1. \\(P(Z \\geq a) = 0.35\\) Como \\(P(Z \\geq a) = 0.35\\), se cumple que: \\[ P(Z \\leq a) = 1 - 0.35 = 0.65 \\] Buscamos el valor de \\(a\\) tal que \\(P(Z \\leq a) = 0.65\\). # Inversa de la normal estándar p &lt;- 0.65 a &lt;- qnorm(p) a # Resultado ≈ 0.385 ## [1] 0.3853205 En este caso \\(a\\) es positivo. 2. \\(P(Z \\geq a) = 0.65\\) Como \\(P(Z \\geq a) = 0.65\\), se cumple que: \\[ P(Z \\leq a) = 1 - 0.65 = 0.35 \\] Buscamos el valor de \\(a\\) tal que \\(P(Z \\leq a) = 0.35\\). p &lt;- 0.35 a &lt;- qnorm(p) a # Resultado ≈ -0.385 ## [1] -0.3853205 En este caso \\(a\\) es negativo 3. \\(P(Z \\leq a) = 0.65\\) Buscamos directamente el valor de \\(a\\) tal que: \\[ P(Z \\leq a) = 0.65 \\] p &lt;- 0.65 a &lt;- qnorm(p) a # Resultado ≈ 0.385 ## [1] 0.3853205 En este caso \\(a\\) es positivo. 4. \\(P(Z \\leq a) = 0.35\\) Buscamos directamente el valor de \\(a\\) tal que: \\[ P(Z \\leq a) = 0.35 \\] p &lt;- 0.35 a &lt;- qnorm(p) a # Resultado ≈ -0.385 ## [1] -0.3853205 En este caso \\(a\\) es negativo. 5.3 Distribuciones derivadas de la Normal En muchas aplicaciones estadísticas no trabajamos directamente con variables que siguen una distribución normal, sino con funciones de variables normales. Estas funciones dan lugar a nuevas distribuciones conocidas como distribuciones derivadas de la normal. Las más importantes son: La distribución ji-cuadrado (\\(\\chi^2\\)), que aparece al elevar al cuadrado variables normales estándar. La distribución t de Student, que surge al estudiar la media muestral cuando la varianza poblacional es desconocida. La distribución F de Snedecor, que se utiliza al comparar dos varianzas. Estas distribuciones desempeñan un papel fundamental en la estadística inferencial, ya que permiten realizar estimaciones y contrastes de hipótesis sobre medias y varianzas, incluso cuando no se conoce toda la información poblacional. A continuación, estudiaremos cada una de estas distribuciones, su definición, propiedades, y cómo se relacionan con la distribución normal. 5.3.1 Distribución ji-cuadrado \\((\\chi^2)\\) La distribución chi-cuadrado (\\(\\chi^2\\)) es una distribución continua que aparece de forma natural cuando se eleva al cuadrado una variable normal estándar o se suman los cuadrados de varias variables normales estándar independientes. Definición Una variable aleatoria \\(Z \\sim \\mathcal{N}(0,1)\\) al ser elevada al cuadrado sigue una distribución \\(\\chi^2\\) con 1 grado de libertad: \\[ Z^2 \\sim \\chi^2_1 \\] Más generalmente, si \\(Z_1, Z_2, \\dots, Z_n\\) son variables normales estándar independientes: \\[ \\chi^2_k = Z_1^2 + Z_2^2 + \\dots + Z_n^2 \\] Entonces decimos que \\(\\chi^2_k\\) sigue una distribución chi-cuadrado con \\(n\\) grados de libertad. Función de densidad de la distribución \\(\\chi^2_n\\) La función de densidad de una variable aleatoria que sigue una distribución \\(\\chi^2_n\\) con \\(n\\) grados de libertad es: \\[ f(x, n) = \\frac{1}{2^{n/2} \\, \\Gamma(n/2)} \\, x^{(n/2 - 1)} \\, e^{-x/2}, \\quad x &gt; 0 \\] donde \\(\\Gamma(\\cdot)\\) es la función gamma. La forma de su función de densidad depende de los grados de libertad de la distribución, aunque su presentación gráfica es una distribución asimétrica positiva bastante pronunciada. Propiedades básicas Soporte: \\(x \\in [0, \\infty)\\) Media: \\(E(\\chi^2_n) = n\\) Varianza: \\(V(\\chi^2_n) = 2n\\) Es una distribución asimétrica positiva, aunque se aproxima a la normal a medida que aumentan los grados de libertad. Aplicaciones La distribución \\(\\chi^2\\) ocupa un lugar central en la estadística inferencial, ya que permite realizar contrastes de hipótesis y evaluar la variabilidad en distintos contextos. Su importancia va más allá de la teoría: en economía y en las ciencias sociales, se utiliza de forma habitual para validar modelos, analizar relaciones entre variables y verificar supuestos estadísticos clave. Entender la distribución \\(\\chi^2\\) y sus aplicaciones es esencial para interpretar correctamente los resultados de numerosos análisis cuantitativos en el ámbito económico. Algunas de sus aplicaciones clave son: Base para la construcción de la distribución t de Student y F de Snedecor. La distribución \\(\\chi^2\\) para construir dos de las distribuciones más importantes derivadas de la Normal. Contrastes de independencia: en análisis de datos categóricos, se utiliza la \\(\\chi^2\\) para contrastar si dos variables (por ejemplo, nivel educativo y tipo de empleo) son independientes. Contrastes de bondad de ajuste: permite evaluar si los datos observados siguen una determinada distribución teórica, útil en estudios de ingresos, gasto, precios, etc. Contrastes de varianzas: en estudios de riesgo o volatilidad (por ejemplo, en finanzas), se emplea la \\(\\chi^2\\) para verificar si la variabilidad observada es compatible con ciertos supuestos. Modelización econométrica: en pruebas de especificación o de homocedasticidad (como la prueba de Breusch-Pagan), la distribución \\(\\chi^2\\) aparece como distribución de referencia para contrastes. Análisis multivariante: en modelos como el análisis factorial o la estimación por máxima verosimilitud, se utilizan contrastes basados en la \\(\\chi^2\\) para evaluar la adecuación del modelo a los datos. Manejo de tablas Para el cálculo de probabilidades asociadas a la distribución \\(\\chi^2\\), es habitual recurrir a tablas estadísticas que proporcionan valores aproximados, del mismo modo que ocurre con la distribución normal \\(\\mathcal{N}(0,1)\\). Estas tablas suelen proporcionar valores de la probabilidad del suceso: \\[ P(\\chi_n^2 \\geq a) \\] Es decir, dan el área bajo la curva situada a la derecha del valor \\(a\\). A diferencia de la distribución normal, la distribución \\(\\chi^2\\), no es simétrica y no admite valores negativos. Interpretación gráfica A continuación se representa el área sombreada que corresponde a \\(P(\\chi^2(n) \\geq a)\\): Ejemplo de búsqueda en tablas Cálculo de una probabilidad directa Queremos calcular: \\[ P(3.94 \\leq \\chi_{10}^2 \\leq 15.987) \\] Utilizando la tabla: \\(P(\\chi_{10}^2 \\geq 3.94) = 0.95\\) \\(P(\\chi_{10}^2 \\geq 15.987) = 0.05\\) Por tanto: \\[ P(3.94 \\leq \\chi_{10}^2 \\leq 15.987) = F(3.94)-F(15.987)= 0.95 - 0.05 = 0.90 \\] Cálculo de probabilidad inversa (calculo de la probabilidad a partir de un valor) Sabemos que: \\[ P(8.231 \\leq \\chi_{19}^2 \\leq a) = 0.725 \\] Entonces: \\(P(\\chi_{19}^2 \\geq 8.231) = 0.95\\) Necesitamos encontrar \\(a\\) tal que \\(P(\\chi_{19}^2 \\geq a) = 0.225\\) Buscando en la tabla para \\(\\chi_{19}^2\\), encontramos: \\[ a \\approx 12.338 \\] Ejemplos de cálculo de probabilidades con R - Probabilidad directa con pchisq Queremos calcular: \\[ P(\\chi_{12}^2 \\leq 18.55) \\] # Probabilidad acumulada a la izquierda p &lt;- pchisq(18.55, df = 12) p # Resultado ≈ 0.8986 ## [1] 0.9000175 Búsqueda dprobabilidad inversa con qchisq Queremos encontrar el valor \\(a\\) tal que: \\[ P(\\chi_{15}^2 \\geq a) = 0.10 \\] Es decir, buscamos el percentil que deja un 10% de probabilidad a la derecha. # Valor crítico tal que P(chi² ≥ a) = 0.10 → cola derecha a &lt;- qchisq(0.90, df = 15) # usamos 0.90 porque calcula P(X ≤ a) a # Resultado ≈ 22.307 ## [1] 22.30713 5.3.2 Distribución t de Student \\((t_n)\\) La distribución t de Student es una distribución continua que surge de forma natural cuando se trabaja con muestras pequeñas de una población normal, especialmente cuando la varianza poblacional es desconocida. Definición Si \\(Z \\sim \\mathcal{N}(0,1)\\) y \\(U \\sim \\chi^2_n\\), con \\(Z\\) y \\(U\\) independientes, entonces la variable: \\[ T = \\frac{Z}{\\sqrt{U/n}} \\sim t_n \\] sigue una distribución t de Student con \\(n\\) grados de libertad. Función de densidad de la distribución \\(t_n\\) La función de densidad de la distribución t de Student con \\(n\\) grados de libertad es: \\[ f(x, n) = \\frac{\\Gamma\\left( \\frac{n+1}{2} \\right)}{\\sqrt{n\\pi} \\, \\Gamma\\left( \\frac{n}{2} \\right)} \\left(1 + \\frac{x^2}{n} \\right)^{-\\frac{n+1}{2}}, \\quad x \\in \\mathbb{R} \\] donde \\(\\Gamma(\\cdot)\\) es la función gamma. Esta distribución tiene cola más pesada que la normal, y tiende a la normal estándar conforme aumentan los grados de libertad. Propiedades básicas Soporte: \\(x \\in (-\\infty, \\infty)\\) Media: \\(E(t_n) = 0\\) si \\(n &gt; 1\\) Varianza: \\(V(t_n) = \\frac{n}{n-2}\\) si \\(n &gt; 2\\) Tiene una forma similar a la normal, pero con colas más pesadas (mayor probabilidad en los extremos). A medida que \\(n \\to \\infty\\), \\(t_n \\to \\mathcal{N}(0,1)\\) Aplicaciones La distribución t de Student es fundamental en estadística inferencial y análisis económico, especialmente cuando trabajamos con muestras pequeñas y no conocemos la varianza poblacional. Algunas de sus aplicaciones clave son: Estimación y contrastes de hipótesis para medias con varianza desconocida. Construcción de intervalos de confianza en econometría y análisis financiero. Aplicaciones en tests de regresión (por ejemplo, para contrastar si un coeficiente es significativamente distinto de cero). Evaluación de resultados experimentales o de encuestas en economía con tamaños muestrales limitados. Manejo de tablas Las tablas de la t de Student proporcionan valores críticos \\(a\\) tales que: \\[ P(T_n \\geq a) \\quad \\text{o} \\quad P(|T_n| \\geq a) \\] Dado que la t es simétrica respecto a 0, se pueden obtener valores de colas unilaterales y bilaterales. A diferencia de la \\(\\chi^2\\), admite valores negativos y positivos, y su interpretación es muy parecida a la de la normal estándar. Ejemplo gráfico Se muestra el área a la derecha de un valor \\(a\\) para la t de Student con n grados de libertad: Ejemplos de búsqueda en tablas Búsqueda directa de una probabilidad Sea \\(T \\sim t_{12}\\). Calcula \\(P(T \\geq 1.782)\\). Resolución: Consultamos la tabla t para \\(n = 12\\) y buscamos el valor \\(t = 1.782\\). En las tablas t de cola derecha, encontramos que: \\[ P(T \\geq 1.782) = 0.05 \\] La probabilidad de que \\(T\\) tome un valor mayor o igual que 1.782 es 0.05. Búsqueda inversa de un valor crítico Sea \\(T \\sim t_{15}\\). ¿Qué valor de \\(t\\) cumple que \\(P(T \\geq t) = 0.10\\)? Resolución: Buscamos en la tabla t, en la fila correspondiente a \\(n = 15\\) y la columna de probabilidad 0.10 (cola derecha). Encontramos: \\[ t = 1.341 \\] El valor crítico que deja una probabilidad de 0.10 a la derecha en una t de Student con 15 grados de libertad es \\(t = 1.341\\). Probabilidad bilateral centrada en 0 Sea \\(T \\sim t_{10}\\). Calcula \\(P(-2.228 \\leq T \\leq 2.228)\\). Resolución: Dado que la distribución t es simétrica, tenemos: \\[ P(-2.228 \\leq T \\leq 2.228) = 1 - 2 \\cdot P(T \\geq 2.228) \\] En la tabla, para \\(n = 10\\) y \\(t = 2.228\\), encontramos: \\[ P(T \\geq 2.228) = 0.025 \\] Por tanto: \\[ P(-2.228 \\leq T \\leq 2.228) = 1 - 2 \\cdot 0.025 = 0.95 \\] El 95% de la distribución t con 10 grados de libertad se encuentra entre -2.228 y 2.228. Ejemplos de cálculo de probabilidades con R Probabilidad directa con pt Queremos calcular: \\[ P(T_{12} \\leq 1.782) \\] # Probabilidad acumulada a la izquierda p &lt;- pt(1.782, df = 12) p # Resultado ≈ 0.9499 ## [1] 0.9499756 Probabilidad inversa con qt Queremos encontrar el valor \\(a\\) tal que: \\[ P(T_{15} \\geq a) = 0.10 \\] Es decir, buscamos el percentil que deja un 10% de probabilidad a la derecha. # Valor crítico tal que P(t ≥ a) = 0.10 a &lt;- qt(0.90, df = 15) # usamos 0.90 porque qt calcula P(t ≤ a) a # Resultado ≈ 1.3406 ## [1] 1.340606 5.3.3 Distribución F de Snedecor \\((F{n_1,n_2})\\) La distribución F de Snedecor es una distribución continua que surge al comparar dos varianzas muestrales provenientes de poblaciones normales. Es fundamental en el análisis de la varianza (ANOVA) y en contrastes de hipótesis sobre varianzas. Definición Si \\(U_1 \\sim \\chi^2_{n_1}\\) y \\(U_2 \\sim \\chi^2_{n_2}\\), independientes, entonces la variable: \\[ F = \\frac{U_1 / n_1}{U_2 / n_2} \\sim F_{n_1, n_2} \\] sigue una distribución F con \\(n_1\\) y \\(n_2\\) grados de libertad en el numerador y denominador, respectivamente. Función de densidad de la distribución \\(F_{n_1, n_2}\\) La función de densidad de la distribución F con \\(n_1\\) grados de libertad en el numerador y \\(n_2\\) en el denominador es: \\[ f(x) = \\frac{\\left(\\frac{n_1}{n_2}\\right)^{n_1/2} \\Gamma\\left(\\frac{n_1 + n_2}{2}\\right)}{\\Gamma\\left(\\frac{n_1}{2}\\right) \\Gamma\\left(\\frac{n_2}{2}\\right)} \\cdot x^{(n_1/2 - 1)} \\cdot \\left(1 + \\frac{n_1}{n_2}x\\right)^{-\\frac{n_1 + n_2}{2}}, \\quad x &gt; 0 \\] donde \\(\\Gamma(\\cdot)\\) es la función gamma. Propiedades básicas Soporte: \\(x \\in (0, \\infty)\\) Media: \\(E(F_{n_1, n_2}) = \\frac{n_2}{n_2 - 2}\\), si \\(n_2 &gt; 2\\) Varianza: más compleja, pero decrece al aumentar los grados de libertad. Es una distribución asimétrica positiva. A medida que \\(n_1\\) y \\(n_2\\) aumentan, la distribución F se aproxima a una distribución normal. Aplicaciones La distribución F es especialmente útil en: Contrastes de varianzas: comparar la variabilidad entre dos poblaciones. Análisis de la varianza (ANOVA): comparar medias de varios grupos. Contrastes sobre modelos de regresión: evaluar si un modelo explica significativamente la variable dependiente. Econometría: pruebas globales de significatividad en modelos lineales. Manejo de tablas Las tablas de la F de Snedecor suelen proporcionar valores críticos \\(x\\) tales que: \\[ P(F_{n_1, n_2} \\geq x) \\] Es decir, indican el valor de \\(x\\) a partir del cual queda una cierta probabilidad a la derecha (cola superior). Como la distribución F no es simétrica ni admite valores negativos, siempre se calcula el área bajo la cola derecha. Ejemplo gráfico Se muestra el área a la derecha de un valor \\(x\\) en una distribución \\(F_{n_1, n_2}\\): Cálculo de probabilidades usando tablas Las tablas de la distribución F de Snedecor suelen mostrar valores críticos \\(x\\) tales que: \\[ P(F_{n_1, n_2} \\geq x) = \\alpha \\] Búsqueda directa de una probabilidad Sea \\(F \\sim F_{5, 10}\\). Calcula \\(P(F \\geq 3.33)\\). Resolución: Consultamos la tabla F en la fila correspondiente a \\(n_1 = 5\\) y la columna \\(n_2 = 10\\). En muchas tablas aparece que: \\[ F_{5, 10}(0.05) = 3.33 \\] Esto indica que: \\[ P(F \\geq 3.33) = 0.05 \\] La probabilidad de que \\(F\\) tome un valor mayor o igual a 3.33 es 0.05. Búsqueda inversa de un valor crítico Sea \\(F \\sim F_{8, 12}\\). ¿Qué valor \\(x\\) cumple que \\(P(F \\geq x) = 0.01\\)? Resolución: Buscamos en la tabla F en la fila de \\(n_1 = 8\\) y columna \\(n_2 = 12\\), en el nivel \\(\\alpha = 0.01\\). Encontramos: \\[ F_{8, 12}(0.01) = 5.40 \\] El valor crítico que deja un 1% de probabilidad a la derecha es \\(x = 5.40\\). Ejemplos de cálculo de probabilidades con R - Probabilidad directa con pf Queremos calcular: \\[ P(F_{5, 10} \\leq 3.33) \\] # Probabilidad acumulada a la izquierda p &lt;- pf(3.33, df1 = 5, df2 = 10) p # Resultado ≈ 0.9502 ## [1] 0.9501687 - Probabilidad inversa con qf Queremos encontrar el valor \\(x\\) tal que: \\[P(F_{8, 12} \\geq x) = 0.05\\] Es decir, buscamos el percentil que deja un 5% de probabilidad a la derecha. # Valor crítico tal que P(F ≥ x) = 0.05 x &lt;- qf(0.95, df1 = 8, df2 = 12) # usamos 0.95 porque qf calcula P(F ≤ x) x # Resultado ≈ 2.9012 ## [1] 2.848565 5.3.4 Aplicaciones a las Ciencias Sociales de las distribuciones derivadas de la Normal Distribución \\(\\chi^2\\) Evaluación del perfil del consumidor: mediante tablas de contingencia y pruebas de independencia (basadas en \\(\\chi^2\\)), se puede estudiar si variables como el género y la preferencia por un producto están relacionadas. Análisis de resultados electorales: se puede contrastar si la distribución de votos difiere de lo esperado por azar entre distintas regiones o franjas de edad. Control de calidad: en la industria, la \\(\\chi^2\\) se usa para comprobar si la variabilidad de los procesos se mantiene dentro de lo permitido por la normativa. Distribución t de Student Estudios de mercado con muestras pequeñas: al analizar encuestas piloto sobre precios, demanda o satisfacción de clientes, se utiliza la t para estimar medias o realizar contrastes sin conocer la varianza poblacional. Evaluación de impacto económico local: en proyectos de desarrollo o inversión, si se toman muestras pequeñas (por ejemplo, ventas antes y después de una intervención), la t permite estimar si el cambio es significativo. Detección de fraude o manipulación: al comparar medias de ingresos o gastos entre grupos (empresas, municipios), se puede detectar comportamientos anómalos mediante contrastes t. Distribución F de Snedecor Comparación de modelos económicos: en econometría, la F se utiliza para comparar modelos de regresión (por ejemplo, uno restringido y uno general) y decidir si añadir nuevas variables mejora significativamente la explicación. Análisis del rendimiento académico: si se quiere saber si las medias de distintas titulaciones universitarias (o facultades) difieren entre sí, se aplica ANOVA, que se basa en la F. Estudios sobre desigualdad: en análisis territorial, se puede utilizar la F para estudiar si la variabilidad en el nivel de renta entre regiones es significativamente distinta de la variabilidad dentro de cada región. Distribución Aplicaciones en Ciencias Sociales \\[\\chi^2\\] • Pruebas de independencia (datos categóricos)• Contrastes de bondad de ajuste• Control de calidad• Validación de modelos en economía y sociología \\[t_n\\] • Estimación y contraste de medias con muestras pequeñas• Análisis de impacto en encuestas piloto• Evaluación de intervenciones económicas• Detección de anomalías o fraude \\[F_{n_1,n_2}\\] • Comparación de modelos en regresión• Análisis de la varianza (ANOVA)• Estudios regionales de desigualdad• Contrastes globales de significatividad 5.4 Distribución Exponencial \\((Exp(\\lambda))\\) La distribución exponencial es un caso particular de la distribución Gamma, y se utiliza frecuentemente para modelar el tiempo entre eventos en un proceso aleatorio que ocurre a una tasa constante, como llegadas de clientes, fallos de sistemas o accidentes. Definición Una variable aleatoria \\(X\\) tiene una distribución exponencial de parámetro \\(\\lambda &gt; 0\\) \\(X \\sim Exp(\\lambda)\\) si su función de densidad es: \\[ f(x; \\lambda) = \\lambda e^{-\\lambda x}, \\quad x &gt; 0 \\] Función de distribución La función de distribución acumulada es: \\[ F(x) = P(X \\leq x) = 1 - e^{-\\lambda x}, \\quad x &gt; 0 \\] Por tanto, la probabilidad de que el evento aún no haya ocurrido antes de tiempo \\(x\\) es: \\[ P(X &gt; x) = e^{-\\lambda x} \\] Relación con la distribución Gamma La distribución exponencial es un caso particular de la distribución Gamma: \\[ \\text{Exponencial}(\\lambda) \\equiv \\text{Gamma}(\\alpha = 1, \\beta = 1/\\lambda) \\] Propiedades Soporte: \\(x \\in (0, \\infty)\\) Media: \\(E(X) = \\frac{1}{\\lambda}\\) Varianza: \\(V(X) = \\frac{1}{\\lambda^2}\\) Asimétrica positiva, con una larga cola hacia la derecha. Cumple la propiedad de falta de memoria: \\[ P(X &gt; s + t \\mid X &gt; s) = P(X &gt; t) \\] Esta propiedad significa que el tiempo esperado restante no depende del tiempo ya transcurrido. Función de densidad para distintos valores de \\(\\lambda\\) Aplicaciones La distribución exponencial es una de las más utilizadas en estadística aplicada debido a su simplicidad y a que describe adecuadamente fenómenos donde interesa medir el tiempo hasta que ocurre un evento. Algunas de sus aplicaciones más relevantes son: Modelado del tiempo entre eventos en procesos de Poisson: En procesos en los que los eventos ocurren de forma aleatoria pero a una tasa constante (por ejemplo, llamadas a un call center, llegadas de clientes a un establecimiento o fallos de una máquina), el tiempo entre dos eventos consecutivos sigue una distribución exponencial. Esto permite simular, prever y gestionar recursos en sistemas de atención, logística o producción. Análisis de supervivencia: En estudios médicos y de ingeniería, se utiliza para modelar el tiempo hasta que ocurre un evento como la muerte, una recaída, o el fallo de un componente. Aunque la exponencial es un caso particular dentro del análisis de supervivencia, sirve como modelo base cuando el riesgo es constante a lo largo del tiempo. Economía y finanzas: La exponencial permite modelar el tiempo entre: operaciones bursátiles o transacciones bancarias, impagos de clientes, reclamaciones de seguros, cambios de régimen en modelos de series temporales. Su facilidad de interpretación la hace útil también como aproximación inicial en estudios de fiabilidad o de riesgo. Procesos industriales y mantenimiento: En entornos industriales, se usa para estimar la duración media de una máquina antes de que falle. Esto permite optimizar el mantenimiento preventivo. Si los fallos ocurren al azar y con una tasa constante, entonces el tiempo hasta el fallo sigue una distribución exponencial. Ejemplos de cálculo con R - 1: Cálculo de la Probabilidad directa Sea \\(X \\sim \\text{Exponencial}(0.25)\\), calcular \\(P(X \\leq 5)\\), es decir, la probabilidad de que el evento ocurra antes de 5 unidades de tiempo: p &lt;- pexp(5, rate = 0.25) p # Resultado ≈ 0.7135 ## [1] 0.7134952 - 2: Cálculo de la Probabilidad inversa Queremos encontrar el valor \\(x\\) tal que: \\[ P(X \\geq x) = 0.1, \\quad X \\sim \\text{Exponencial}(\\lambda = 0.5) \\] Dado que la función qexp() calcula la probabilidad acumulada a la izquierda \\(P(X \\leq x)\\), necesitamos encontrar el cuantil correspondiente al 90%: \\[ P(X \\geq x) = 0.1 \\quad \\Rightarrow \\quad P(X \\leq x) = 0.9 \\] # Valor crítico correspondiente al percentil 90 x &lt;- qexp(0.9, rate = 0.5) x # Resultado ≈ 4.605 ## [1] 4.60517 5.5 Distribución Gamma \\((\\Gamma(\\alpha))\\) La distribución Gamma es una distribución continua que generaliza la distribución \\(\\chi^2\\) y se utiliza en contextos donde modelamos tiempos de espera, vida útil de productos o fenómenos con tasas constantes. La función gamma se define mediante la siguiente integral: \\[ \\Gamma(p) = \\int_0^{\\infty} x^{p - 1} e^{-x} \\, dx \\quad \\text{si } x &gt; 0 \\text{ y } p &gt; 0. \\] Definición Una variable aleatoria \\(X\\) sigue una distribución Gamma de parámetros \\(\\alpha &gt; 0\\) (parámetro de forma) y \\(\\beta &gt; 0\\) (parámetro de escala) \\(X \\sim Ga(\\alpha, \\beta)\\) si su función de densidad es: \\[ f(x; \\alpha, \\beta) = \\frac{1}{\\Gamma(\\alpha) \\beta^\\alpha} \\, x^{\\alpha - 1} e^{-x / \\beta}, \\quad x &gt; 0 \\] donde \\(\\Gamma(\\alpha)\\) es la función gamma. Función de densidad para diferentes valores de \\(\\alpha\\) Propiedades básicas Soporte: \\(x \\in (0, \\infty)\\) Media: \\(E(X) = \\alpha \\beta\\) Varianza: \\(V(X) = \\alpha \\beta^2\\) Si \\(\\alpha = n/2\\), \\(\\beta = 2\\) → \\(X \\sim \\chi^2_n\\) Para \\(\\alpha = 1\\), se convierte en una distribución exponencial. Aplicaciones Modelización de tiempos de espera hasta la ocurrencia de un evento (por ejemplo, averías, llegadas de clientes). Análisis de la vida útil de productos o componentes. En seguros, para modelar el importe de reclamaciones agregadas. En hidrología, para modelar el volumen de lluvias extremas. En teoría de colas y procesos de Poisson, al estudiar el tiempo hasta el \\(\\alpha\\)-ésimo evento. Ejemplos de cálculo de probabilidades con R Pasamos directamente al cálculo en R porque las probabilidades de esta distribución no suele buscarse con tablas estadísticas. - 1. Probabilidad directa con pgamma Queremos calcular: \\[ P(X \\leq 6), \\quad X \\sim \\text{Gamma}(\\alpha = 3, \\beta = 2) \\] p &lt;- pgamma(6, shape = 3, scale = 2) p # Resultado ≈ 0.5768 ## [1] 0.5768099 - 2. Valor crítico (probabilidad inversa) con qgamma Queremos encontrar el valor \\(x\\) tal que: \\[ P(X \\geq x) = 0.05, \\quad X \\sim \\text{Gamma}(\\alpha = 3, \\beta = 2) \\] Dado que la función qgamma calcula la probabilidad acumulada a la izquierda \\(P(X \\leq x)\\), buscamos: \\[ P(X \\leq x) = 0.95 \\] # Valor crítico para una cola derecha del 5% x &lt;- qgamma(0.95, shape = 3, scale = 2) x # Resultado ≈ 9.4877 ## [1] 12.59159 5.6 Distribución Beta \\((\\mathsf{Beta}(\\alpha, \\beta))\\) La distribución Beta es una distribución continua definida en el intervalo \\([0,1]\\) y muy versátil, especialmente útil en estadística bayesiana, teoría de la probabilidad y simulación. Es una generalización de la distribución uniforme sobre \\([0,1]\\). La función beta se define mediante la siguiente integral: \\[ B(\\alpha, \\beta) = \\int_0^1 x^{\\alpha - 1}(1 - x)^{\\beta - 1} \\, dx = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} \\] donde \\(\\Gamma(\\cdot)\\) es la función gamma, y se requiere que \\(\\alpha &gt; 0\\), \\(\\beta &gt; 0\\). Distribución beta Una variable aleatoria \\(X\\) tiene una distribución beta con parámetros \\(\\alpha &gt; 0\\) y \\(\\beta &gt; 0\\) si su función de densidad es: \\[ f(x) = \\begin{cases} \\displaystyle \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}(1 - x)^{\\beta - 1}, &amp; 0 &lt; x &lt; 1 \\\\ 0, &amp; \\text{en otro caso} \\end{cases} \\] Esta distribución está acotada en el intervalo \\((0,1)\\), y su forma depende fuertemente de los valores de los parámetros. Nota: Cuando \\(\\alpha = 1\\) y \\(\\beta = 1\\), se obtiene la distribución uniforme sobre el intervalo \\([0,1]\\). Propiedades básicas Soporte: \\(x \\in (0, 1)\\) Media: \\(\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta}\\) Varianza: \\(\\text{Var}(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\\) La forma de la densidad depende de la relación entre \\(\\alpha\\) y \\(\\beta\\): Si \\(\\alpha = \\beta = 1\\), la distribución es uniforme. Si \\(\\alpha &gt; 1\\) y \\(\\beta &gt; 1\\), tiene forma de campana (simétrica o asimétrica). Si \\(\\alpha &lt; 1\\) o \\(\\beta &lt; 1\\), puede presentar asimetría o forma en U. Es una distribución útil para modelar proporciones o probabilidades. Representación gráfica Aplicaciones La distribución beta es especialmente útil para modelar variables continuas que toman valores en el intervalo [0, 1], como proporciones, porcentajes o probabilidades. Gracias a la flexibilidad que permiten sus dos parámetros \\(\\alpha\\) y \\(\\beta\\), puede adoptar formas simétricas, asimétricas, en U o en forma de campana, adaptándose a distintos tipos de datos. A continuación, se detallan algunas aplicaciones relevantes: - Estadística bayesiana: La beta es la distribución a priori conjugada de la binomial. Esto significa que, cuando se utiliza una beta para modelar la probabilidad desconocida de éxito en un experimento binomial, la distribución posterior también será una beta. Esto facilita los cálculos y la interpretación. - Análisis de proporciones en ciencias sociales: En estudios de encuestas o demografía, las respuestas pueden ser proporciones: porcentaje de ciudadanos que votan, nivel de satisfacción en una escala de 0 a 1, proporción de hogares con acceso a internet, etc. La beta permite modelar estas proporciones de forma continua y flexible. - Economía y finanzas: En análisis de eficiencia, los scores obtenidos por métodos como DEA (Data Envelopment Analysis) toman valores entre 0 y 1. La distribución beta se ajusta perfectamente para representar su distribución empírica. También se utiliza para modelar tasas de rendimiento normalizadas (por ejemplo, la rentabilidad diaria de un fondo como proporción del rendimiento máximo teórico). En estudios de desigualdad, el índice de Theil o el índice de Atkinson se expresan como proporciones y pueden ser analizados con distribuciones beta. - Gestión de riesgos y marketing: En marketing, al estimar tasas de conversión (por ejemplo, porcentaje de clics sobre impresiones), la distribución beta permite incorporar incertidumbre y construir intervalos creíbles o probabilísticos para la tasa real de conversión. En seguros o análisis actuarial, puede usarse para modelar el proporción del siniestro cubierto, o la fracción de gasto en salud respecto al ingreso familiar. - Simulación y generación de datos aleatorios: En simulación Monte Carlo, la distribución beta se usa para modelar inputs inciertos cuando los valores están acotados en [0,1], y se desea evitar asumir simetría o forma normal. Ejemplos de cálculo con R 1: Cálculo de la Probabilidad directa Sea \\(X \\sim \\text{Beta}(2, 5)\\). Calcular \\(P(X \\leq 0.3)\\): p &lt;- pbeta(0.3, shape1 = 2, shape2 = 5) p # Resultado ≈ 0.4718 ## [1] 0.579825 -2: Valor crítico (probabilidad inversa) Queremos encontrar el valor \\(x\\) tal que: \\[ P(X \\leq x) = 0.90, \\quad X \\sim \\text{Beta}(2, 5) \\] Para obtener este valor usamos la función qbeta() en R, que nos devuelve el cuantil correspondiente a la probabilidad acumulada deseada. # Cálculo del percentil 90 para Beta(2, 5) x &lt;- qbeta(0.90, shape1 = 2, shape2 = 5) x # Resultado ≈ 0.6217 ## [1] 0.5103163 5.7 Distribución de Pareto La distribución de Pareto es especialmente útil para describir fenómenos en los que una pequeña parte de la población concentra una gran proporción de un recurso, como ocurre en la distribución de la renta, la riqueza o el tamaño de empresas. Gracias a su forma de cola pesada, permite modelar con precisión valores extremos y desigualdades marcadas en contextos económicos y sociales. Definición Una variable aleatoria \\(X\\) sigue una distribución de Pareto con parámetros \\(x_m &gt; 0\\) (mínimo) y \\(\\alpha &gt; 0\\) (parámetro de forma), si su función de densidad es: \\[ f(x) = \\begin{cases} \\displaystyle \\frac{\\alpha x_m^\\alpha}{x^{\\alpha + 1}}, &amp; x \\geq x_m \\\\ 0, &amp; x &lt; x_m \\end{cases} \\] donde: - \\(\\alpha &gt; 0\\): determina la concentración de la distribución (a mayor \\(\\alpha\\), menor desigualdad). - \\(x_m &gt; 0\\): es el valor mínimo (umbral) a partir del cual se define la variable aleatoria. Estas condiciones aseguran que la función sea una densidad válida, es decir, que su integral en \\([x_m, \\infty)\\) sea igual a 1. Función de distribución acumulada La función de distribución acumulada (FDA) es: \\[ F(x) = P(X \\leq x) = 1 - \\left( \\frac{x_m}{x} \\right)^{\\alpha}, \\quad x \\geq x_m \\] Propiedades Soporte: \\(x \\in [x_m, \\infty)\\) Media: \\(E(X) = \\begin{cases} \\infty, &amp; \\text{si } \\alpha \\leq 1 \\\\ \\frac{\\alpha x_m}{\\alpha - 1}, &amp; \\text{si } \\alpha &gt; 1 \\end{cases}\\) Varianza: \\(V(X) = \\begin{cases} \\infty, &amp; \\text{si } \\alpha \\leq 2 \\\\ \\frac{x_m^2 \\alpha}{(\\alpha - 1)^2(\\alpha - 2)}, &amp; \\text{si } \\alpha &gt; 2 \\end{cases}\\) Es una distribución asimétrica positiva, con cola pesada. Aplicaciones La distribución de Pareto es ampliamente utilizada en: Economía y distribución de la riqueza - Ley de Pareto (80/20): Una pequeña fracción de la población (el 20%) acumula una gran parte de la riqueza (el 80%). - Se usa para modelar distribuciones de ingreso o riqueza, especialmente en los niveles altos (cola de la distribución). Finanzas y seguros Modelado de pérdidas extremas o reclamaciones grandes. Distribución base en el análisis de riesgos de cola y modelos de ruina. Marketing y gestión empresarial Análisis de clientes: una pequeña parte genera la mayor parte de las ventas (clientes clave). Modelado del tamaño de empresas o número de productos vendidos. Ejemplos de cálculo con R - 1: Densidad - 2: Cáclulo de probabilidad directa Queremos calcular la probabilidad de que una variable aleatoria \\(X \\sim \\text{Pareto}(x_m = 1, \\alpha = 2)\\) tome un valor menor o igual que 3, es decir: \\[ P(X \\leq 3) \\] Usamos la función de distribución acumulada: \\[ F(x) = 1 - \\left( \\frac{x_m}{x} \\right)^\\alpha \\] xm &lt;- 1 alpha &lt;- 2 x &lt;- 3 # Probabilidad acumulada F &lt;- 1 - (xm / x)^alpha F # Resultado ≈ 0.8889 ## [1] 0.8888889 -3: Cálculo de probabilidad inversa Queremos encontrar el valor \\(x\\) tal que: \\[ P(X \\geq x) = 0.05 \\] Si \\(X \\sim \\text{Pareto}(x_m = 1, \\alpha = 2)\\), podemos utilizar la función de distribución acumulada inversa. Recordamos que: \\[ F(x) = 1 - \\left( \\frac{x_m}{x} \\right)^\\alpha \\quad \\Rightarrow \\quad x = x_m \\cdot (1 - p)^{-1/\\alpha} \\] Donde \\(p\\) es la probabilidad acumulada a la izquierda. # Parámetros xm &lt;- 1 alpha &lt;- 2 p &lt;- 0.05 # P(X ≥ x) = 0.05 → P(X ≤ x) = 0.95 # Cálculo del valor crítico x_critico &lt;- xm / (1 - p)^(1 / alpha) x_critico # Resultado ≈ 4.4721 ## [1] 1.025978 5.8 Resumen de las distribuciones continuas A continuación se presenta una tabla resumen con las principales distribuciones continuas tratadas en este tema: Distribución Variable Parámetros Soporte…x.. Densidad…f.x… Media Varianza Normal Variable continua simétrica \\(\\mu,\\ \\sigma\\) \\(\\mathbb{R}\\) \\(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\) \\(\\mu\\) \\(\\sigma^2\\) Exponencial Tiempo entre eventos \\(\\lambda\\) \\([0,\\infty)\\) \\(\\lambda e^{-\\lambda x}\\) \\(\\frac{1}{\\lambda}\\) \\(\\frac{1}{\\lambda^2}\\) Chi-cuadrado Suma de cuadrados normales estándar \\(k\\) \\([0,\\infty)\\) \\(\\frac{1}{2^{k/2}\\Gamma(k/2)} x^{k/2 - 1} e^{-x/2}\\) \\(k\\) \\(2k\\) t de Student Media muestral con varianza desconocida \\(n\\) \\(\\mathbb{R}\\) \\(\\frac{\\Gamma(\\frac{n+1}{2})}{\\sqrt{n\\pi}\\Gamma(n/2)} \\left(1 + \\frac{x^2}{n}\\right)^{-\\frac{n+1}{2}}\\) \\(0\\) si \\(n \\gt 1\\) \\(\\frac{n}{n - 2}\\) si \\(n \\gt 2\\) F de Snedecor Cociente de dos chi-cuadrado normalizados \\(n_1,\\ n_2\\) \\([0,\\infty)\\) \\(\\frac{\\Gamma((n_1 + n_2)/2)}{\\Gamma(n_1/2)\\Gamma(n_2/2)} \\cdot \\frac{(n_1/n_2)^{n_1/2} x^{n_1/2 - 1}}{(1 + \\frac{n_1}{n_2} x)^{(n_1+n_2)/2}}\\) \\(\\frac{n_2}{n_2 - 2}\\) si \\(n_2 \\gt 2\\) \\(\\frac{2n_2^2(n_1 + n_2 - 2)}{n_1(n_2 - 2)^2(n_2 - 4)}\\) si \\(n_2 \\gt 4\\) Gamma Variable con crecimiento exponencial \\(\\alpha,\\ \\beta\\) \\([0,\\infty)\\) \\(\\frac{1}{\\Gamma(\\alpha) \\beta^{\\alpha}} x^{\\alpha - 1} e^{-x/\\beta}\\) \\(\\alpha\\beta\\) \\(\\alpha\\beta^2\\) Beta Proporciones entre 0 y 1 \\(\\alpha,\\ \\beta\\) \\((0,1)\\) \\(\\frac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}\\) \\(\\frac{\\alpha}{\\alpha + \\beta}\\) \\(\\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\\) Pareto Distribución de ingresos/riqueza \\(x_m,\\ \\alpha\\) \\([x_m,\\infty)\\) \\(\\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}\\) \\(\\frac{\\alpha x_m}{\\alpha - 1}\\) si \\(\\alpha \\gt 1\\) \\(\\frac{\\alpha x_m^2}{(\\alpha - 1)^2(\\alpha - 2)}\\) si \\(\\alpha \\gt 2\\) 5.9 Funciones disponibles en R para distribuciones continuas R proporciona un conjunto de funciones estándar para trabajar con distribuciones de probabilidad continuas. Estas funciones permiten: Calcular la densidad de probabilidad: dxxx() Calcular la función de distribución acumulada: pxxx() Obtener valores críticos (cuantiles): qxxx() Simular valores aleatorios: rxxx() A continuación se resumen las funciones más comunes: Distribución Densidad Acumulada Cuantil Aleatoria Normal dnorm() pnorm() qnorm() rnorm() Exponencial dexp() pexp() qexp() rexp() Chi-cuadrado dchisq() pchisq() qchisq() rchisq() t de Student dt() pt() qt() rt() F de Snedecor df() pf() qf() rf() Gamma dgamma() pgamma() qgamma() rgamma() Beta dbeta() pbeta() qbeta() rbeta() Pareto (no base R) Ver más abajo Ver más abajo Ver más abajo Ver más abajo Nota: La distribución de Pareto no está incluida por defecto en R base. Para trabajar con ella se pueden definir funciones personalizadas o utilizar paquetes como VGAM o actuar. "],["conv.html", "Tema 6 Relación entre Distribuciones. Convergencia en Distribución 6.1 Introducción 6.2 Relaciones entre distribuciones 6.3 Convergencia en distribución 6.4 Ejercicios prácticos 6.5 Ejercicio guiado en R", " Tema 6 Relación entre Distribuciones. Convergencia en Distribución 6.1 Introducción En el estudio de los fenómenos aleatorios y en la modelización del azar, las distribuciones de probabilidad desempeñan un papel fundamental. No obstante, en muchas situaciones prácticas no se trabaja con distribuciones exactas, sino con aproximaciones. Comprender cómo se relacionan diferentes distribuciones y bajo qué condiciones una puede aproximarse por otra es una herramienta clave en el análisis de datos, en la inferencia estadística y en la toma de decisiones fundamentadas en incertidumbre. Este tema aborda dos ideas centrales. Por un lado, el estudio de las relaciones entre distribuciones permite simplificar cálculos complejos utilizando distribuciones límite o aproximadas. Por ejemplo, en vez de trabajar directamente con una distribución binomial con gran número de ensayos, puede resultar mucho más eficiente aproximarla por una normal. Estas aproximaciones son esenciales para desarrollar soluciones prácticas en contextos reales, donde la precisión absoluta cede paso a la eficiencia computacional y a la interpretabilidad. Por otro lado, se introduce el concepto de convergencia en distribución, una noción fundamental en probabilidad que explica cómo se comportan las distribuciones de ciertas variables aleatorias a medida que se incrementa el tamaño de la muestra o cambia un parámetro clave. Esta idea es la base teórica detrás del Teorema Central del Límite y sustenta muchas de las técnicas estadísticas modernas, desde la estimación mediante remuestreo (bootstrap) hasta el análisis asintótico de estimadores y contrastes. En el ámbito del análisis de datos, estas herramientas permiten justificar el uso de modelos simplificados en grandes volúmenes de datos, aplicar inferencias sobre parámetros poblacionales o entender el comportamiento de algoritmos estadísticos. En economía y empresa, facilitan la toma de decisiones bajo incertidumbre, el análisis de riesgos, la evaluación de políticas y la previsión basada en grandes muestras o en distribuciones derivadas de simulaciones. 6.2 Relaciones entre distribuciones En estadística y teoría de la probabilidad, es frecuente que una variable aleatoria se modele inicialmente con una cierta distribución, pero que para facilitar los cálculos o el análisis, se recurra a una distribución aproximada. Estas relaciones entre distribuciones son particularmente útiles cuando los parámetros de la distribución original se encuentran en ciertos rangos que permiten una buena aproximación. En este apartado se revisan algunas de las aproximaciones clásicas más utilizadas, así como ejemplos prácticos que ilustran sus condiciones de validez. 6.2.1 Aproximaciones clásicas Binomial ≈ Poisson La distribución binomial \\(B(n, p)\\) puede aproximarse por una distribución de Poisson \\(\\text{Po}(\\lambda)\\) cuando: \\(n\\) es grande, \\(p\\) es pequeño, y \\(\\lambda = np\\) se mantiene constante. Condiciones típicas: - \\(n \\geq 30\\) - \\(p \\leq 0.1\\) Esta aproximación es útil en contextos como la modelización de defectos poco frecuentes en procesos industriales o incidencias poco comunes en un gran número de observaciones. Binomial ≈ Normal Cuando \\(n\\) es grande, la distribución binomial puede aproximarse por una normal: \\[ B(n, p) \\approx \\mathcal{N}(np, np(1 - p)) \\] Condiciones típicas: - \\(np \\geq 5\\) - \\(n(1 - p) \\geq 5\\) Corrección por continuidad: Para mejorar la aproximación, se usa una corrección por continuidad. Por ejemplo, para calcular \\(P(X \\leq k)\\), se utiliza: \\[ P(Y \\leq k + 0.5), \\quad Y \\sim \\mathcal{N}(np, np(1-p)) \\] Esta aproximación es especialmente útil en análisis de proporciones, encuestas y estudios de comportamiento del consumidor. Poisson ≈ Normal Si \\(\\lambda\\) es suficientemente grande, una variable Poisson puede aproximarse por una normal: \\[ \\text{Po}(\\lambda) \\approx \\mathcal{N}(\\lambda, \\lambda) \\] Condición típica: - \\(\\lambda \\geq 10\\) Este caso aparece en problemas de conteo, como el número de llamadas en un centro de atención al cliente por minuto o el número de transacciones por segundo en una plataforma digital. ## Warning: package &#39;DiagrammeR&#39; was built under R version 4.3.3 Figura 1: Diagrama de las relaciones de aproximación entre la distribución binomial, Poisson y normal. Las flechas indican que una distribución sirve de aproximación a otra bajo las condiciones señaladas junto a cada flecha. Por ejemplo, una \\(B(n,p)\\) con \\(n\\) muy grande y \\(p\\) muy pequeño (de modo que \\(np\\) se mantiene aproximadamente constante) se puede aproximar mediante una \\(Poisson(n p)\\); si \\(np\\) y \\(n(1-p)\\) son bastante grandes, \\(B(n,p)\\) se aproxima bien por una normal; y si \\(\\lambda\\) es grande, \\(Poisson(\\lambda)\\) se aproxima por \\(\\mathcal{N}(\\lambda,\\lambda)\\). 6.2.2 Condiciones de validez para cada aproximación Las siguientes condiciones son orientativas y ayudan a decidir si una aproximación es razonable en la práctica: Binomial ≈ Poisson: válida cuando el número de ensayos \\(n\\) es grande (por ejemplo, \\(n \\geq 30\\)) y la probabilidad de éxito \\(p\\) es pequeña (por ejemplo, \\(p \\leq 0.1\\)), de forma que \\(\\lambda = np\\) se mantenga constante y de valor moderado. Binomial ≈ Normal: se recomienda que tanto \\(np \\geq 5\\) como \\(n(1 - p) \\geq 5\\). Además, la corrección por continuidad mejora significativamente la aproximación cuando \\(n\\) no es muy grande. Poisson ≈ Normal: adecuada cuando \\(\\lambda \\geq 10\\). A mayor valor de \\(\\lambda\\), mejor será la aproximación, ya que la distribución Poisson se vuelve más simétrica. Estas condiciones son de carácter práctico y deben verificarse antes de aplicar la aproximación. En caso contrario, se corre el riesgo de obtener resultados imprecisos. Aplicaciones prácticas: simplificación de cálculos, simulaciones, modelización en contexto económico y empresarial Estas aproximaciones son fundamentales en numerosos entornos de trabajo donde la eficiencia computacional, la rapidez de decisión y la claridad de interpretación son clave. Algunos ejemplos incluyen: Simplificación de cálculos: en vez de trabajar con sumas de probabilidades o combinatorias complicadas (como en la binomial), se puede utilizar una distribución más manejable como la normal, con funciones ya integradas en la mayoría de software estadísticos. Simulación de escenarios: en análisis de datos y econometría, las simulaciones con miles de repeticiones son comunes. Utilizar distribuciones límite (como la normal) permite generar datos de forma más rápida y con menor coste computacional. Modelización en economía y empresa: En estudios de mercado, se modelan proporciones (clientes que compran un producto, votantes que eligen una opción) mediante binomiales, que pueden aproximarse por normales en grandes muestras. En análisis de riesgos, incidentes o reclamaciones poco frecuentes (seguros, sistemas de calidad) se modelan con Poisson, y si el número esperado de eventos es alto, se emplea la normal. En logística o producción, el número de errores, fallos o llegadas a un sistema se puede modelar inicialmente con Poisson y luego aproximarse por normal si se cumplen las condiciones adecuadas. Estas aproximaciones también constituyen una introducción natural al uso de métodos asintóticos, fundamentales en técnicas modernas como los contrastes de hipótesis, la inferencia basada en simulación y el aprendizaje automático con grandes volúmenes de datos. Ejemplos con condiciones de validez A continuación se presentan algunos ejemplos ilustrativos que muestran cómo aplicar las aproximaciones mencionadas y en qué situaciones son válidas. Ejemplo 1: Binomial grande, Poisson como aproximación Supongamos que en una gran fábrica hay 10,000 productos y la probabilidad de que uno sea defectuoso es de 0.001. \\[ X \\sim B(10000, 0.001), \\quad \\lambda = np = 10 \\] Dado que \\(n\\) es grande y \\(p\\) es pequeño, podemos aproximar: \\[ X \\approx \\text{Po}(10) \\] Esto permite simplificar el cálculo de probabilidades como \\(P(X = 0)\\), \\(P(X \\leq 5)\\), etc., sin tener que calcular combinatorias. Ejemplo 2: Binomial a Normal con corrección Sea \\(X \\sim B(100, 0.4)\\). Queremos calcular \\(P(X \\geq 45)\\). Dado que \\(np = 40\\) y \\(n(1 - p) = 60\\), se cumple la condición para usar la normal. \\[ X \\approx \\mathcal{N}(40, 24) \\] Aplicamos la corrección por continuidad: \\[ P(X \\geq 45) \\approx P(Y \\geq 44.5), \\quad Y \\sim \\mathcal{N}(40, 24) \\] Este tipo de aproximación es habitual en estudios de población donde se analizan porcentajes de respuestas o elecciones en muestras grandes. Ejemplo 3: Poisson con parámetro alto Si el número de accidentes laborales mensuales sigue una Poisson con \\(\\lambda = 15\\), entonces: \\[ X \\sim \\text{Po}(15) \\approx \\mathcal{N}(15, 15) \\] Esto permite usar la normal para construir intervalos de confianza o contrastes, incluso si originalmente se partía de una distribución discreta. Estas relaciones entre distribuciones son esenciales para aplicar herramientas de inferencia estadística de forma eficiente, especialmente en escenarios donde el volumen de datos es elevado o el tiempo de cálculo es limitado. También constituyen la base intuitiva para introducir el concepto de convergencia en distribución, que será formalizado en el siguiente apartado. 6.3 Convergencia en distribución Hasta ahora hemos visto cómo algunas distribuciones pueden aproximarse por otras bajo ciertas condiciones. Sin embargo, para dar rigor a estas afirmaciones, es necesario entender en qué sentido una sucesión de distribuciones se aproxima a una distribución límite. Esto nos lleva al concepto fundamental de convergencia de variables aleatorias, y en particular a la convergencia en distribución, también conocida como convergencia débil. Entre los distintos tipos de convergencia existentes en teoría de la probabilidad, la convergencia en distribución es especialmente relevante en estadística porque: Permite justificar aproximaciones como \\(B(n, p) \\approx \\mathcal{N}(np, np(1-p))\\) o \\(\\text{Poisson}(\\lambda) \\approx \\mathcal{N}(\\lambda, \\lambda)\\). Aparece de forma natural en resultados fundamentales como el Teorema Central del Límite. Se emplea para estudiar el comportamiento asintótico de estadísticos y estimadores cuando el tamaño muestral tiende a infinito. Es la base teórica de técnicas modernas como el bootstrap o la validación empírica por simulación. A diferencia de otras formas más fuertes de convergencia, como la convergencia en probabilidad o en media cuadrática, la convergencia en distribución no requiere que las variables aleatorias estén definidas en un mismo espacio de probabilidad ni que las realizaciones individuales se acerquen. Solo exige que las funciones de distribución acumulada converjan. En este apartado, exploraremos primero los distintos tipos de convergencia para situar la convergencia en distribución en su contexto teórico. A continuación, abordaremos el Teorema Central del Límite, la convergencia de las distribuciones empíricas, y finalizaremos con aplicaciones relevantes en economía, empresa y análisis de datos. 6.3.1 Tipos de convergencia y definición formal En teoría de la probabilidad, es fundamental distinguir entre los distintos tipos de convergencia de sucesiones de variables aleatorias. Cada tipo de convergencia expresa una forma diferente en la que una secuencia de variables aleatorias puede aproximarse a una variable aleatoria límite. Estas nociones son esenciales tanto desde un punto de vista teórico como aplicado, especialmente en estadística asintótica y modelización del azar. A continuación se presentan los principales tipos de convergencia, ordenados de más fuerte a más débil: 6.3.1.1 Convergencia casi segura (convergencia con probabilidad) Se dice que una sucesión de variables aleatorias \\(X_n\\) converge casi seguramente a una variable aleatoria \\(X\\) si: \\[ P\\left( \\lim_{n \\to \\infty} X_n = X \\right) = 1 \\] Esta forma de convergencia asegura que las realizaciones de \\(X_n\\) se aproximan indefinidamente a las de \\(X\\), salvo en un conjunto de probabilidad cero. 6.3.1.2 Convergencia en probabilidad Se dice que \\(X_n \\xrightarrow{P} X\\) si, para todo \\(\\varepsilon &gt; 0\\): \\[ \\lim_{n \\to \\infty} P(|X_n - X| &gt; \\varepsilon) = 0 \\] Es decir, la probabilidad de que \\(X_n\\) esté lejos de \\(X\\) se hace cada vez más pequeña a medida que \\(n\\) crece. 6.3.1.3 Convergencia en media \\(r\\)-ésima (por ejemplo, en media cuadrática) Se dice que \\(X_n \\xrightarrow{L^r} X\\) si: \\[ \\lim_{n \\to \\infty} \\mathbb{E}[|X_n - X|^r] = 0 \\] Un caso particular importante es \\(r = 2\\), conocido como convergencia en media cuadrática. Esta convergencia implica la convergencia en probabilidad bajo ciertas condiciones. 6.3.1.4 Convergencia en distribución (o en ley) Se dice que \\(X_n \\xrightarrow{d} X\\) si la función de distribución acumulada \\(F_{X_n}(x)\\) converge puntualmente a \\(F_X(x)\\) en los puntos de continuidad de \\(F_X\\): \\[ \\lim_{n \\to \\infty} F_{X_n}(x) = F_X(x) \\] Esta es la forma más débil de convergencia y la más utilizada en estadística inferencial, ya que permite estudiar el comportamiento asintótico de secuencias de variables aleatorias sin requerir convergencia en términos más fuertes. 6.3.1.5 Relación entre los tipos de convergencia Las implicaciones entre los distintos tipos de convergencia pueden resumirse en el siguiente esquema: \\[ \\text{Casi segura} \\Rightarrow \\text{En probabilidad} \\Rightarrow \\text{En distribución} \\] Además: \\[ \\text{En media cuadrática ($L^2$)} \\Rightarrow \\text{En probabilidad} \\] Sin embargo, las implicaciones no se dan en sentido contrario: - La convergencia en distribución no implica convergencia en probabilidad. - La convergencia en probabilidad no implica convergencia casi segura ni en media. - La convergencia en distribución puede darse incluso si \\(X_n\\) y \\(X\\) no están definidas en el mismo espacio de probabilidad. Esta jerarquía de convergencias proporciona el marco formal necesario para entender los resultados asintóticos y las aproximaciones entre distribuciones que estudiaremos en los siguientes apartados. Figura 2. Jerarquía entre tipos de convergencia 6.3.2 Teorema Central del Límite (TCL) El Teorema Central del Límite (TCL) es uno de los resultados más importantes de la teoría de la probabilidad y constituye la base teórica de muchas técnicas estadísticas. Justifica por qué en muchos contextos, incluso cuando los datos individuales no siguen una distribución normal, la distribución de ciertos estadísticos tiende a ser normal cuando el tamaño muestral es grande. Definición Sea \\(X_1, X_2, \\dots, X_n\\) una sucesión de variables aleatorias independientes e idénticamente distribuidas (i.i.d.) con: \\(\\mathbb{E}(X_i) = \\mu\\) \\(\\text{Var}(X_i) = \\sigma^2 &lt; \\infty\\) Entonces, la variable aleatoria: \\[ Z_n = \\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\quad \\text{donde} \\quad \\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\] converge en distribución a una normal estándar: \\[ Z_n \\xrightarrow{d} \\mathcal{N}(0,1) \\] Interpretación intuitiva Aunque los datos individuales \\(X_i\\) no estén normalmente distribuidos, al tomar una media de muchas observaciones (muestra grande), la distribución de esa media se aproxima a una normal. Cuanto mayor es el tamaño de la muestra, mejor es la aproximación. Por simplicicdad, en la definición se ha supuesto que las medias y varianzas de las variables aleatorias eran iguales, sin embargo ese supuesto no es necesario, y se puede hacer con cualquier media o varianza. En el siguiente link se explica muy claramente esta afirmación. (.https://bookdown.org/aquintela/EBE/el-teorema-central-del-limite.html) Este resultado explica por qué la distribución normal aparece con tanta frecuencia en estadística, incluso cuando los fenómenos originales no son normales. Ejemplos de aplicación en análisis de datos y economía Encuestas: al calcular la media de respuestas de una muestra grande (por ejemplo, gasto mensual), el TCL permite aproximar la distribución de la media por una normal, lo cual es clave para construir intervalos de confianza y realizar contrastes de hipótesis. Análisis financiero: al modelar rendimientos medios de activos financieros en periodos largos, el TCL justifica el uso de herramientas normales, incluso si los rendimientos individuales tienen colas pesadas o asimetría. Control de calidad: en procesos industriales donde se toma una muestra de productos, el TCL permite estimar con precisión el valor medio del parámetro de interés (por ejemplo, peso, tamaño, tiempo de fabricación). Relación con las aproximaciones vistas El Teorema Central del Límite justifica las aproximaciones que hemos visto anteriormente, como: \\(B(n,p) \\approx \\mathcal{N}(np, np(1-p))\\) \\(\\text{Poisson}(\\lambda) \\approx \\mathcal{N}(\\lambda, \\lambda)\\) En ambos casos, lo que subyace es que se están sumando muchas variables aleatorias independientes (Bernoulli o indicadores de ocurrencia), y su suma se aproxima a una normal, tal como predice el TCL. Este teorema es esencial en inferencia estadística porque permite aplicar métodos basados en la normalidad en una gran variedad de contextos, incluso cuando los datos originales no son normales. 6.3.3 Convergencia de distribuciones empíricas \\(F_n\\) En estadística aplicada y en ciencia de datos es habitual trabajar con muestras y estimar la distribución de una variable aleatoria a partir de sus valores observados. Una herramienta fundamental para ello es la función de distribución empírica, que permite aproximar la distribución teórica a partir de una muestra. Distribución empírica \\(F_n\\) Dada una muestra aleatoria \\(X_1, X_2, \\dots, X_n\\) de una variable aleatoria \\(X\\), se define la función de distribución empírica como: \\[ F_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}_{\\{X_i \\leq x\\}} \\] donde \\(\\mathbb{I}_{\\{X_i \\leq x\\}}\\) es una función indicadora que vale 1 si \\(X_i \\leq x\\) y 0 en caso contrario. \\(F_n(x)\\) representa la proporción de valores de la muestra que son menores o iguales que \\(x\\), y constituye una estimación natural de la función de distribución verdadera \\(F(x)\\). Convergencia de \\(F_n\\) a \\(F\\) A medida que aumenta el tamaño muestral \\(n\\), la función de distribución empírica \\(F_n(x)\\) converge a la verdadera función de distribución \\(F(x)\\). Esta convergencia se produce uniformemente en todos los puntos \\(x\\), y se puede expresar formalmente como: \\[ \\sup_x |F_n(x) - F(x)| \\xrightarrow{a.s.} 0 \\] Esta es una forma fuerte de convergencia (convergencia casi segura), y garantiza que, con suficiente tamaño muestral, la distribución empírica se aproxima arbitrariamente bien a la real. Teorema de Glivenko-Cantelli (opcional) Este resultado formaliza la convergencia uniforme de la distribución empírica: Sea \\(X_1, X_2, \\dots, X_n\\) una muestra i.i.d. de una variable con función de distribución \\(F\\). Entonces: \\[ \\sup_x |F_n(x) - F(x)| \\xrightarrow{a.s.} 0 \\quad \\text{cuando } n \\to \\infty \\] Este teorema garantiza que, con probabilidad 1, la distribución empírica converge uniformemente a la distribución real a medida que el tamaño muestral crece. Aplicación práctica La distribución empírica es ampliamente utilizada en: Visualización de datos: al comparar \\(F_n(x)\\) con distribuciones teóricas (gráficas Q-Q o P-P). Simulación y bootstrap: se parte de \\(F_n\\) para generar nuevas muestras (remuestreo con reemplazo). Contrastes no paramétricos: como el test de Kolmogórov-Smirnov, que mide la distancia entre \\(F_n\\) y una distribución teórica. 6.3.4 Ejemplos y visualizaciones Ejemplo 1: Convergencia en media cuadrática pero no casi seguramente Este ejemplo muestra que la convergencia en media cuadrática no implica necesariamente la convergencia casi segura. Simularemos una sucesión de variables aleatorias \\(X_n\\) definida de la siguiente manera: \\[ X_n = \\begin{cases} 1 &amp; \\text{con probabilidad } \\frac{1}{n} \\\\ 0 &amp; \\text{con probabilidad } 1 - \\frac{1}{n} \\end{cases} \\] Esto significa que a medida que \\(n\\) crece, la probabilidad de que \\(X_n = 1\\) disminuye, pero nunca es cero. ¿Qué vamos a observar? Convergencia en media cuadrática: la esperanza \\(\\mathbb{E}(X_n^2) = \\mathbb{E}(X_n) = \\frac{1}{n} \\to 0\\). Veremos que el promedio de los cuadrados de los \\(X_n\\) tiende a 0. ¿Convergencia casi segura?: veremos que, aunque los valores de \\(X_n\\) son mayoritariamente ceros, nunca dejan de aparecer algunos unos (saltos). Por tanto, no hay una realización fija hacia la que todos los \\(X_n\\) tiendan. Simulación en R Conclusión Sí hay convergencia en media cuadrática: En el gráfico de la izquierda observamos que la media de los cuadrados de los \\(X_n\\) tiende a 0 cuando \\(n\\) crece. Esto confirma que la sucesión \\(X_n\\) converge a 0 en media cuadrática. No hay convergencia casi segura: En el gráfico de la derecha vemos que, aunque los unos aparecen cada vez con menos frecuencia, nunca desaparecen del todo. Es decir, por grande que sea \\(n\\), siempre existe una probabilidad (aunque pequeña) de que \\(X_n = 1\\). Por tanto, no hay una realización de la sucesión que se mantenga fija a partir de cierto punto, y eso viola la definición de convergencia casi segura. Este ejemplo demuestra que la convergencia en media cuadrática no implica convergencia casi segura. Es una excelente ilustración de la jerarquía entre tipos de convergencia y de por qué no deben confundirse. Ejemplo 2: El método bootstrap como aplicación de la convergencia de \\(F_n\\) El método bootstrap es una técnica de remuestreo que permite estimar la distribución de un estadístico (como la media, la mediana, o la varianza) a partir de una única muestra. En lugar de asumir una distribución teórica concreta, se utiliza la distribución empírica \\(F_n\\) como una aproximación de la distribución real de los datos. La idea central del bootstrap es que si \\(F_n\\) se aproxima bien a la distribución verdadera \\(F\\), entonces al generar nuevas muestras (con reemplazo) a partir de los datos observados, podemos simular el comportamiento del estadístico como si estuviéramos muestreando del modelo original. ¿Qué se persigue? Queremos estimar la distribución de la media muestral sin conocer la distribución de la población original. Para ello: Tomamos una muestra original de tamaño \\(n\\). Generamos muchas muestras bootstrap de tamaño \\(n\\), remuestreando con reemplazo de la muestra original. Calculamos la media en cada una de esas muestras bootstrap. Observamos cómo se distribuyen esas medias y comparamos su forma con la predicha por el Teorema Central del Límite. Se observa que la distribución de las medias bootstrap: Se aproxima a una normal cuando \\(n\\) es suficientemente grande. Tiene una dispersión similar a la que tendría la distribución real del estadístico si se repitiera el muestreo desde la población. ¿Cuál es el resultado? El bootstrap simula la distribución del estadístico sin necesidad de conocer la verdadera distribución de los datos. Y, gracias a la convergencia en distribución y al hecho de que \\(F_n \\to F\\), esta aproximación es cada vez más precisa conforme aumenta el tamaño muestral. El ejemplo que sigue permite visualizar cómo el bootstrap se apoya en la distribución empírica y en el Teorema Central del Límite para generar inferencias válidas de forma no paramétrica. Resultados de la estimación de la distribución de la media mediante bootstrap Vamos a aplicar el método bootstrap para estimar la distribución de la media muestral a partir de una sola muestra. Usaremos una variable con distribución desconocida (en este caso una exponencial) y observaremos cómo el bootstrap reproduce la forma de la distribución del estadístico. Interpretación La distribución de las medias bootstrap (en azul) se ajusta notablemente bien a una distribución normal (curva roja), a pesar de que la variable original sigue una distribución exponencial (asimétrica y no normal). Esto confirma el poder del Teorema Central del Límite y la validez del uso de \\(F_n\\) (la distribución empírica) para aproximar la distribución de un estadístico. Este procedimiento permite construir intervalos de confianza o estimar errores estándar sin necesidad de asumir una distribución poblacional conocida. Ejemplo 3: Comparación de \\(F_n\\) y \\(F\\) con el test de Kolmogórov-Smirnov Este ejemplo muestra cómo se mide formalmente la diferencia entre la distribución empírica \\(F_n(x)\\) y la distribución teórica \\(F(x)\\) usando el estadístico de Kolmogórov-Smirnov, definido como: \\[ D_n = \\sup_x |F_n(x) - F(x)| \\] Queremos observar cómo \\(D_n\\) disminuye al aumentar el tamaño muestral, lo que ilustra la convergencia uniforme de \\(F_n\\) a \\(F\\), como afirma el Teorema de Glivenko-Cantelli. Simulación en R Interpretación El estadístico \\(D\\) mide la máxima diferencia vertical entre la función de distribución empírica \\(F_n(x)\\) y la función de distribución teórica \\(F(x)\\). En los gráficos se observa que, a medida que aumenta el tamaño de la muestra \\(n\\), la curva empírica \\(F_n(x)\\) se ajusta cada vez mejor a la curva teórica \\(F(x)\\). La distancia \\(D\\) disminuye con \\(n\\), lo que ilustra de forma empírica el Teorema de Glivenko-Cantelli, que afirma que \\(F_n(x) \\to F(x)\\) uniformemente con probabilidad 1. Este ejemplo muestra cómo la convergencia de la distribución empírica no solo es una herramienta teórica, sino que tiene aplicaciones prácticas directas como el test de Kolmogórov-Smirnov, muy utilizado en análisis no paramétrico y validación de modelos. Ejemplo 4 del TCL: Ingresos de clientes (distribución exponencial) Supongamos que los ingresos diarios de ciertos clientes en una empresa siguen una distribución exponencial con media 100. Esta distribución es muy asimétrica, lo cual la aleja de una normal. Queremos ver cómo se comporta la distribución de la media muestral para distintos tamaños de muestra. Interpretación: aunque la distribución original es claramente no normal (muy asimétrica), la distribución de la media muestral se va aproximando a una normal a medida que aumenta el tamaño de la muestra, como predice el TCL. Ejemplo 5 del TCL: Tiempo de respuesta de clientes (distribución uniforme) Supongamos ahora que el tiempo de respuesta de los clientes ante una campaña publicitaria sigue una distribución uniforme entre 0 y 10 minutos. Esta distribución es simétrica pero no normal. Observamos cómo evoluciona la distribución de la media muestral a medida que aumenta el tamaño de la muestra. Interpretación: aunque la variable original (tiempo de respuesta) no sigue una normal sino una distribución uniforme, la distribución de la media muestral se aproxima progresivamente a una distribución normal a medida que se incrementa el tamaño de la muestra. Esto confirma empíricamente el Teorema Central del Límite y justifica por qué podemos utilizar herramientas basadas en la normalidad (como intervalos de confianza o contrastes) incluso con variables originales no normales, siempre que el tamaño de muestra sea suficientemente grande. Ejemplo 6 de convergencia en distribución: Distribución normal estándar A continuación ilustramos mediante una simulación en R cómo la función de distribución empírica \\(F_n\\) se aproxima a la función de distribución teórica \\(F\\) al aumentar el tamaño muestral, tal como garantiza el Teorema de Glivenko-Cantelli. Generamos tres muestras de tamaños crecientes \\(n = 10, 50, 500\\) de una distribución normal estándar, y comparamos sus funciones de distribución empíricas \\(F_n(x)\\) con la distribución acumulada teórica \\(\\Phi(x)\\). Interpretación: En los tres gráficos se comparan las funciones de distribución empíricas \\(F_n(x)\\) con la función teórica \\(\\Phi(x)\\) de la normal estándar, para distintos tamaños muestrales \\(n = 10, 50, 500\\). Cuando \\(n = 10\\), la función empírica presenta saltos y desviaciones notables respecto a la distribución teórica. Con \\(n = 50\\), los saltos son menores y el ajuste mejora, aunque sigue habiendo variabilidad. A partir de \\(n = 500\\), \\(F_n(x)\\) se aproxima muy bien a \\(\\Phi(x)\\), y apenas se distinguen visualmente. Este comportamiento confirma el Teorema de Glivenko-Cantelli, que garantiza que la función de distribución empírica converge uniformemente a la verdadera función de distribución cuando el tamaño de la muestra tiende a infinito. Este ejemplo también refuerza la utilidad de \\(F_n(x)\\) en estadística aplicada, ya que permite aproximar la distribución de una variable aleatoria a partir de observaciones reales, incluso cuando se desconoce su forma exacta. 6.3.5 Aplicaciones en Economía, empresa y análisis de datos El concepto de convergencia en distribución no es solo una herramienta teórica, sino que se encuentra en el núcleo de muchas aplicaciones modernas en análisis de datos, economía y empresa. Su utilidad principal radica en que permite justificar el uso de distribuciones límite (como la normal) para estadísticos muestrales, incluso cuando los datos originales no siguen distribuciones conocidas. A continuación se presentan algunas aplicaciones representativas: 1. Justificación asintótica de contrastes y estimadores Muchos procedimientos de inferencia estadística, como los contrastres de hipótesis y los intervalos de confianza, se basan en el hecho de que ciertos estadísticos convergen en distribución a una normal. Por ejemplo: La media muestral \\(\\overline{X}\\) converge a \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\) bajo condiciones generales (por el TCL). En regresión lineal, los estimadores de mínimos cuadrados ordinarios convergen en distribución a una normal multivariante. Esto permite aplicar resultados normales incluso si la población no es normal, siempre que el tamaño muestral sea grande. 2. Bootstrap y remuestreo El método bootstrap se basa en el principio de aproximar la distribución en el muestreo de un estadístico (media, mediana, etc.) a través de remuestreo con reemplazo. Bajo ciertas condiciones, se demuestra que la distribución bootstrap converge en distribución a la misma distribución límite que tendría el estadístico original. Este enfoque es especialmente útil en: Estimación de errores estándar sin fórmulas analíticas. Construcción de intervalos de confianza en muestras pequeñas. Evaluación de la robustez de estimadores. 3. Evaluación de políticas económicas basada en grandes muestras En estudios de impacto de políticas públicas o programas sociales, se suele estimar el efecto medio del tratamiento (por ejemplo, un subsidio o reforma). Si se cuenta con una muestra grande, la distribución del estimador converge a una normal, lo que permite construir intervalos de confianza o realizar contrastes utilizando esta distribución límite, incluso si la distribución original de los datos es asimétrica o presenta colas pesadas. 4. Inferencia para big data En contextos de grandes volúmenes de datos (por ejemplo, comportamiento de usuarios, datos financieros de alta frecuencia, registros administrativos masivos), no siempre se conoce la distribución exacta de las variables de interés. Sin embargo, gracias a la convergencia en distribución, es posible: Utilizar inferencia basada en resultados asintóticos. Justificar la validez de algoritmos de aprendizaje estadístico. Evaluar el comportamiento de modelos de predicción en muestras grandes. La convergencia en distribución permite aplicar resultados normales y métodos de simulación en una amplia gama de problemas económicos y empresariales, facilitando el análisis de fenómenos complejos incluso cuando las distribuciones originales son desconocidas o difíciles de manejar. 6.4 Ejercicios prácticos Ejercicio 1. Aproximación de la binomial por la distribución de Poisson Supongamos que en una fábrica se producen piezas electrónicas con una probabilidad de defecto del 1%. Si se inspecciona una muestra de 100 piezas: Sea \\(X \\sim B(100, 0.01)\\) el número de piezas defectuosas. Queremos calcular \\(P(X = 2)\\), es decir, la probabilidad de encontrar exactamente 2 defectuosos. Se pide: Calcular \\(P(X = 2)\\) exactamente usando la fórmula de la binomial. Aproximar \\(P(X = 2)\\) usando una distribución de Poisson. Comparar ambos resultados e interpretar. Solución 1. Cálculo exacto con la distribución binomial: \\[ P(X = 2) = \\binom{100}{2} \\cdot (0.01)^2 \\cdot (0.99)^{98} \\] Calculamos: \\(\\binom{100}{2} = \\frac{100 \\cdot 99}{2} = 4950\\) \\((0.01)^2 = 0.0001\\) \\((0.99)^{98} \\approx 0.366\\) Entonces: \\[ P(X = 2) \\approx 4950 \\cdot 0.0001 \\cdot 0.366 = 0.181 \\] 2. Aproximación con una distribución de Poisson: Usamos que si \\(X \\sim B(n, p)\\), con \\(n\\) grande y \\(p\\) pequeño, entonces: \\[ X \\approx \\text{Poisson}(\\lambda = np) = \\text{Poisson}(1) \\] Entonces: \\[ P(X = 2) \\approx \\frac{1^2}{2!} e^{-1} = \\frac{1}{2} \\cdot \\frac{1}{e} \\approx 0.184 \\] Como resultado se ha obtenido: Exacto (binomial): \\(P(X = 2) \\approx 0.181\\) Aproximado (Poisson): \\(P(X = 2) \\approx 0.184\\) La diferencia es mínima: la aproximación de Poisson simplifica los cálculos y es muy aceptable en este caso, ya que \\(n = 100\\) es suficientemente grande y \\(p = 0.01\\) es pequeño. Interpretación: Este ejercicio muestra cómo aplicar la aproximación binomial → Poisson, una herramienta práctica cuando el número de ensayos es grande y la probabilidad de éxito es pequeña. Es útil en contextos donde calcular la binomial exacta puede ser costoso, y demuestra cómo las relaciones entre distribuciones permiten simplificar problemas sin perder precisión significativa. Ejercicio 2. Aproximación de la binomial por la distribución normal Una empresa realiza un estudio sobre el cumplimiento puntual de sus envíos. Se sabe que, históricamente, el 80% de los pedidos se entregan a tiempo. Se selecciona una muestra aleatoria de 100 envíos. Sea \\(X \\sim B(100, 0.8)\\) el número de pedidos entregados puntualmente. Queremos estimar la probabilidad de que al menos 85 pedidos lleguen a tiempo, es decir, \\(P(X \\geq 85)\\), usando: La fórmula exacta de la binomial (solo se planteará, no se calculará a mano). La distribución normal sin corrección por continuidad. La distribución normal con corrección por continuidad. Comparación e interpretación. Solución Parámetros de la binomial: \\[ n = 100, \\quad p = 0.8, \\quad \\mu = np = 80, \\quad \\sigma = \\sqrt{np(1 - p)} = \\sqrt{100 \\cdot 0.8 \\cdot 0.2} = \\sqrt{16} = 4 \\] 1. Cálculo exacto (no se desarrolla): \\[ P(X \\geq 85) = \\sum_{x=85}^{100} \\binom{100}{x} (0.8)^x (0.2)^{100 - x}=0.0951 \\] # Parámetros n &lt;- 100 p &lt;- 0.8 # Cálculo exacto de P(X &gt;= 85) prob_exacta &lt;- pbinom(84, size = n, prob = p, lower.tail = FALSE) prob_exacta ## [1] 0.1285055 Es complejo para hacerlo a mano ⇒ se recurre a una aproximación (si se hiciera a mano habría que calcular 16 probabilidades individuales para agregarlas, por lo que es muy laborioso y se muestra con R). 2. Aproximación normal sin corrección por continuidad: Explicación del cálculo con distribución normal Para aproximar la probabilidad \\(P(X \\geq 85)\\) cuando \\(X \\sim B(100, 0.8)\\), se utiliza una distribución normal con la misma media y desviación típica: \\(\\mu = np = 100 \\cdot 0.8 = 80\\) \\(\\sigma = \\sqrt{np(1 - p)} = \\sqrt{100 \\cdot 0.8 \\cdot 0.2} = \\sqrt{16} = 4\\) En este caso (sin correción por continuidad), se sustituye directamente la binomial por una normal: \\[ P(X \\geq 85) \\approx P(Z \\geq \\frac{85 - 80}{4}) = P(Z \\geq 1.25) \\] Buscando en la tabla de la normal estándar: \\[ P(Z \\geq 1.25) = 1 - F(1.25) \\approx 1 - 0.8944 = 0.1056 \\] 3. Aproximación normal con corrección por continuidad: La corrección por continuidad consiste en ajustar el valor discreto al entorno continuo. Como queremos \\(P(X \\geq 85)\\), pasamos a: \\[ P(Y \\geq 84.5), \\quad \\text{donde } Y \\sim \\mathcal{N}(80, 4) \\] Entonces: \\[ Z = \\frac{84.5 - 80}{4} = 1.125 \\] \\[ P(Z \\geq 1.125) = 1 - F(1.125) \\approx 1 - 0.8690 = 0.1310 \\] Nota didáctica: ¿Por qué se aplica la corrección por continuidad? Cuando usamos la distribución normal para aproximar una binomial, debemos tener en cuenta que: La binomial es discreta. La normal es continua. Por ejemplo: \\[ P(X \\geq 85) = P(X = 85) + P(X = 86) + \\cdots + P(X = 100) \\] En la normal se calcula el área bajo la curva, por eso se sustituye por: \\[ P(X \\geq 85) \\approx P(Y \\geq 84.5) \\] Regla práctica: Binomial Normal (con corrección) \\(P(X \\geq k)\\) \\(P(Y \\geq k - 0.5)\\) \\(P(X \\leq k)\\) \\(P(Y \\leq k + 0.5)\\) \\(P(X = k)\\) \\(P(k - 0.5 &lt; Y &lt; k + 0.5)\\) La corrección mejora el ajuste porque tiene en cuenta que la binomial toma valores discretos, mientras que la normal es continua. \\[ Z = \\frac{85 - 80}{4} = 1.25 \\] \\[ P(X \\geq 85) \\approx P(Z \\geq 1.25) = 1 - F(1.25) \\approx 1 - 0.8944 = 0.1056 \\] \\[ P(X \\geq 85) \\approx P(Y \\geq 84.5), \\quad Y \\sim \\mathcal{N}(80, 16) \\] \\[ Z = \\frac{84.5 - 80}{4} = 1.125 \\] \\[ P(Z \\geq 1.125) = 1 - \\Phi(1.125) \\approx 1 - 0.869 = 0.131 \\] Como resultado tenemos: Método Probabilidad aproximada Binomial exacta 0.095 Normal sin corrección 0.106 Normal con corrección 0.131 Interpretación: - La aproximación normal es válida porque se cumplen las condiciones: \\(np = 80 \\geq 5\\), \\(n(1 - p) = 20 \\geq 5\\) - La corrección por continuidad mejora el ajuste, ya que la binomial es discreta y la normal es continua. - Este tipo de aproximación permite resolver problemas de forma rápida en estudios de calidad, logística o análisis de eficiencia. El ejercicio refuerza el papel del Teorema Central del Límite como herramienta para pasar de una distribución discreta a una continua. ❓ ¿Por qué la corrección por continuidad se aleja más del valor exacto en este caso? En el ejemplo de la aproximación binomial-normal: Método Probabilidad aproximada Binomial exacta 0.095 Normal sin corrección 0.106 Normal con corrección 0.131 Aunque la corrección por continuidad se considera una mejora técnica, no siempre se traduce en una mejor aproximación numérica. En este caso, la normal con corrección da un valor más lejano al exacto que la normal sin corregir.  ¿Por qué ocurre? La corrección por continuidad ajusta la normal (continua) a la binomial (discreta) desplazando el umbral: \\(P(X \\geq 85) \\rightarrow P(Y \\geq 84.5)\\) Esto amplía el área bajo la curva, aumentando la probabilidad estimada. En los extremos de la distribución (colas), la binomial y la normal pueden diferir más. La normal tiende a sobreestimar las colas. La corrección mejora el ajuste estructural, pero puede exagerar la probabilidad cuando se trata de eventos poco frecuentes. ✅ Conclusión didáctica La corrección por continuidad mejora la adaptación entre una distribución continua y una discreta, pero no garantiza un ajuste numérico más preciso en todos los casos. Lo importante es que respeta mejor la estructura de la binomial, especialmente cuando se trabaja con rangos o se realizan contrastes. Ejercicio 3. Función de distribución empírica \\(F_n(x)\\) Se ha registrado el tiempo (en minutos) que tardan 8 empleados en resolver una tarea: \\[ \\{4, 6, 5, 3, 5, 4, 7, 6\\} \\] Se pide: Calcular la función de distribución empírica \\(F_n(x)\\) para esta muestra. Representar gráficamente \\(F_n(x)\\) (forma escalonada). Indicar el valor de \\(F_n(5)\\), \\(F_n(6.5)\\), y \\(F_n(10)\\). Interpretar qué significa \\(F_n(x)\\) y cómo se relaciona con la función de distribución teórica. Solución: Ordenamos los datos: \\[ \\{3, 4, 4, 5, 5, 6, 6, 7\\} \\] Recordamos la definición: \\[ F_n(x) = \\frac{\\text{número de observaciones} \\leq x}{n} \\] Donde \\(n = 8\\). Calculamos \\(F_n(x)\\) para los valores distintos observados: \\(x\\) \\(F_n(x)\\) 3 \\(\\frac{1}{8} = 0.125\\) 4 \\(\\frac{3}{8} = 0.375\\) 5 \\(\\frac{5}{8} = 0.625\\) 6 \\(\\frac{7}{8} = 0.875\\) 7 \\(\\frac{8}{8} = 1.000\\) Entre valores, la función se mantiene constante. \\(F_n(5) = 0.625\\) \\(F_n(6.5) = F_n(6) = 0.875\\) \\(F_n(10) = 1\\) (todos los valores son menores o iguales) Representación gráfica (escalonada) Pueden representarlo como una función escalonada que salta en cada valor observado. El salto en cada punto es de \\(\\frac{1}{8}\\), y se mantiene constante entre valores. Interpretación: La función \\(F_n(x)\\) representa la proporción acumulada de observaciones hasta \\(x\\). Es una herramienta muy útil para: Visualizar la distribución de los datos Comparar con distribuciones teóricas (como la normal o exponencial) Realizar tests de bondad de ajuste (como Kolmogórov-Smirnov) Servir como base para el bootstrap En este caso, por ejemplo, podemos decir que el 62.5% de los empleados tardaron 5 minutos o menos en completar la tarea. Ejercicio 4. Jerarquía entre tipos de convergencia Se presentan tres sucesiones de variables aleatorias \\(\\{X_n\\}\\), todas con valor esperado 0 y varianzas decrecientes. Se indica el tipo de convergencia que verifican respecto a una variable aleatoria \\(X \\equiv 0\\). En cada caso, responde: ¿Qué tipo de convergencia se verifica? ¿Qué se puede demostrar a partir de ella? ¿Qué otras convergencias no se pueden asegurar? Justifica tu razonamiento brevemente. Casos propuestos a) La sucesión \\(X_n\\) verifica que \\(\\mathbb{E}[(X_n - 0)^2] \\to 0\\) b) La sucesión \\(X_n\\) verifica que \\(P(|X_n| &gt; \\varepsilon) \\to 0\\) para todo \\(\\varepsilon &gt; 0\\) c) La sucesión \\(X_n\\) verifica que \\(P(\\lim_{n \\to \\infty} X_n = 0) = 1\\) Solución guiada  Caso a) Se verifica que: \\[ \\lim_{n \\to \\infty} \\mathbb{E}[|X_n|^2] = 0 \\] Esto es convergencia en media cuadrática hacia 0: \\[ X_n \\xrightarrow{L^2} 0 \\] Demostración: Por definición, la convergencia en media \\(r\\)-ésima se cumple si: \\[ \\mathbb{E}[|X_n - X|^r] \\to 0 \\] En este caso, con \\(r = 2\\) y \\(X = 0\\), se cumple. Esto implica: \\(X_n \\xrightarrow{P} 0\\) (convergencia en probabilidad) \\(X_n \\xrightarrow{d} 0\\) (convergencia en distribución) y no implica: No se puede concluir que \\(X_n \\to 0\\) casi seguramente. Tampoco garantiza que las trayectorias converjan punto a punto.  Caso b) Se verifica que: \\[ \\forall \\varepsilon &gt; 0,\\quad P(|X_n| &gt; \\varepsilon) \\to 0 \\] Esto es la definición de convergencia en probabilidad hacia 0: \\[ X_n \\xrightarrow{P} 0 \\] Demostración: La definición formal de convergencia en probabilidad se cumple directamente por hipótesis. Lo qué implica: \\(X_n \\xrightarrow{d} 0\\) (convergencia en distribución) y no implica: No implica convergencia en media cuadrática: podrían existir varianzas grandes pero con probabilidad concentrada. No implica convergencia casi segura.  Caso c) Se verifica que: \\[ P\\left( \\lim_{n \\to \\infty} X_n = 0 \\right) = 1 \\] Esto es convergencia casi segura (también llamada con probabilidad 1): \\[ X_n \\xrightarrow{a.s.} 0 \\] Demostración: La hipótesis coincide exactamente con la definición de convergencia casi segura. Lo que implica: \\(X_n \\xrightarrow{P} 0\\) \\(X_n \\xrightarrow{d} 0\\) y no implica: No implica convergencia en media cuadrática (podrían existir valores extremos poco frecuentes que inflen la varianza) Conclusión general Este ejercicio ilustra que: La convergencia casi segura es la más fuerte. La convergencia en distribución es la más débil. Cada tipo de convergencia implica otras más débiles, pero no al revés. Jerarquía: \\[ X_n \\xrightarrow{a.s.} X \\Rightarrow X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{d} X \\] \\[ X_n \\xrightarrow{L^2} X \\Rightarrow X_n \\xrightarrow{P} X \\] 6.5 Ejercicio guiado en R Supongamos que una empresa registra el número de unidades vendidas por día durante una semana: \\[ \\text{Ventas} = \\{12,\\ 9,\\ 13,\\ 16,\\ 8,\\ 14,\\ 11\\} \\] Queremos: Estimar la media de ventas por día. Estimar la distribución de la media mediante bootstrap. Comparar visualmente la distribución bootstrap con una distribución normal (Teorema Central del Límite). Reflexionar sobre el uso de aproximaciones en contextos con pocos datos. Resolución guiada con R set.seed(2025) # Datos originales ventas &lt;- c(12, 9, 13, 16, 8, 14, 11) n &lt;- length(ventas) # Estadístico original media_original &lt;- mean(ventas) media_original ## [1] 11.85714 # Bootstrap B &lt;- 5000 medias_bootstrap &lt;- replicate(B, mean(sample(ventas, size = n, replace = TRUE))) # Estimación normal según TCL media_hat &lt;- media_original sd_hat &lt;- sd(ventas) / sqrt(n) # Gráfico hist(medias_bootstrap, probability = TRUE, col = &quot;skyblue&quot;, breaks = 40, main = &quot;Distribución bootstrap de la media&quot;, xlab = &quot;Media muestral (bootstrap)&quot;, border = &quot;white&quot;) curve(dnorm(x, mean = media_hat, sd = sd_hat), add = TRUE, col = &quot;darkred&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Bootstrap&quot;, &quot;Normal (TCL)&quot;), fill = c(&quot;skyblue&quot;, NA), border = c(&quot;white&quot;, NA), lty = c(NA, 1), col = c(&quot;skyblue&quot;, &quot;darkred&quot;), bty = &quot;n&quot;) Interpretación: - El histograma representa la distribución empírica de la media de ventas por día, generada mediante remuestreo bootstrap a partir de la muestra original. - La curva representa la aproximación normal basada en el Teorema Central del Límite (TCL), utilizando la media y desviación típica estimadas de los datos originales. - Aunque la muestra es pequeña (\\(n = 7\\)), la distribución bootstrap ya muestra una forma aproximadamente simétrica y unimodal, próxima a una distribución normal. - Esto sugiere que la distribución de la media muestral converge en distribución hacia una normal, como predice el TCL. Además, se observa que: El bootstrap no necesita asumir normalidad de los datos originales. La aproximación normal basada en el TCL puede ser razonable incluso con muestras pequeñas, aunque con mayor incertidumbre. "],["ejercicios.html", "Tema 7 Ejercicios 7.1 Preguntas tipo test 7.2 Ejercicios a desarrollar", " Tema 7 Ejercicios 7.1 Preguntas tipo test 7.1.1 Preguntas tipo test – Tema 4: Distribuciones discretas T4.1 ¿Cuál es la esperanza de una variable aleatoria uniforme discreta \\(X \\sim \\mathcal{U}_d(1, 7)\\)? - A) 4 - B) 3.5 - C) 3 - D) 5 T4.2 La función de cuantía de una variable binomial \\(B(n, p)\\) es: - A) \\(p^x (1 - p)^{1 - x}\\) - B) \\(\\binom{n}{x} p^x (1 - p)^{n - x}\\) - C) \\(\\lambda^x e^{-\\lambda} / x!\\) - D) \\(\\frac{1}{n}\\) T4.3 Una variable \\(X \\sim \\text{Poisson}(\\lambda)\\) puede tomar: - A) Solo valores 0 y 1 - B) Valores entre 0 y 1 - C) Cualquier número real positivo - D)Cualquier entero no negativo T4.4 Si \\(X \\sim B(5, 0.4)\\), la probabilidad de obtener exactamente 2 éxitos es: - A) \\(\\binom{5}{2} \\cdot 0.4^2 \\cdot 0.6^3\\) - B) \\(0.5\\) - C) \\(\\binom{5}{2} \\cdot 0.6^2 \\cdot 0.4^3\\) - D) \\(\\frac{1}{5}\\) T4.5 La media de una variable Poisson con parámetro \\(\\lambda = 4\\) es: - A) 2 - B) 4 - C) 8 - D) 16 T4.6 La distribución binomial negativa \\(BN(r, p)\\) modela: - A) El número de éxitos en \\(r\\) ensayos - B) El número de fallos antes del \\(r\\)-ésimo éxito - C) El número total de ensayos - D) El número de éxitos entre dos fallos T4.7 Si una variable tiene una distribución geométrica \\(G(p)\\), entonces: - A) Tiene media \\(\\frac{1}{p}\\) - B) Puede tomar valores negativos - C) Se utiliza solo en muestras pequeñas - D) Tiene parámetro \\(\\lambda\\) T4.8 Una variable con distribución hipergeométrica: - A) Admite repeticiones - B) Tiene media \\(np\\) - C) Modela extracciones sin reemplazo - D) Tiene distribución normal T4.9 La distribución multinomial se utiliza para: - A) Modelar resultados de más de dos categorías - B) Experimentos con solo dos posibles resultados - C) Aproximar distribuciones normales - D) Datos continuos T4.10 ¿Cuál es la varianza de una variable \\(X \\sim \\text{Bernoulli}(0.3)\\)? 0.3 - B) 0.09 - C) 0.21 - D) 0.7 T4.11 La distribución uniforme discreta: - A) Asigna probabilidades diferentes a cada valor - B) Tiene media \\(\\frac{a + b}{2}\\) - C) Modela fracasos hasta el primer éxito - D) Tiene función de densidad continua T4.12 ¿Qué función R permite generar observaciones de una binomial negativa? - A) rbinom() - B) rbeta() - C) rnbinom() - D) rgamma() T4.13 La distribución de Poisson se puede usar como aproximación de la binomial cuando: - A) \\(n\\) es pequeño y \\(p\\) es alto - \\(n\\) es grande y \\(p\\) es pequeño - C) \\(p \\approx 0.5\\) - D) Solo hay un único ensayo T4.14 En una multinomial con \\(n = 10\\) y \\(p_1 = 0.3, p_2 = 0.7\\), ¿cuántas categorías tiene? - A) 1 - B) 2 - C) 3 - D) 10 T4.15 En una distribución geométrica \\(G(0.25)\\), la probabilidad de que el primer éxito ocurra en el tercer intento es: - A) \\(0.25 \\cdot 0.75^3\\) - B) \\(0.75 \\cdot 0.25^2\\) - C) \\(0.75^2 \\cdot 0.25\\) - D) \\(0.25^3\\) 7.1.2 Preguntas tipo test – Tema 5: Distribuciones continuas T5.1. Si \\(X \\sim \\mathcal{U}(2, 6)\\), su esperanza es: A) 2 B) 4 C) 6 D) 8 T5.2. En una distribución uniforme continua \\(\\mathcal{U}(a, b)\\), la densidad es: A) \\(\\frac{1}{b - a}\\) B) \\(\\frac{1}{b + a}\\) C) \\(\\frac{a}{b}\\) D) \\(\\frac{b}{a}\\) T5.3. Si \\(X \\sim \\mathcal{N}(10, 4)\\), su desviación típica es: A) 4 B) 2 C) 10 D) 6 T5.4. La función de densidad de la normal estándar \\(\\mathcal{N}(0,1)\\) alcanza su máximo en: A) 0 B) 1 C) -1 D) No tiene máximo T5.5. ¿Cuál de las siguientes afirmaciones sobre la normal estándar es correcta? A) Tiene varianza 1 y media 0 B) Tiene media 1 y varianza 0 C) Tiene media 0 y varianza 0 D) Tiene media 1 y varianza 1 T5.6. La distribución normal es simétrica respecto a: A) Su media B) Su mediana C) Su moda D) Todas las anteriores T5.7. Sea \\(Z \\sim \\mathcal{N}(0, 1)\\). Entonces \\(P(Z &lt; -1)\\) es: A) Aproximadamente 0.16 B) Aproximadamente 0.5 C) Aproximadamente 0.84 D) Aproximadamente 0.68 T5.8. Si \\(X \\sim \\mathcal{N}(100, 25)\\), entonces \\(Z = \\frac{X - 100}{5}\\) sigue: A) Una normal estándar B) Una gamma C) Una ji-cuadrado D) Una exponencial T5.9. La distribución \\(\\chi^2_n\\) solo toma: A) Valores negativos B) Valores reales C) Valores enteros D) Valores positivos T5.10. La esperanza de una variable \\(\\chi^2_n\\) es: A) \\(n\\) B) \\(\\sqrt{n}\\) C) \\(2n\\) D) \\(n - 1\\) T5.11. Una variable t de Student con \\(n\\) grados de libertad: A) Es simétrica B) Tiene colas más pesadas que la normal C) Se aproxima a la normal cuando \\(n \\to \\infty\\) D) Todas son correctas T5.12. En la distribución \\(F_{n_1,n_2}\\), los grados de libertad están asociados a: A) Dos varianzas B) Dos medias C) Dos esperanzas D) Dos proporciones T5.13. La distribución \\(F\\) de Snedecor: A) Es simétrica B) Solo toma valores positivos C) Es idéntica a la normal D) Tiene media 0 T5.14. Si \\(X \\sim \\text{Exp}(\\lambda)\\), entonces \\(E(X) =\\): A) \\(\\lambda\\) B) \\(\\frac{1}{\\lambda}\\) C) \\(\\lambda^2\\) D) \\(\\log(\\lambda)\\) T5.15. La función de densidad de la distribución exponencial es decreciente: A) Si \\(\\lambda &gt; 0\\) B) Solo si \\(\\lambda = 1\\) C) Nunca D) Siempre que \\(\\lambda &lt; 1\\) T5.16. La distribución exponencial es útil para modelar: A) El número de ensayos hasta un éxito B) El tiempo entre eventos C) Las proporciones de éxito D) Los ingresos por persona T5.17. La distribución gamma con parámetro \\(\\alpha = 1\\) coincide con: A) Una normal estándar B) Una Poisson C) Una exponencial D) Una beta T5.18. La distribución beta está definida sobre el intervalo: A) \\([0, \\infty)\\) B) \\((-\\infty, \\infty)\\) C) \\((0, 1)\\) D) \\([0, 1]\\) T5.19. Una beta \\(\\text{Beta}(\\alpha, \\beta)\\) puede usarse para modelar: A) Densidades de probabilidad entre 0 y 1 B) Proporciones C) Tasas de éxito D) Todas son correctas T5.20. La distribución de Pareto se caracteriza por: A) Cola pesada B) Densidad decreciente C) Aparece en la distribución de la riqueza D) Todas las anteriores T5.21. El Teorema Central del Límite justifica el uso de la normal cuando: A) La muestra es muy grande, sin importar la distribución original B) La variable es categórica C) Se estudia una muestra pequeña D) No hay independencia T5.22. Una función R que permite calcular la probabilidad acumulada de una normal es: A) rnorm() B) pnorm() C) qnorm() D) dnorm() T5.23. Para generar datos aleatorios de una \\(t_{10}\\), se usa: A) rt(10) B) rt(n = 100, df = 10) C) t(10) D) rstudent(10) T5.24. La distribución \\(\\chi^2\\) aparece al elevar al cuadrado: A) Una variable t B) Una variable normal estándar C) Una exponencial D) Una binomial T5.25. El cociente de dos variables \\(\\chi^2\\) independientes divididas por sus grados de libertad sigue: A) Una \\(t\\) B) Una normal C) Una \\(F\\) D) Una gamma 7.1.3 Preguntas tipo test – Tema 6: Convergencia en distribución T6.1 ¿Cuál es la condición principal para aproximar una binomial \\(B(n, p)\\) por una Poisson? A) \\(p \\to 1\\), \\(n \\to 0\\) B) \\(n\\) grande, \\(p\\) cercano a 1 C) \\(n \\to \\infty\\), \\(p \\to 0\\), \\(np = \\lambda\\) constante D) \\(p = 0.5\\) T6.2 Una binomial \\(B(n, p)\\) puede aproximarse por una normal cuando: A) \\(n\\) pequeño y \\(p \\to 0\\) B) \\(np &gt; 5\\), \\(n(1-p) &gt; 5\\) C) \\(n \\to \\infty\\), \\(p = 1\\) D) Siempre que \\(p \\ne 0.5\\) T6.3 La distribución Poisson puede aproximarse por una normal si: A) \\(\\lambda\\) es grande B) \\(\\lambda \\to 0\\) C) La variable es discreta D) No puede aproximarse por una normal T6.4 El Teorema Central del Límite afirma que: A) La media muestral tiende a una Poisson B) Toda variable tiende a una chi-cuadrado C) La suma de variables independientes tiende a una normal D) El número de observaciones se reduce a 1 T6.5 El TCL es válido cuando: A) Las variables tienen distribución simétrica B) Las variables son independientes con media y varianza finitas C) Las variables son categóricas D) Siempre que la muestra sea menor de 30 T6.6 Según el TCL, la variable que converge es: A) La media poblacional B) La proporción poblacional C) La media muestral D) La mediana T6.7 Sea \\(X_i \\sim U(0,1)\\). Entonces, por el TCL: A) La suma de los \\(X_i\\) converge a una uniforme B) La media de los \\(X_i\\) converge a una normal C) La varianza converge a una t D) Nada puede decirse T6.8 La aproximación binomial → normal requiere corrección de continuidad porque: A) La binomial es discreta y la normal continua B) Ambas son continuas C) La normal es más precisa D) La binomial tiene media 0 T6.9 La variable \\(Z = \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}\\) tiende a: A) Una distribución exponencial B) Una distribución normal C) Una distribución beta D) Una distribución t T6.10 ¿Qué distribución se utiliza para aproximar la distribución muestral de la media cuando el tamaño muestral es pequeño y la desviación típica poblacional es desconocida? A) Normal B) Binomial C) Exponencial D) t de Student T6.11 Una variable binomial negativa puede aproximarse por: A) Una t de Student B) Una normal si \\(r\\) grande C) Una uniforme D) Una beta T6.12 La convergencia en distribución se refiere a: A) Valores puntuales exactos B) Igualdad de medias C) Convergencia de las funciones de distribución D) Convergencia casi segura T6.13 La relación entre tipos de convergencia indica que: A) Convergencia en distribución implica convergencia casi segura B) Convergencia casi segura implica en probabilidad C) En probabilidad implica en distribución D) b) y c) son correctas T6.14 La convergencia en probabilidad se da cuando: A) La probabilidad de que la variable se aleje mucho de un valor tiende a cero B) La función de densidad es constante C) La esperanza es 0 D) La varianza tiende a infinito T6.15 El TCL se aplica también a: A) Variables dependientes B) Distribuciones con varianza infinita C) Proporciones muestrales D) Histogramas T6.16 Una variable normalizada mediante \\(Z = \\frac{X - \\mu}{\\sigma}\\) es útil para: A) Convergencia en media B) Aproximación Poisson C) Comparar con la normal estándar D) Pasar a una t T6.17 Si una variable converge en distribución a otra, entonces: A) También converge casi seguramente B) No tiene por qué converger en media C) Las funciones de densidad son idénticas D) Se puede usar la misma simulación T6.18 El TCL puede aplicarse en economía para modelar: A) Tasas marginales B) Medias muestrales de ingresos C) Desigualdad extrema D) Probabilidades exactas T6.19 ¿Cuándo es adecuada la aproximación de una distribución binomial por una distribución normal? A) \\(p\\) está cerca de 0 o 1 B) \\(n\\) pequeño y \\(p = 0.5\\) C) \\(n\\) grande y \\(p\\) no muy extremo D) Se usa una gamma T6.20 El TCL permite justificar el uso de: A) Modelos exponenciales B) Aproximaciones normales en inferencia C) Medidas de concentración D) Histograma de frecuencias relativas 7.1.4 Soluciones a los ejercicios tipo test ## Warning: package &#39;dplyr&#39; was built under R version 4.3.3 Table 7.1: Respuestas correctas por tema (tipo test) Pregunta T2 T3 T4 T5 T6 1 A B C 2 B A B 3 D B A 4 A A C 5 B A B 6 B D C 7 A A B 8 C A A 9 A D B 10 C A D 11 B D B 12 C A C 13 B B D 14 B B A 15 C A C 16 B C 17 C B 18 D B 19 D C 20 D B 21 A 22 B 23 B 24 B 25 C T4.1: A T4.2: B T4.3: D T4.4: A T4.5: B T4.6: B T4.7: A T4.8: C T4.9: A T4.10: C T4.11: B T4.12: C T4.13: B T4.14: B T4.15: C T5.1: B T5.2: A T5.3: B T5.4: A T5.5: A T5.6: D T5.7: A T5.8: A T5.9: D T5.10: A T5.11: D T5.12: A T5.13: B T5.14: B T5.15: A T5.16: B T5.17: C T5.18: D T5.19: D T5.20: D T5.21: A T5.22: B T5.23: B T5.24: B T5.25: C T6.1: C T6.2: B T6.3: A T6.4: C T6.5: B T6.6: C T6.7: B T6.8: A T6.9: B T6.10: D T6.11: B T6.12: C T6.13: D T6.14: A T6.15: C T6.16: C T6.17: B T6.18: B T6.19: C T6.20: B 7.2 Ejercicios a desarrollar 7.2.1 Ejercicios del Tema 1: Probabilidad E1.1 Se extrae una bola de una urna con bolas numeradas del 1 al 9. Define: \\(A = \\{1, 2, 3\\}\\) \\(B = \\{3, 4, 5, 6, 7, 8, 9\\}\\) Calcula: \\(A \\cup B\\) \\(A \\cap B\\) \\(A - B\\) \\(\\overline{A}\\) respecto de \\(\\Omega = \\{1, \\dots, 9\\}\\) ¿Son incompatibles A y B? ¿Y compatibles? E1.2 Lanzamiento de un dado. Sea \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\). Define: \\(A =\\) “obtener un número menor o igual que 3” \\(B =\\) “obtener un número par” Calcula: \\(A \\cup B\\) \\(A \\cap B\\) \\(A - B\\) \\(B - A\\) \\(\\overline{A \\cap B}\\) 7.2.2 Ejercicios del Tema 4: Distribuciones discretas E4.1 Se lanza un dado de 10 caras numeradas del 1 al 10. Considera la variable aleatoria \\(X\\) que representa el número obtenido en un lanzamiento. a. ¿Qué tipo de distribución tiene \\(X\\)? Justifícalo. b. Calcula la probabilidad de obtener un número impar. c. Calcula la esperanza y la varianza de \\(X\\). d. Representa su función de distribución acumulada (a mano o en R). E4.2 Un 20% de los usuarios que reciben una campaña de email compran el producto. Se seleccionan 6 usuarios al azar. a. Modeliza esta situación indicando la variable aleatoria y su distribución. b. Calcula la probabilidad de que exactamente 2 compren el producto. c. Calcula la probabilidad de que al menos 1 realice una compra. d. ¿Cuál es la esperanza y varianza del número de compras? E4.3 Una empresa recibe una media de 3 reclamaciones diarias. Sea \\(X \\sim \\text{Poisson}(3)\\) el número de reclamaciones en un día. a. Calcula la probabilidad de que no se reciba ninguna reclamación. b. Calcula la probabilidad de recibir exactamente 2 reclamaciones. c. Calcula la probabilidad de recibir 3 o más reclamaciones. d .¿Cuál es la media y la varianza de esta distribución? E4.4 Un lote de 20 productos contiene 4 defectuosos. Se extraen 5 al azar sin reemplazo. Sea \\(X\\) el número de defectuosos extraídos. a. ¿Qué tipo de distribución sigue \\(X\\)? Indica sus parámetros. b. Calcula \\(P(X = 2)\\). c. Calcula la probabilidad de que al menos uno sea defectuoso. d. ¿Cuál es la esperanza de la variable? E4.5 La probabilidad de que un usuario haga clic en un anuncio es del 10%. Sea \\(X\\) la posición del primer usuario que hace clic. a. ¿Qué distribución tiene \\(X\\)? ¿Qué valores puede tomar? b. Calcula la probabilidad de que el primer clic ocurra en el cuarto intento. c. Simula en R 1000 repeticiones con rgeom(n, prob = 0.1) y representa el histograma. d. ¿Cuál es la media teórica de la distribución? E4.6 Una empresa necesita que su equipo de ventas consiga 3 contratos. Cada llamada tiene una probabilidad del 20% de terminar en contrato y las llamadas son independientes. a) ¿Cuál es la distribución que modela el número total de llamadas necesarias hasta lograr los 3 contratos? b) Calcula la probabilidad de que se necesiten exactamente 8 llamadas. c) ¿Cuál es la esperanza y la varianza del número total de llamadas? E4.7 Un operario realiza intentos independientes para reparar una máquina. La probabilidad de éxito en cada intento es del 30%. a) ¿Cuál es la probabilidad de que el primer intento exitoso se produzca en el cuarto intento? b) ¿Cuál es la esperanza y la varianza del número de intentos hasta el primer éxito? E4.8 En una fábrica, se inspeccionan 10 piezas seleccionadas al azar de un lote de 100, de las cuales se sabe que 20 son defectuosas. a) ¿Cuál es la probabilidad de encontrar exactamente 3 piezas defectuosas en la muestra? b) ¿Cuál es la esperanza del número de defectuosas encontradas? E4.9 En un juego, se lanza una moneda hasta obtener el quinto cara. a) ¿Cuál es la distribución que modela el número total de lanzamientos necesarios? b) Calcula la probabilidad de que se necesiten exactamente 7 lanzamientos. c) Calcula la esperanza y la varianza del número total de lanzamientos. E4.10 En una encuesta sobre el desayuno, el 30% de las personas eligen café, el 50% té, y el 20% zumo. Se seleccionan al azar 10 personas. a) ¿Qué distribución modela el número de personas que eligen cada bebida? b) Calcula la probabilidad de que 3 elijan café, 5 té y 2 zumo. c) Calcula la esperanza del número de personas que eligen té. 7.2.3 Ejercicios del Tema 5: Distribuciones continuas E5.1 Una variable aleatoria continua sigue una distribución uniforme en el intervalo [3, 7]. a) Calcula su función de densidad. b) Halla la probabilidad de que la variable tome un valor entre 4 y 5. c) Calcula su esperanza y varianza. E5.2 Sea \\(X \\sim \\mathcal{N}(100, 16)\\). a) Tipifica la variable. b) Calcula \\(P(X &lt; 104)\\). c) Calcula \\(P(95 &lt; X &lt; 105)\\). E5.3 Una máquina produce tornillos cuyo peso sigue una distribución normal con media 20g y desviación típica 2g. a) ¿Cuál es la probabilidad de que un tornillo pese más de 22g? b) ¿Y de que pese entre 18g y 21g? E5.4 Sea \\(X \\sim \\text{Exp}(0.5)\\). a) Calcula la función de densidad. b) Halla \\(P(X \\leq 3)\\). c) Calcula la media y la varianza. E5.5 Una variable \\(X \\sim \\chi^2_4\\). a) ¿Cuál es su esperanza y varianza? b) ¿Cuál es \\(P(X &gt; 5)\\)? E5.6 La variable \\(T \\sim t_5\\). a) ¿Qué forma tiene la distribución? b) ¿Cuál es su esperanza y su varianza? c) ¿Cuál es \\(P(T &lt; 2.015)\\)? E5.7 En una fábrica se estima que los tiempos de reparación siguen una distribución exponencial con \\(\\lambda = 1/30\\). a) Calcula la probabilidad de que una reparación dure menos de 15 minutos. b) Simula 100 tiempos de reparación en R y representa el histograma. E5.8 Sea \\(X \\sim \\mathcal{N}(80, 25)\\). a) ¿Cuál es la probabilidad de que \\(X &gt; 90\\)? Calcula este valor teóricamente. b) Calcula esa misma probabilidad utilizando R. c) Simula 1000 valores de esta distribución en R y calcula la proporción que supera 90. d) Compara el valor teórico, el calculado con R y el empírico. E5.9 Una variable \\(Y \\sim \\text{Beta}(2, 5)\\). a) Genera 1000 valores aleatorios y representa el histograma. b) Calcula la media empírica y compárala con la media teórica. c) Representa sobre el histograma la función de densidad teórica. E5.10 Simula 1000 observaciones de dos muestras independientes: una con \\(X \\sim \\chi^2_{10}\\) y otra con \\(Y \\sim \\chi^2_{20}\\). a) Calcula el cociente \\(F = \\frac{X/10}{Y/20}\\) para cada pareja. b) Representa el histograma del cociente obtenido. c) Utiliza R para calcular la probabilidad de que \\(F &gt; 2.0\\) según la distribución teórica \\(F_{10, 20}\\). d) Superpón la densidad teórica de la distribución \\(F_{10, 20}\\) sobre el histograma del apartado b. 7.2.4 Ejercicios del Tema 6: Convergencia entre distribuciones E6.1 Un operario tiene una probabilidad del 20% de cometer un error en una tarea. Si realiza 50 tareas, calcula la probabilidad de que cometa exactamente 10 errores: a) Usando la distribución binomial exacta. b) Usando una aproximación normal con corrección de continuidad. E6.2 La variable aleatoria \\(X \\sim B(100, 0.6)\\). a) Calcula la probabilidad de que \\(X \\leq 65\\) utilizando la aproximación normal con corrección de continuidad. b) Justifica por qué es válida esta aproximación. E6.3 Sea \\(Y \\sim \\text{Poisson}(20)\\). a) Calcula la probabilidad de que \\(Y \\leq 25\\) usando la distribución de Poisson. b) Aplica la aproximación normal con corrección de continuidad y compara los resultados. E6.4 Sea \\(X \\sim B(200, 0.05)\\). a) Calcula \\(P(X \\leq 10)\\) usando la distribución binomial. b) Sustituye la binomial por una distribución de Poisson adecuada y calcula la misma probabilidad. E6.5 Considera una variable \\(X \\sim \\text{Poisson}(8)\\). a) Calcula \\(P(X \\geq 10)\\) usando la distribución de Poisson. b) Utiliza una distribución normal adecuada con corrección de continuidad para aproximar esta probabilidad. E6.6 Un lote contiene 2000 productos, de los cuales el 1% está defectuoso. Se toma una muestra aleatoria de 100 productos. a) ¿Qué distribución usarías para modelar el número de defectuosos? b) Calcula la probabilidad de obtener exactamente 2 defectuosos usando la distribución adecuada. c) Propón una aproximación por otra distribución y calcula la probabilidad aproximada. E6.7 Simula 1000 observaciones de una binomial \\(B(30, 0.4)\\). a) Representa el histograma de la muestra. b) Superpón la curva de densidad de la distribución normal que aproxima esta binomial. c) Comenta si visualmente la normal es una buena aproximación. E6.8 Considera una variable \\(X \\sim \\text{Poisson}(15)\\). a) Simula 1000 valores de esta distribución. b) Representa el histograma. c) Añade la curva de la normal con media y varianza iguales a la de \\(X\\). d) Calcula la proporción empírica de valores mayores que 20 y compárala con la estimación normal. E6.9 Una fábrica ha comprobado que solo el 1% de los productos que fabrica presentan defectos. Para controlar la calidad, se selecciona al azar una muestra de 100 productos y se cuenta cuántos son defectuosos. Calcula la probabilidad de que exactamente 2 productos de la muestra sean defectuosos, utilizando el modelo que consideres adecuado. Dado que la muestra es grande y la probabilidad de defecto es muy baja, se decide utilizar un modelo alternativo que simplifique los cálculos. Estima la probabilidad de que haya exactamente 2 productos defectuosos aplicando este modelo aproximado. Compara los resultados de los apartados anteriores. ¿Crees que la aproximación del apartado b) es adecuada? Justifica tu respuesta. Imagina ahora que el número de productos muestreados es 1000 y que la probabilidad de que un producto sea defectuoso es 0.4. ¿A qué otra distribución podría aproximarse este fenómeno bajo esas nuevas condiciones? Justifica tu respuesta. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
